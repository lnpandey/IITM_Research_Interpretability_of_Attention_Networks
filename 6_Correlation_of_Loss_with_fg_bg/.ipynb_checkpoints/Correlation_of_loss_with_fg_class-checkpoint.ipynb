{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wherenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Wherenet,self).__init__()\n",
    "        self.linear1 = nn.Linear(2,16)\n",
    "        self.linear2 = nn.Linear(16,32)\n",
    "        self.linear3 = nn.Linear(32,1)\n",
    "    def forward(self,z):\n",
    "        x = torch.zeros([batch,9],dtype=torch.float64)\n",
    "        y = torch.zeros([batch,2], dtype=torch.float64)\n",
    "        #x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
    "        for i in range(9):\n",
    "            x[:,i] = self.helper(z[:,2*i:2*i+2])[:,0]\n",
    "            #print(k[:,0].shape,x[:,i].shape)\n",
    "        x = F.softmax(x,dim=1)   # alphas\n",
    "        x1 = x[:,0]\n",
    "        for i in range(9):\n",
    "            x1 = x[:,i]          \n",
    "            #print()\n",
    "            y = y+torch.mul(x1[:,None],z[:,2*i:2*i+2])\n",
    "        return y , x \n",
    "\n",
    "    \n",
    "    def helper(self,x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Whatnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Whatnet,self).__init__()\n",
    "        self.linear1 = nn.Linear(2,8)\n",
    "        self.linear2 = nn.Linear(8,16)\n",
    "        self.linear3 = nn.Linear(16,3)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 99\n",
      "1 102\n",
      "2 83\n",
      "3 111\n",
      "4 107\n",
      "5 104\n",
      "6 96\n",
      "7 93\n",
      "8 105\n",
      "9 100\n"
     ]
    }
   ],
   "source": [
    "y = np.random.randint(0,10,1000)\n",
    "idx= []\n",
    "for i in range(10):\n",
    "    print(i,sum(y==i))\n",
    "    idx.append(y==i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((1000,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[idx[0],:] = np.random.multivariate_normal(mean = [2,2],cov=[[0.01,0],[0,0.01]],size=sum(idx[0]))\n",
    "\n",
    "\n",
    "x[idx[1],:] = np.random.multivariate_normal(mean = [0,-2],cov=[[0.01,0],[0,0.01]],size=sum(idx[1]))\n",
    "\n",
    "\n",
    "x[idx[2],:] = np.random.multivariate_normal(mean = [-2,2],cov=[[0.01,0],[0,0.01]],size=sum(idx[2]))\n",
    "\n",
    "\n",
    "\n",
    "x[idx[3],:] = np.random.multivariate_normal(mean = [0,0],cov=[[0.01,0],[0,0.01]],size=sum(idx[3]))\n",
    "\n",
    "\n",
    "x[idx[4],:] = np.random.multivariate_normal(mean =[-2,-4] ,cov=[[0.01,0],[0,0.01]],size=sum(idx[4]))\n",
    "\n",
    "\n",
    "\n",
    "x[idx[5],:] = np.random.multivariate_normal(mean = [2,-4],cov=[[0.01,0],[0,0.01]],size=sum(idx[5]))\n",
    "\n",
    "\n",
    "x[idx[6],:] = np.random.multivariate_normal(mean = [-4,0],cov=[[0.01,0],[0,0.01]],size=sum(idx[6]))\n",
    "\n",
    "\n",
    "x[idx[7],:] = np.random.multivariate_normal(mean = [-2,4],cov=[[0.01,0],[0,0.01]],size=sum(idx[7]))\n",
    "\n",
    "\n",
    "x[idx[8],:] = np.random.multivariate_normal(mean = [2,4],cov=[[0.01,0],[0,0.01]],size=sum(idx[8]))\n",
    "\n",
    "\n",
    "x[idx[9],:] = np.random.multivariate_normal(mean = [4,0],cov=[[0.01,0],[0,0.01]],size=sum(idx[9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.random.randint(0,10,1000)\n",
    "idx= []\n",
    "for i in range(10):\n",
    "    #print(i,sum(y==i))\n",
    "    idx.append(y==i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff5174707f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(x[idx[i],0],x[idx[i],1],label=\"class_\"+str(i))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_classes = {'class_0','class_1', 'class_2'}\n",
    "\n",
    "background_classes = {'class_3','class_4', 'class_5', 'class_6','class_7', 'class_8', 'class_9'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background 5 present at 0\n",
      "background 4 present at 1\n",
      "background 8 present at 2\n",
      "background 9 present at 3\n",
      "background 7 present at 4\n",
      "background 7 present at 5\n",
      "background 4 present at 6\n",
      "background 6 present at 7\n",
      "foreground 0 present at 8\n",
      "(9, 2)\n",
      "0 8\n"
     ]
    }
   ],
   "source": [
    "fg_class  = np.random.randint(0,3)\n",
    "fg_idx = np.random.randint(0,9)\n",
    "\n",
    "a = []\n",
    "for i in range(9):\n",
    "    if i == fg_idx:\n",
    "        b = np.random.choice(np.where(idx[fg_class]==True)[0],size=1)\n",
    "        a.append(x[b])\n",
    "        print(\"foreground \"+str(fg_class)+\" present at \" + str(fg_idx))\n",
    "    else:\n",
    "        bg_class = np.random.randint(3,10)\n",
    "        b = np.random.choice(np.where(idx[bg_class]==True)[0],size=1)\n",
    "        a.append(x[b])\n",
    "        print(\"background \"+str(bg_class)+\" present at \" + str(i))\n",
    "a = np.concatenate(a,axis=0)\n",
    "print(a.shape)\n",
    "\n",
    "print(fg_class , fg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_num = 3000\n",
    "mosaic_list =[]\n",
    "mosaic_label = []\n",
    "fore_idx=[]\n",
    "for j in range(desired_num):\n",
    "    fg_class  = np.random.randint(0,3)\n",
    "    fg_idx = np.random.randint(0,9)\n",
    "    a = []\n",
    "    for i in range(9):\n",
    "        if i == fg_idx:\n",
    "            b = np.random.choice(np.where(idx[fg_class]==True)[0],size=1)\n",
    "            a.append(x[b])\n",
    "#             print(\"foreground \"+str(fg_class)+\" present at \" + str(fg_idx))\n",
    "        else:\n",
    "            bg_class = np.random.randint(3,10)\n",
    "            b = np.random.choice(np.where(idx[bg_class]==True)[0],size=1)\n",
    "            a.append(x[b])\n",
    "#             print(\"background \"+str(bg_class)+\" present at \" + str(i))\n",
    "    a = np.concatenate(a,axis=0)\n",
    "    mosaic_list.append(np.reshape(a,(18,1)))\n",
    "    mosaic_label.append(fg_class)\n",
    "    fore_idx.append(fg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_list = np.concatenate(mosaic_list,axis=1).T\n",
    "#print(mosaic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MosaicDataset(Dataset):\n",
    "  \"\"\"MosaicDataset dataset.\"\"\"\n",
    "\n",
    "  def __init__(self, mosaic_list, mosaic_label, fore_idx):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "        csv_file (string): Path to the csv file with annotations.\n",
    "        root_dir (string): Directory with all the images.\n",
    "        transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "    \"\"\"\n",
    "    self.mosaic = mosaic_list\n",
    "    self.label = mosaic_label\n",
    "    self.fore_idx = fore_idx\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.label)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
    "\n",
    "batch = 250\n",
    "msd = MosaicDataset(mosaic_list, mosaic_label , fore_idx)\n",
    "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = Wherenet().double()\n",
    "what = Whatnet().double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected backend CPU and dtype Double but got backend CPU and dtype Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1ada782a06c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mone_hot_fg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfidx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfidx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mone_hot_bg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mone_hot_fg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss_alpha_fg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_fg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mloss_alpha_bg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_bg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected backend CPU and dtype Double but got backend CPU and dtype Float"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_where = optim.SGD(where.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_what = optim.SGD(what.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "nos_epochs = 100\n",
    "\n",
    "train_loss=[]\n",
    "train_loss_tot=[]\n",
    "test_loss =[]\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "fg_grad=[]\n",
    "bg_grad=[]\n",
    "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    cnt=0\n",
    "    loss_alpha_fg = 0\n",
    "    loss_alpha_bg = 0\n",
    "    iteration = desired_num // batch\n",
    "    \n",
    "    for i, data in  enumerate(train_loader):\n",
    "        inputs , labels , fidx = data\n",
    "        \n",
    "        optimizer_what.zero_grad()\n",
    "        optimizer_where.zero_grad()\n",
    "        \n",
    "        avg_inp,alphas = where(inputs)\n",
    "        \n",
    "        outputs = what(avg_inp)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels) \n",
    "        \n",
    "        grd = torch.autograd.grad(loss,alphas,retain_graph=True)\n",
    "        \n",
    "        one_hot_fg = torch.zeros(len(fidx),fidx.max()+1).scatter_(1,fidx.unsqueeze(1),1.)\n",
    "        one_hot_bg = (1-one_hot_fg)/8\n",
    "        loss_alpha_fg += torch.sum(torch.sum(torch.mul(one_hot_fg, grd[0]),dim=1))\n",
    "        loss_alpha_bg += torch.sum(torch.sum(torch.mul(one_hot_bg, grd[0]),dim=1))\n",
    " \n",
    "        loss.backward(retain_graph =True)\n",
    "        \n",
    "        optimizer_where.step()\n",
    "        optimizer_what.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if cnt % 4 == 3:    # print every 6 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / 4))\n",
    "#             print('[%d,%5d] accuracy: %.3f' %(epoch + 1, cnt+1,running_acc/desired_num))\n",
    "            running_loss = 0.0\n",
    "            train_loss.append(running_loss)\n",
    "#             train_acc.append(running_acc /desired_num)\n",
    "            running_acc = 0\n",
    "        cnt=cnt+1\n",
    "        \n",
    "        \n",
    "    fg_grad.append(loss_alpha_fg.item()/desired_num)\n",
    "    bg_grad.append(loss_alpha_bg.item()/desired_num)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        train_loss_epoch = 0\n",
    "        for data in train_loader:\n",
    "            \n",
    "            inputs, labels , fore_idx = data\n",
    "            avg_inp,alphas = where(inputs)\n",
    "            outputs = what(avg_inp)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_loss_epoch += criterion(outputs, labels).item()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_loss_tot.append(train_loss_epoch)\n",
    "    print('Accuracy of the network on the 1000 train images: %d %%' % (100 * correct / total))\n",
    "print(\"finished training\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,nos_epochs+1)\n",
    "# print(x)\n",
    "plt.plot(x,fg_grad,label = \"grad_alpha_fg\")\n",
    "plt.plot(x,bg_grad, label = \"grad_alpha_bg\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,train_loss_tot, label = \"train loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,ys,fidx = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data,alpha = where(xs)\n",
    "out = what(avg_data)\n",
    "_, predicted = torch.max(out.data, 1)\n",
    "loss = criterion(out, ys) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd = torch.autograd.grad(loss,alpha,retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = torch.zeros(len(fidx),fidx.max()+1).scatter_(1,fidx.unsqueeze(1),1.)µ4ŸÀKwû§BØ?sJ≤Ü^o˚úÆHoF}Ω¸Lø–ñé∞FΩÖJåÊ'ØØjzÚ∫PÌçæ˜È–&öi'û¡çb√O;ó5≥Õu‹ß¡˜dÇ~:1ø5}”è≠˙È⁄ÏùG¬VëV|—©QãíC°ëÃè˙HRÆ	DPN7ìƒ0jÒ“êFÍkµ±ÂÒ7Ò[Î¸YÏäcÓŸ)1÷x”kfÅE6c∞ñΩ?Ò‚`'áRG/ ,/¥‰ ˆ∫óN7˛∆À(yØóÎ∂	DMca‡@È⁄
fn·rﬂbka©P⁄Q∏£]Eg€8õ†oøI
‹ÚÖ"Óy«‡Ω ≥#~˝áÅ?ûÊP:ú¡+É÷A™%g4IÉiÂ»Ü∂=âù$˘ #ê¥ê—B¨d◊SMÖe(;Œ‰ù≠ùP&n•\JÇ,2{∂¸!÷òÒ«l%∂M¨é?ßbw∞Ô∫<ÒA¨(-—jÈsse£xÏ{*o¡Îÿ‡ØX™πÁ¸k‘\º„kNÚ`ì:úöá«πÉ1zˆêJoÑä∆AÓ‚ä^H¸¯xÕ∞wòî°Ìœgtœ,˝6ÖÌ·4œÌL¯ﬁ PÜÈ>7îÑâ	Â’Å¯∏˜wçÂ'B˜‚aR·:ı≥UÏ˝d6Ï¯˝≠0aàª +™QhÙµˆÜ@ﬂ[C?zÒê®àA g"ÚxÁ›äÉâÌ±În!èiPF,ßt˝—È@ßŸòm:}˜µW,ºµ‚˝E»Ï#37¯gæ¶FX¬$˙i⁄©¨ë_E2ˇô4a¸∂¶q¬√wplùµı·D˛—:‚∞3 yb&t Nb|PöﬁcÍ,úg…ÓhÕ˚Ö¨¿‡”YHÀ¢‘ÌLY‹.]QKæ∏9X&‰Å3jlA‚´<æ‰≥©ΩW°]„›güK%ñäÂ¿˝M– ˆjà{"ÚMsàÁÔÖ2@F£Ω?Æp
Ö™F·AÎd⁄›ë≈Nˆ3ëpzr¡’Gñm}CÇNB™UÌπ~À|A>
‚œÃ»Ù›ØXÆ∂◊ªÏ√¥£!œ_ë§—`‚¬N$‘HÄ∫K’V¨c Ÿñ«ìpÒÂâ»’Y–2ƒÕÏ´â´m“ç∆¡É2˚9Î[ôî†EﬁÿOp∞ÁA˜rπúèD¯<}œÚü(c2	úõﬂöï}RÍ¨∞û<Nµ~√∏ Ó.—@î¸ÿ?~ûQ˛+hÓ ÁUoÇé^ÒÇ».‰÷\}kKWŒæ˛QJº>Òp‚T≤◊´’eªì`4aT3˛i$ƒPËäñÀ7„‘∂öÌ¡}RÉ…b1i.´ı¿ÓŒıìÙ