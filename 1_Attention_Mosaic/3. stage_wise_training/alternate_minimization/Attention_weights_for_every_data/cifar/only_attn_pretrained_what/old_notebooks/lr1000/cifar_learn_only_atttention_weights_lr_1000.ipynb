{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar_learn_only_atttention_weights_lr_1000.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIyC9Ip_bcq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgw1f4rVkGr9",
        "outputId": "1a8c52e4-d707-4f9c-b6bb-ae56d4016d1d"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-xlWYTKkQEn"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "#foreground_classes = {'bird', 'cat', 'deer'}\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}\n",
        "#background_classes = {'plane', 'car', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrX68qhikUbz"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD-QJkvnkgyk"
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]])#.type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx])#.type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]-fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs10rfXHkli2"
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  np.random.seed(i)\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7km9Swb1kq4O"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "batch = 250\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=False,num_workers=0,)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGVy-1EllAc_"
      },
      "source": [
        "data,labels,fg_index = iter(train_loader).next()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpZfj1bq7wN"
      },
      "source": [
        "ag = []\n",
        "for i in range(120):\n",
        "  alphag = torch.ones((250,9))/9\n",
        "  ag.append( alphag.requires_grad_() )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrMidFCla6h"
      },
      "source": [
        "class Module2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Module2, self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "    self.fc4 = nn.Linear(10,3)\n",
        "\n",
        "  def forward(self,y):  #z batch of list of 9 images\n",
        "    y1 = self.pool(F.relu(self.conv1(y)))\n",
        "    y1 = self.pool(F.relu(self.conv2(y1)))\n",
        "    y1 = y1.view(-1, 16 * 5 * 5)\n",
        "\n",
        "    y1 = F.relu(self.fc1(y1))\n",
        "    y1 = F.relu(self.fc2(y1))\n",
        "    y1 = F.relu(self.fc3(y1))\n",
        "    y1 = self.fc4(y1)\n",
        "    return y1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqj2VELllkX"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "what_net = Module2().double()\n",
        "\n",
        "what_net.load_state_dict(torch.load(\"simultaneous_what.pt\"))\n",
        "what_net = what_net.to(\"cuda\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d8Wch99l4yB"
      },
      "source": [
        "def attn_avg(x,alpha):\n",
        "  y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "  y = y.to(\"cuda\")\n",
        "  alpha = F.softmax(alpha,dim=1)   # alphas\n",
        "  for i in range(9):            \n",
        "    alpha1 = alpha[:,i]          \n",
        "    y = y + torch.mul(alpha1[:,None,None,None],x[:,i])\n",
        "    return y,alpha\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz1Kpw12loV6"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,criter):\n",
        "  what.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  correct = 0\n",
        "  tot = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx= data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      alpha = ag[i]  # alpha for ith batch\n",
        "      inputs, labels,alpha = inputs.to(\"cuda\"),labels.to(\"cuda\"),alpha.to(\"cuda\")\n",
        "      avg,alpha = attn_avg(inputs,alpha)\n",
        "      alpha = alpha.to(\"cuda\")\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += sum(predicted == labels)\n",
        "      tot += len(predicted)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis,correct.item(),tot,correct.item()/tot"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAY-x6UAwrwE"
      },
      "source": [
        "for param in what_net.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_toCktPanH0S"
      },
      "source": [
        "\n",
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S633XgMToeN3"
      },
      "source": [
        "optim1 = []\n",
        "for i in range(120):\n",
        "  optim1.append(optim.RMSprop([ag[i]], lr=1000))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPaYaojinMTA",
        "outputId": "6a8e3ca8-e575-49a5-e224-99fcf0247bfe"
      },
      "source": [
        "# instantiate optimizer\n",
        "#optimizer_what = optim.RMSprop(what_net.parameters(), lr=0.001)#, momentum=0.9)#,nesterov=True)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "acti = []\n",
        "analysis_data_tr = []\n",
        "analysis_data_tst = []\n",
        "loss_curi_tr = []\n",
        "loss_curi_tst = []\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "# calculate zeroth epoch loss and FTPT values\n",
        "running_loss,anlys_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(0,running_loss,correct,total,accuracy)) \n",
        "loss_curi_tr.append(running_loss)\n",
        "analysis_data_tr.append(anlys_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training starts \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what_net.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    grads = [] \n",
        "    inputs, labels,_  = data\n",
        "    inputs = inputs.double()\n",
        "    alpha = ag[i] # alpha for ith batch\n",
        "    inputs, labels,alpha = inputs.to(\"cuda\"),labels.to(\"cuda\"),alpha.to(\"cuda\")\n",
        "        \n",
        "    # zero the parameter gradients\n",
        "    #optimizer_what.zero_grad()\n",
        "    optim1[i].zero_grad()\n",
        "      \n",
        "    # forward + backward + optimize\n",
        "    avg,alpha = attn_avg(inputs,alpha)\n",
        "    outputs = what_net(avg)     \n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    #alpha.retain_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    #optimizer_what.step()\n",
        "    optim1[i].step()\n",
        "\n",
        "\n",
        "  running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "  analysis_data_tr.append(anls_data)\n",
        "  loss_curi_tr.append(running_loss_tr)   #loss per epoch\n",
        "  print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(epoch+1,running_loss_tr,correct,total,accuracy)) \n",
        "\n",
        "\n",
        "  \n",
        "  if running_loss_tr<=0.08:\n",
        "    break\n",
        "print('Finished Training run ')\n",
        "analysis_data_tr = np.array(analysis_data_tr)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training epoch: [0 ] loss: 4.434 correct: 9998.000, total: 30000.000, accuracy: 0.333\n",
            "training epoch: [1 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [2 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [3 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [4 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [5 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [6 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [7 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [8 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [9 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [10 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [11 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [12 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [13 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [14 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [15 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [16 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [17 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [18 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [19 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [20 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [21 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [22 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [23 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [24 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [25 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [26 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [27 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [28 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [29 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [30 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [31 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [32 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [33 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [34 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [35 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [36 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [37 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [38 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [39 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [40 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [41 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [42 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [43 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [44 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [45 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [46 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [47 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [48 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [49 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [50 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [51 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [52 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [53 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [54 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [55 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [56 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [57 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [58 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [59 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [60 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [61 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [62 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [63 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [64 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [65 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [66 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [67 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [68 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [69 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [70 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [71 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [72 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [73 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [74 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [75 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [76 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [77 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [78 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [79 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [80 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [81 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [82 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [83 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [84 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [85 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [86 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [87 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [88 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [89 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [90 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [91 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [92 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [93 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [94 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [95 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [96 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [97 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [98 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [99 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "training epoch: [100 ] loss: 4.358 correct: 14126.000, total: 30000.000, accuracy: 0.471\n",
            "Finished Training run \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciJnAh5nfug"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train[columns[0]] = np.arange(0,epoch+2)\n",
        "df_train[columns[1]] = analysis_data_tr[:,-2]\n",
        "df_train[columns[2]] = analysis_data_tr[:,-1]\n",
        "df_train[columns[3]] = analysis_data_tr[:,0]\n",
        "df_train[columns[4]] = analysis_data_tr[:,1]\n",
        "df_train[columns[5]] = analysis_data_tr[:,2]\n",
        "df_train[columns[6]] = analysis_data_tr[:,3]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "NoQpS_6scRsC",
        "outputId": "8200c182-001b-4c29-c28d-bea528fe5778"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>1158</td>\n",
              "      <td>8840</td>\n",
              "      <td>2226</td>\n",
              "      <td>17776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>17106</td>\n",
              "      <td>12894</td>\n",
              "      <td>2885</td>\n",
              "      <td>11241</td>\n",
              "      <td>1008</td>\n",
              "      <td>14866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>17106</td>\n",
              "      <td>12894</td>\n",
              "      <td>2885</td>\n",
              "      <td>11241</td>\n",
              "      <td>1008</td>\n",
              "      <td>14866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>17106</td>\n",
              "      <td>12894</td>\n",
              "      <td>2885</td>\n",
              "      <td>11241</td>\n",
              "      <td>1008</td>\n",
              "      <td>14866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>17106</td>\n",
              "      <td>12894</td>\n",
              "      <td>2885</td>\n",
              "      <td>11241</td>\n",
              "      <td>1008</td>\n",
              "      <td>14866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>17106</td>\n",
              "      <td>12894</td>\n",
              "      <td>2885</td>\n",
              "      <td>11241</td>\n",
              "      <td>1008</td>\n",
              "      <td>14866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>17106</td>\n",
              "      <td>12894</td>\n",
              "      <td>2885</td>\n",
              "      <td>11241</td>\n",
              "      <td>1008</td>\n",
              "      <td>14866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>17106</td>\n",
              "      <td>12894</td>\n",
              "      <td>2885</td>\n",
              "      <td>11241</td>\n",
              "      <td>1008</td>\n",
              "      <td>14866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>17106</td>\n",
              "      <td>12894</td>\n",
              "      <td>2885</td>\n",
              "      <td>11241</td>\n",
              "      <td>1008</td>\n",
              "      <td>14866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>100</td>\n",
              "      <td>17106</td>\n",
              "      <td>12894</td>\n",
              "      <td>2885</td>\n",
              "      <td>11241</td>\n",
              "      <td>1008</td>\n",
              "      <td>14866</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0         0             0  ...                   2226                   17776\n",
              "1         1         17106  ...                   1008                   14866\n",
              "2         2         17106  ...                   1008                   14866\n",
              "3         3         17106  ...                   1008                   14866\n",
              "4         4         17106  ...                   1008                   14866\n",
              "..      ...           ...  ...                    ...                     ...\n",
              "96       96         17106  ...                   1008                   14866\n",
              "97       97         17106  ...                   1008                   14866\n",
              "98       98         17106  ...                   1008                   14866\n",
              "99       99         17106  ...                   1008                   14866\n",
              "100     100         17106  ...                   1008                   14866\n",
              "\n",
              "[101 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "IMAhRdxOcVf6",
        "outputId": "7bc48063-f721-4bc1-c11d-db8f6a9e6e45"
      },
      "source": [
        "fig= plt.figure(figsize=(12,12))\n",
        "plt.plot(df_train[columns[0]],df_train[columns[3]]/300, label =\"focus_true_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[4]]/300, label =\"focus_false_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[5]]/300, label =\"focus_true_pred_false \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[6]]/300, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Train set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"percentage of data\")\n",
        "#plt.vlines(vline_list,min(min(df_train[columns[3]]/300),min(df_train[columns[4]]/300),min(df_train[columns[5]]/300),min(df_train[columns[6]]/300)), max(max(df_train[columns[3]]/300),max(df_train[columns[4]]/300),max(df_train[columns[5]]/300),max(df_train[columns[6]]/300)),linestyles='dotted')\n",
        "plt.show()\n",
        "fig.savefig(\"train_analysis_every_20.pdf\")\n",
        "fig.savefig(\"train_analysis_every_20.png\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCnS6r2_3WdU"
      },
      "source": [
        "aph = []\n",
        "for i in ag:\n",
        "  aph.append(F.softmax(i,dim=1).detach().numpy())\n",
        "  \n",
        "aph = np.concatenate(aph,axis=0)\n",
        "torch.save({\n",
        "            'epoch': 500,\n",
        "            'model_state_dict': what_net.state_dict(),\n",
        "            #'optimizer_state_dict': optimizer_what.state_dict(),\n",
        "            \"optimizer_alpha\":optim1,\n",
        "            \"FTPT_analysis\":analysis_data_tr,\n",
        "            \"alpha\":aph\n",
        "\n",
        "            }, \"cifar_what_net_500.pt\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVzrDOGS4UxU",
        "outputId": "76b2fa4c-35e4-40c6-80a6-e3b6bc2e802c"
      },
      "source": [
        "aph"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.   , 0.125, 0.125, ..., 0.125, 0.125, 0.125],\n",
              "       [1.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
              "       [1.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
              "       ...,\n",
              "       [0.   , 0.125, 0.125, ..., 0.125, 0.125, 0.125],\n",
              "       [1.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
              "       [1.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6heHND15EMz"
      },
      "source": [
        "running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeKhsdpYWQvB",
        "outputId": "14aa82bb-1b23-4722-d6be-3dc220ee8391"
      },
      "source": [
        "print(\"argmax>0.5\",anls_data[-2])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "argmax>0.5 17106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF2bvWdIWUTa"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}