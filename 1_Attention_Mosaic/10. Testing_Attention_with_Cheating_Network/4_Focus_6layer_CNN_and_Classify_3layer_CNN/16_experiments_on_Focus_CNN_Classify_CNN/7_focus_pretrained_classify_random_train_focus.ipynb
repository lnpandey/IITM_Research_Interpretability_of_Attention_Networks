{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "7_focus_pretrained_classify_random_train_focus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c34e36873c64f33b37e875dae0d4ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b28e3a34b8f4d4eb7b146bfcebc5aa4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_437d603907b048f99e209def09ff2e75",
              "IPY_MODEL_539e57982c1e439b88bf79dc276695c2"
            ]
          }
        },
        "8b28e3a34b8f4d4eb7b146bfcebc5aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "437d603907b048f99e209def09ff2e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fad631a7b8fb4e4194b287b45086ecdb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df387359a02742969aaacd5990f84743"
          }
        },
        "539e57982c1e439b88bf79dc276695c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14f96da28b244f67b1deaa5b102adba7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 32486213.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4aa86b76bc1b4633b70b7a012fcc7c03"
          }
        },
        "fad631a7b8fb4e4194b287b45086ecdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df387359a02742969aaacd5990f84743": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14f96da28b244f67b1deaa5b102adba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4aa86b76bc1b4633b70b7a012fcc7c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSjG64ra4aFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "c3ca1017-963a-4fbc-d339-2c71f4495c82"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8-7SARDZErK",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import copy\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acRFqJNrZErV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "1c34e36873c64f33b37e875dae0d4ffe",
            "8b28e3a34b8f4d4eb7b146bfcebc5aa4",
            "437d603907b048f99e209def09ff2e75",
            "539e57982c1e439b88bf79dc276695c2",
            "fad631a7b8fb4e4194b287b45086ecdb",
            "df387359a02742969aaacd5990f84743",
            "14f96da28b244f67b1deaa5b102adba7",
            "4aa86b76bc1b4633b70b7a012fcc7c03"
          ]
        },
        "outputId": "394963e8-2ee6-4b98-f097-1801dc5c6d12"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c34e36873c64f33b37e875dae0d4ffe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5DXuAV1tp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "foreground_classes = {'plane', 'car', 'bird'}\n",
        "\n",
        "background_classes = {'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck'}\n",
        "\n",
        "fg1,fg2,fg3 = 0,1,2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V_JUhwCeZErk",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "background_data=[]\n",
        "background_label=[]\n",
        "foreground_data=[]\n",
        "foreground_label=[]\n",
        "batch_size=10\n",
        "\n",
        "for i in range(5000):\n",
        "  images, labels = dataiter.next()\n",
        "  for j in range(batch_size):\n",
        "    if(classes[labels[j]] in background_classes):\n",
        "      img = images[j].tolist()\n",
        "      background_data.append(img)\n",
        "      background_label.append(labels[j])\n",
        "    else:\n",
        "      img = images[j].tolist()\n",
        "      foreground_data.append(img)\n",
        "      foreground_label.append(labels[j])\n",
        "            \n",
        "foreground_data = torch.tensor(foreground_data)\n",
        "foreground_label = torch.tensor(foreground_label)\n",
        "background_data = torch.tensor(background_data)\n",
        "background_label = torch.tensor(background_label)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW9MkktGysAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mosaic_img(bg_idx,fg_idx,fg): \n",
        "  \"\"\"\n",
        "  bg_idx : list of indexes of background_data[] to be used as background images in mosaic\n",
        "  fg_idx : index of image to be used as foreground image from foreground data\n",
        "  fg : at what position/index foreground image has to be stored out of 0-8\n",
        "  \"\"\"\n",
        "  image_list=[]\n",
        "  j=0\n",
        "  for i in range(9):\n",
        "    if i != fg:\n",
        "      image_list.append(background_data[bg_idx[j]].type(\"torch.DoubleTensor\"))\n",
        "      j+=1\n",
        "    else: \n",
        "      image_list.append(foreground_data[fg_idx].type(\"torch.DoubleTensor\"))\n",
        "      label = foreground_label[fg_idx]- fg1  # minus 7 because our fore ground classes are 7,8,9 but we have to store it as 0,1,2\n",
        "  #image_list = np.concatenate(image_list ,axis=0)\n",
        "  image_list = torch.stack(image_list) \n",
        "  return image_list,label"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxkp87fNwnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desired_num = 30000\n",
        "mosaic_list_of_images =[]      # list of mosaic images, each mosaic image is saved as list of 9 images\n",
        "fore_idx =[]                   # list of indexes at which foreground image is present in a mosaic image i.e from 0 to 9               \n",
        "mosaic_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(desired_num):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  mosaic_list_of_images.append(image_list)\n",
        "  mosaic_label.append(label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuGak6_zXgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n",
        "batch = 125\n",
        "msd = MosaicDataset(mosaic_list_of_images, mosaic_label , fore_idx)\n",
        "train_loader = DataLoader( msd,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SadRzWBBZEsP",
        "colab": {}
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Focus, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "    self.dropout1 = nn.Dropout2d(p=0.05)\n",
        "    self.dropout2 = nn.Dropout2d(p=0.1)\n",
        "    self.fc1 = nn.Linear(128,64)\n",
        "    self.fc2 = nn.Linear(64, 32)\n",
        "    self.fc3 = nn.Linear(32, 10)\n",
        "    self.fc4 = nn.Linear(10, 2)\n",
        "\n",
        "  def forward(self,z):  #y is avg image #z batch of list of 9 images\n",
        "    y = torch.zeros([batch,3, 32,32], dtype=torch.float64)\n",
        "    x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "    y = y.to(\"cuda\")\n",
        "    x = x.to(\"cuda\")\n",
        "    \n",
        "    for i in range(9):\n",
        "        x[:,i] = self.helper(z[:,i])[:,0]\n",
        "\n",
        "    x = F.softmax(x,dim=1)\n",
        "\n",
        "    x1 = x[:,0]\n",
        "    torch.mul(x1[:,None,None,None],z[:,0])\n",
        "\n",
        "    for i in range(9):            \n",
        "      x1 = x[:,i]          \n",
        "      y = y + torch.mul(x1[:,None,None,None],z[:,i])\n",
        "\n",
        "    return x, y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.batch_norm1(x))\n",
        "\n",
        "    x = (F.relu(self.conv2(x)))\n",
        "    x = self.pool(x)\n",
        "    \n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv4(x)))\n",
        "    x = self.pool(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = F.relu(self.batch_norm2(x))\n",
        "\n",
        "    x = (F.relu(self.conv6(x)))\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout2(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvXR1zV5n4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focus_net = Focus().double()\n",
        "focus_net = focus_net.to(\"cuda\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZob1uGT6fTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e8850d00-6258-4109-c320-f823889636f2"
      },
      "source": [
        "focus_net.load_state_dict( torch.load(\"/content/drive/My Drive/Research/Cheating_data/Focus_net_weights/focus_net_6layer_cnn.pt\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuvh8egty-M8",
        "colab_type": "text"
      },
      "source": [
        "Changing the last layer of Focus net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF-WJw9Da0MM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41e1b759-a7a1-404e-b2c4-7c3daa431390"
      },
      "source": [
        "focus_net.fc4"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=2, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugYLSgCpyv2i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "3cca6a57-c55b-4baa-9da9-54848d049b40"
      },
      "source": [
        "print(focus_net.fc4)\n",
        "print(focus_net.fc4.weight)\n",
        "print(focus_net.fc4.bias)\n",
        "temp = focus_net.fc4.weight.data\n",
        "temp2 = focus_net.fc4.bias.data\n",
        "focus_net.fc4 = nn.Linear(10,1).double()\n",
        "focus_net.fc4.weight.data = torch.unsqueeze(temp[1,:], 0)\n",
        "focus_net.fc4.bias.data = torch.unsqueeze(temp2[1], 0)\n",
        "focus_net = focus_net.to(\"cuda\")\n",
        "print(focus_net.fc4.weight)\n",
        "print(focus_net.fc4.bias)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=10, out_features=2, bias=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.3974,  0.2455,  0.2787, -0.4295, -0.5508,  0.8661, -0.2221, -0.6396,\n",
            "          0.5014,  0.1486],\n",
            "        [-0.1227,  0.1252, -0.0242,  0.3076,  0.7789, -0.7985, -0.2840,  0.6068,\n",
            "         -0.5138,  0.2816]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2738,  0.0337], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.1227,  0.1252, -0.0242,  0.3076,  0.7789, -0.7985, -0.2840,  0.6068,\n",
            "         -0.5138,  0.2816]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0337], device='cuda:0', dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnE-DYdAa4LL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b12751b5-b072-4188-cfc1-3ab86934a77c"
      },
      "source": [
        "focus_net.fc4"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=1, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uE2ecgApdwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for params in focus_net.parameters():\n",
        "#   params.requires_grad = False"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0rkwoqLpya8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for params in focus_net.parameters():\n",
        "#   print(params)\n",
        "#   break;"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdCXceZzSk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=0)\n",
        "    self.fc1 = nn.Linear(1024, 512)\n",
        "    self.fc2 = nn.Linear(512, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "    self.fc4 = nn.Linear(10,3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    # print(x.shape)\n",
        "    x = (F.relu(self.conv3(x)))\n",
        "    x =  x.view(x.size(0), -1)\n",
        "    # print(x.shape)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYplUGazU9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classify = Classification().double()\n",
        "classify = classify.to(\"cuda\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjK7sLtEouXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for params in classify.parameters():\n",
        "  params.requires_grad = False"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWqPec7aoynC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "828bacad-d8ae-4f7d-aee7-eccbd3576ae1"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.0156,  0.1159,  0.0410],\n",
            "          [-0.1563, -0.1572, -0.1408],\n",
            "          [-0.1151,  0.1371,  0.0656]],\n",
            "\n",
            "         [[ 0.0482, -0.0495, -0.1614],\n",
            "          [-0.1785, -0.1560,  0.0295],\n",
            "          [ 0.1733, -0.0512, -0.1101]],\n",
            "\n",
            "         [[-0.1752, -0.0922,  0.0216],\n",
            "          [ 0.1009, -0.1605, -0.0230],\n",
            "          [ 0.1828,  0.0740, -0.1501]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1835,  0.1559,  0.0706],\n",
            "          [ 0.0240, -0.0607, -0.0079],\n",
            "          [ 0.1309,  0.1401, -0.0030]],\n",
            "\n",
            "         [[ 0.0976,  0.0028, -0.1704],\n",
            "          [-0.0219, -0.0743, -0.1558],\n",
            "          [ 0.0786,  0.0969, -0.0716]],\n",
            "\n",
            "         [[-0.1034,  0.1893, -0.0273],\n",
            "          [-0.0317,  0.1182, -0.0102],\n",
            "          [ 0.0922, -0.0456, -0.0388]]],\n",
            "\n",
            "\n",
            "        [[[-0.1525, -0.0107, -0.1594],\n",
            "          [-0.0165, -0.0297,  0.0849],\n",
            "          [-0.1854, -0.1048,  0.0287]],\n",
            "\n",
            "         [[ 0.0820, -0.0330,  0.1505],\n",
            "          [-0.0193,  0.1298,  0.1412],\n",
            "          [-0.1885,  0.1099,  0.0713]],\n",
            "\n",
            "         [[-0.0696, -0.0180, -0.0397],\n",
            "          [-0.1065, -0.1760, -0.1626],\n",
            "          [ 0.0932,  0.1298, -0.1582]]],\n",
            "\n",
            "\n",
            "        [[[-0.1655,  0.0129,  0.0112],\n",
            "          [ 0.0632,  0.1445,  0.0918],\n",
            "          [-0.0033, -0.0952, -0.0882]],\n",
            "\n",
            "         [[ 0.1495,  0.0642,  0.0971],\n",
            "          [ 0.0344, -0.1380, -0.0613],\n",
            "          [-0.0776, -0.1490, -0.1411]],\n",
            "\n",
            "         [[-0.0518,  0.1250, -0.0349],\n",
            "          [-0.1415, -0.1777, -0.0529],\n",
            "          [ 0.0306,  0.0018,  0.0123]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0315,  0.1851, -0.0284],\n",
            "          [-0.1842, -0.1624,  0.0871],\n",
            "          [-0.0558,  0.1550, -0.0135]],\n",
            "\n",
            "         [[-0.1668, -0.0693, -0.0077],\n",
            "          [-0.1412, -0.0047, -0.0923],\n",
            "          [ 0.1048,  0.1649,  0.1669]],\n",
            "\n",
            "         [[-0.0663, -0.0182,  0.0987],\n",
            "          [-0.0161,  0.0186,  0.0146],\n",
            "          [ 0.1331,  0.1902,  0.0730]]],\n",
            "\n",
            "\n",
            "        [[[-0.0199,  0.0883, -0.1743],\n",
            "          [-0.0886,  0.1755, -0.0116],\n",
            "          [ 0.1657, -0.0474,  0.0350]],\n",
            "\n",
            "         [[ 0.0612,  0.1620, -0.1873],\n",
            "          [-0.0266, -0.0494,  0.1589],\n",
            "          [-0.1386,  0.1655,  0.1839]],\n",
            "\n",
            "         [[-0.1125,  0.0324,  0.0084],\n",
            "          [ 0.1219,  0.1416,  0.1689],\n",
            "          [ 0.1052,  0.0409,  0.1797]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1384, -0.0869,  0.0816],\n",
            "          [ 0.1772, -0.1604, -0.1237],\n",
            "          [ 0.1281,  0.1160,  0.1174]],\n",
            "\n",
            "         [[ 0.1491, -0.0515,  0.1312],\n",
            "          [ 0.1042, -0.0445, -0.0138],\n",
            "          [-0.1170, -0.0750,  0.1510]],\n",
            "\n",
            "         [[-0.0101, -0.0502, -0.0686],\n",
            "          [-0.0316,  0.0026, -0.0943],\n",
            "          [ 0.1259,  0.1583,  0.1369]]],\n",
            "\n",
            "\n",
            "        [[[-0.1884, -0.0295, -0.1406],\n",
            "          [ 0.0932,  0.0757,  0.1553],\n",
            "          [-0.0629, -0.1010, -0.0279]],\n",
            "\n",
            "         [[-0.1786, -0.1890, -0.0180],\n",
            "          [ 0.0517, -0.1706,  0.0613],\n",
            "          [ 0.0209, -0.1192, -0.1125]],\n",
            "\n",
            "         [[-0.0949, -0.0766,  0.1367],\n",
            "          [-0.0874,  0.0847,  0.1167],\n",
            "          [-0.1191, -0.0614,  0.0564]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0957,  0.0554, -0.0765],\n",
            "          [ 0.1606,  0.0348,  0.0745],\n",
            "          [ 0.0069,  0.1636,  0.1544]],\n",
            "\n",
            "         [[-0.0082,  0.0277,  0.0091],\n",
            "          [-0.0300,  0.1364,  0.1923],\n",
            "          [ 0.1719, -0.1033,  0.0112]],\n",
            "\n",
            "         [[-0.0248,  0.0031, -0.1885],\n",
            "          [-0.0515, -0.1492,  0.1894],\n",
            "          [-0.0094,  0.1157,  0.0780]]],\n",
            "\n",
            "\n",
            "        [[[-0.0639, -0.1186, -0.1712],\n",
            "          [ 0.1099, -0.0700, -0.1327],\n",
            "          [ 0.1128, -0.1402,  0.0697]],\n",
            "\n",
            "         [[ 0.0908,  0.0092,  0.1614],\n",
            "          [ 0.0273,  0.1293, -0.0143],\n",
            "          [-0.1789,  0.0474,  0.0549]],\n",
            "\n",
            "         [[-0.0154,  0.0255, -0.0249],\n",
            "          [-0.1686, -0.0578,  0.0906],\n",
            "          [-0.1409, -0.0493, -0.0598]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1327, -0.0552,  0.0719],\n",
            "          [ 0.1169,  0.1206, -0.0888],\n",
            "          [-0.1847, -0.0711, -0.0824]],\n",
            "\n",
            "         [[ 0.1505, -0.0359, -0.0636],\n",
            "          [-0.0425,  0.1068, -0.1349],\n",
            "          [ 0.1606,  0.0018, -0.1230]],\n",
            "\n",
            "         [[ 0.0555, -0.1460, -0.1906],\n",
            "          [ 0.1213, -0.0552,  0.1524],\n",
            "          [ 0.0677,  0.0160,  0.0833]]],\n",
            "\n",
            "\n",
            "        [[[-0.1309, -0.0228,  0.1652],\n",
            "          [ 0.0217,  0.1667,  0.0147],\n",
            "          [ 0.1179,  0.1445, -0.0148]],\n",
            "\n",
            "         [[-0.0993,  0.1020, -0.1564],\n",
            "          [ 0.0565,  0.0837,  0.1711],\n",
            "          [ 0.1319, -0.0688,  0.1647]],\n",
            "\n",
            "         [[ 0.1879, -0.0029,  0.0122],\n",
            "          [-0.0649,  0.1870,  0.1419],\n",
            "          [-0.1504,  0.1171, -0.1625]]],\n",
            "\n",
            "\n",
            "        [[[-0.0368, -0.1808, -0.1576],\n",
            "          [ 0.0072, -0.0401,  0.1415],\n",
            "          [-0.1737, -0.1856,  0.1323]],\n",
            "\n",
            "         [[-0.0663, -0.0723, -0.1185],\n",
            "          [ 0.0915,  0.1452,  0.0441],\n",
            "          [ 0.0802, -0.1466, -0.1460]],\n",
            "\n",
            "         [[-0.1115, -0.0251,  0.0483],\n",
            "          [-0.0822, -0.1408,  0.1835],\n",
            "          [ 0.0376, -0.0909, -0.0267]]],\n",
            "\n",
            "\n",
            "        [[[-0.0878,  0.0646, -0.1812],\n",
            "          [ 0.1650,  0.0965,  0.0693],\n",
            "          [-0.1484, -0.0651, -0.1263]],\n",
            "\n",
            "         [[-0.0509, -0.0951, -0.0142],\n",
            "          [ 0.0530, -0.1442,  0.0299],\n",
            "          [ 0.0840,  0.1304, -0.0735]],\n",
            "\n",
            "         [[ 0.1291,  0.0208, -0.1670],\n",
            "          [ 0.0518,  0.0964,  0.1552],\n",
            "          [-0.1410, -0.0946,  0.1140]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1685, -0.0363,  0.1153],\n",
            "          [-0.1923,  0.1411, -0.0956],\n",
            "          [-0.1019, -0.1701,  0.1425]],\n",
            "\n",
            "         [[ 0.0797, -0.0919,  0.0223],\n",
            "          [ 0.1460, -0.1455,  0.1324],\n",
            "          [-0.0794, -0.0233, -0.0388]],\n",
            "\n",
            "         [[-0.1091,  0.1767,  0.1660],\n",
            "          [-0.0909, -0.1251, -0.1592],\n",
            "          [-0.1838, -0.0522, -0.1426]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1144, -0.0257,  0.0602],\n",
            "          [ 0.0032,  0.1688,  0.0363],\n",
            "          [-0.1549,  0.0152,  0.1827]],\n",
            "\n",
            "         [[-0.1617, -0.0045,  0.0389],\n",
            "          [-0.0841,  0.0244,  0.0586],\n",
            "          [-0.1773, -0.0327, -0.0424]],\n",
            "\n",
            "         [[-0.1551,  0.0507, -0.0424],\n",
            "          [ 0.1841,  0.1769, -0.1480],\n",
            "          [-0.0035, -0.1767,  0.1169]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1841,  0.1798, -0.0084],\n",
            "          [-0.1695, -0.1048, -0.1317],\n",
            "          [-0.0003,  0.0691, -0.0389]],\n",
            "\n",
            "         [[-0.1433,  0.1551, -0.0366],\n",
            "          [ 0.1631,  0.1576,  0.1571],\n",
            "          [-0.1029, -0.0470, -0.1608]],\n",
            "\n",
            "         [[-0.1705,  0.0730,  0.1552],\n",
            "          [-0.0726, -0.0891, -0.0096],\n",
            "          [ 0.1312, -0.0471,  0.0587]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1116,  0.1525,  0.0747],\n",
            "          [-0.0680,  0.1072, -0.1389],\n",
            "          [ 0.0676, -0.0244,  0.1707]],\n",
            "\n",
            "         [[ 0.1171,  0.0466,  0.1583],\n",
            "          [ 0.0085, -0.0530,  0.1904],\n",
            "          [-0.0971, -0.1669,  0.1648]],\n",
            "\n",
            "         [[ 0.0267,  0.0379, -0.0461],\n",
            "          [-0.1814,  0.0189, -0.1121],\n",
            "          [-0.1600,  0.1492, -0.0961]]],\n",
            "\n",
            "\n",
            "        [[[-0.0617, -0.1437, -0.1508],\n",
            "          [ 0.1201,  0.1768, -0.0461],\n",
            "          [ 0.0982, -0.0291, -0.0947]],\n",
            "\n",
            "         [[-0.0974,  0.1554,  0.0408],\n",
            "          [ 0.0720, -0.0697, -0.0251],\n",
            "          [ 0.0322,  0.0936,  0.1644]],\n",
            "\n",
            "         [[-0.1664, -0.0883, -0.1066],\n",
            "          [-0.0579,  0.0544, -0.0924],\n",
            "          [-0.0889, -0.1760,  0.1256]]],\n",
            "\n",
            "\n",
            "        [[[-0.1477, -0.1690, -0.1853],\n",
            "          [-0.0386,  0.0114,  0.0280],\n",
            "          [ 0.0144, -0.0289,  0.1136]],\n",
            "\n",
            "         [[-0.1777, -0.1851,  0.1235],\n",
            "          [ 0.1006, -0.0616, -0.0994],\n",
            "          [ 0.0930, -0.0802, -0.0679]],\n",
            "\n",
            "         [[-0.0046, -0.0569,  0.0625],\n",
            "          [ 0.0597,  0.0650, -0.0592],\n",
            "          [ 0.1113, -0.1730, -0.0322]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0537,  0.1698,  0.0219],\n",
            "          [ 0.0959,  0.0354, -0.0264],\n",
            "          [-0.1671, -0.0129,  0.0860]],\n",
            "\n",
            "         [[ 0.1893,  0.1077,  0.0152],\n",
            "          [-0.1647, -0.1827, -0.0753],\n",
            "          [-0.0533,  0.1702, -0.0697]],\n",
            "\n",
            "         [[-0.0347,  0.1163, -0.0736],\n",
            "          [ 0.0152, -0.1779,  0.1586],\n",
            "          [ 0.1698,  0.0823,  0.0359]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0403,  0.1191,  0.0493],\n",
            "          [ 0.0266,  0.1087,  0.1331],\n",
            "          [-0.0191,  0.1472, -0.0047]],\n",
            "\n",
            "         [[ 0.1500, -0.0964,  0.0490],\n",
            "          [ 0.1823,  0.0187,  0.1151],\n",
            "          [ 0.0883, -0.0963, -0.1001]],\n",
            "\n",
            "         [[-0.0047,  0.1905, -0.0467],\n",
            "          [-0.0255,  0.0408,  0.0685],\n",
            "          [ 0.0553, -0.1425,  0.1278]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1058, -0.0152, -0.1273],\n",
            "          [-0.0741,  0.0596,  0.0062],\n",
            "          [-0.1505,  0.1628,  0.0253]],\n",
            "\n",
            "         [[-0.0942, -0.1393, -0.1552],\n",
            "          [-0.1547, -0.0705,  0.1388],\n",
            "          [-0.0107, -0.0527,  0.1119]],\n",
            "\n",
            "         [[ 0.0635,  0.0173,  0.0680],\n",
            "          [-0.0416,  0.1860,  0.0341],\n",
            "          [-0.1039,  0.0439,  0.0441]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1661, -0.0140,  0.0110],\n",
            "          [ 0.0052, -0.0717,  0.0538],\n",
            "          [ 0.0854,  0.0188,  0.0755]],\n",
            "\n",
            "         [[-0.0586, -0.0299,  0.0443],\n",
            "          [-0.0042,  0.0861,  0.1263],\n",
            "          [ 0.1624,  0.1545,  0.1235]],\n",
            "\n",
            "         [[ 0.1633, -0.0380, -0.0056],\n",
            "          [-0.0377, -0.1156, -0.0738],\n",
            "          [ 0.0627, -0.0864,  0.1396]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0924, -0.1090,  0.0501],\n",
            "          [ 0.1168,  0.0842,  0.1751],\n",
            "          [-0.1292,  0.0015,  0.1661]],\n",
            "\n",
            "         [[-0.0836, -0.1632,  0.1831],\n",
            "          [ 0.1052, -0.1005, -0.1397],\n",
            "          [ 0.0754, -0.0755,  0.1712]],\n",
            "\n",
            "         [[ 0.1536, -0.1792, -0.1187],\n",
            "          [-0.0611,  0.0760,  0.0775],\n",
            "          [-0.1140, -0.0431, -0.1458]]],\n",
            "\n",
            "\n",
            "        [[[-0.0232,  0.1835,  0.0745],\n",
            "          [ 0.1117, -0.0883, -0.1386],\n",
            "          [-0.1557,  0.1758, -0.0936]],\n",
            "\n",
            "         [[-0.0016, -0.0489, -0.1789],\n",
            "          [-0.0633, -0.0327, -0.0209],\n",
            "          [-0.0344, -0.1555,  0.1767]],\n",
            "\n",
            "         [[-0.0761, -0.1868, -0.1141],\n",
            "          [-0.1585,  0.0602, -0.0238],\n",
            "          [ 0.0859,  0.1493,  0.1338]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0246,  0.0528,  0.0173],\n",
            "          [-0.1369,  0.1246,  0.0543],\n",
            "          [-0.0981, -0.1195,  0.0366]],\n",
            "\n",
            "         [[ 0.0792, -0.0554,  0.0652],\n",
            "          [ 0.1514,  0.0854,  0.0888],\n",
            "          [-0.1700,  0.1094,  0.0109]],\n",
            "\n",
            "         [[-0.0795, -0.0438, -0.1501],\n",
            "          [ 0.0464,  0.0611, -0.1631],\n",
            "          [-0.0012, -0.0922, -0.1099]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0530,  0.1233,  0.0131],\n",
            "          [ 0.0589,  0.1036, -0.0108],\n",
            "          [-0.1690,  0.1131, -0.1043]],\n",
            "\n",
            "         [[ 0.0457, -0.0277,  0.0859],\n",
            "          [-0.0954, -0.0956,  0.1217],\n",
            "          [-0.0095, -0.1706, -0.0111]],\n",
            "\n",
            "         [[ 0.0052, -0.0206, -0.0942],\n",
            "          [ 0.1453, -0.0762, -0.0102],\n",
            "          [-0.0133, -0.0472, -0.0296]]],\n",
            "\n",
            "\n",
            "        [[[-0.0032,  0.1767, -0.1359],\n",
            "          [ 0.0095, -0.0147,  0.1706],\n",
            "          [ 0.0657, -0.0276,  0.0065]],\n",
            "\n",
            "         [[-0.1688,  0.0782,  0.0228],\n",
            "          [ 0.1471, -0.0263,  0.1305],\n",
            "          [ 0.1693, -0.1343,  0.1514]],\n",
            "\n",
            "         [[-0.0731, -0.0426,  0.1111],\n",
            "          [ 0.1197, -0.1028, -0.1659],\n",
            "          [ 0.1363,  0.0867,  0.0408]]],\n",
            "\n",
            "\n",
            "        [[[-0.1326, -0.1377, -0.1251],\n",
            "          [-0.1438,  0.0879,  0.0806],\n",
            "          [-0.1093, -0.0851,  0.0084]],\n",
            "\n",
            "         [[-0.1638,  0.0462, -0.0785],\n",
            "          [-0.1418, -0.0246,  0.1373],\n",
            "          [ 0.0300, -0.0012,  0.0693]],\n",
            "\n",
            "         [[ 0.0011, -0.0709, -0.0437],\n",
            "          [ 0.0789,  0.0093,  0.1753],\n",
            "          [-0.0658,  0.0923, -0.0706]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1880,  0.1886,  0.0199],\n",
            "          [-0.1486, -0.1509,  0.0211],\n",
            "          [ 0.1125,  0.1696, -0.0596]],\n",
            "\n",
            "         [[-0.1832, -0.1260, -0.0459],\n",
            "          [-0.1565,  0.0077, -0.1587],\n",
            "          [ 0.0859,  0.0331,  0.0812]],\n",
            "\n",
            "         [[ 0.1637,  0.0628, -0.1320],\n",
            "          [ 0.1461, -0.1573, -0.0135],\n",
            "          [ 0.0994,  0.1162,  0.1150]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1168,  0.1048,  0.1275],\n",
            "          [-0.1507, -0.1773, -0.1313],\n",
            "          [ 0.0992, -0.0936, -0.0489]],\n",
            "\n",
            "         [[-0.0222,  0.0873, -0.0327],\n",
            "          [-0.1858, -0.0051,  0.1830],\n",
            "          [ 0.1878, -0.0448,  0.1308]],\n",
            "\n",
            "         [[-0.1856, -0.1460,  0.1094],\n",
            "          [-0.1686,  0.0692,  0.0391],\n",
            "          [-0.1914, -0.1477,  0.1868]]]], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l789TLMP9zJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images =[]        #list of mosaic images, each mosaic image is saved as laist of 9 images\n",
        "fore_idx_test =[]                   #list of indexes at which foreground image is present in a mosaic image                \n",
        "test_label=[]                # label of mosaic image = foreground class present in that mosaic\n",
        "for i in range(10000):\n",
        "  bg_idx = np.random.randint(0,35000,8)\n",
        "  fg_idx = np.random.randint(0,15000)\n",
        "  fg = np.random.randint(0,9)\n",
        "  fore_idx_test.append(fg)\n",
        "  image_list,label = create_mosaic_img(bg_idx,fg_idx,fg)\n",
        "  test_images.append(image_list)\n",
        "  test_label.append(label)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBzV9dKS5po7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = MosaicDataset(test_images,test_label,fore_idx_test)\n",
        "test_loader = DataLoader( test_data,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5g3geNJ5zEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion_focus = nn.CrossEntropyLoss()\n",
        "optimizer_focus = optim.SGD(focus_net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp2lv5U9nkhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col1=[]\n",
        "col2=[]\n",
        "col3=[]\n",
        "col4=[]\n",
        "col5=[]\n",
        "col6=[]\n",
        "col7=[]\n",
        "col8=[]\n",
        "col9=[]\n",
        "col10=[]\n",
        "col11=[]\n",
        "col12=[]\n",
        "col13=[]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b6_lir4nnb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "62c9ae01-2bd4-49fc-9f7c-fe1eafa8f97b"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      count += 1\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "print(count)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "col1.append(0)\n",
        "col2.append(argmax_more_than_half)\n",
        "col3.append(argmax_less_than_half)\n",
        "col4.append(focus_true_pred_true)\n",
        "col5.append(focus_false_pred_true)\n",
        "col6.append(focus_true_pred_false)\n",
        "col7.append(focus_false_pred_false)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 33 %\n",
            "total correct 9984\n",
            "total train set images 30000\n",
            "focus_true_pred_true 9984 =============> FTPT : 33 %\n",
            "focus_false_pred_true 0 =============> FFPT : 0 %\n",
            "focus_true_pred_false 20016 =============> FTPF : 66 %\n",
            "focus_false_pred_false 0 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  30000\n",
            "argmax_less_than_half ==================>  0\n",
            "30000\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r6xCSiSnnND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "253a7ab8-ac3e-4a91-f53b-a38aebeb04c5"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)\n",
        "col8.append(argmax_more_than_half)\n",
        "col9.append(argmax_less_than_half)\n",
        "col10.append(focus_true_pred_true)\n",
        "col11.append(focus_false_pred_true)\n",
        "col12.append(focus_true_pred_false)\n",
        "col13.append(focus_false_pred_false)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 32 %\n",
            "total correct 3274\n",
            "total train set images 10000\n",
            "focus_true_pred_true 3273 =============> FTPT : 32 %\n",
            "focus_false_pred_true 1 =============> FFPT : 0 %\n",
            "focus_true_pred_false 6724 =============> FTPF : 67 %\n",
            "focus_false_pred_false 2 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  9999\n",
            "argmax_less_than_half ==================>  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tFfAJZkcZEsY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be883725-64c7-4e17-c1e4-66c69905a070"
      },
      "source": [
        "nos_epochs = 50\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "\n",
        "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "  focus_true_pred_true =0\n",
        "  focus_false_pred_true =0\n",
        "  focus_true_pred_false =0\n",
        "  focus_false_pred_false =0\n",
        "  \n",
        "  argmax_more_than_half = 0\n",
        "  argmax_less_than_half =0\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  epoch_loss = []\n",
        "  cnt=0\n",
        "\n",
        "  iteration = desired_num // batch\n",
        "  \n",
        "  #training data set\n",
        "  \n",
        "  for i, data in  enumerate(train_loader):\n",
        "    inputs , labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    # zero the parameter gradients\n",
        "    \n",
        "    optimizer_focus.zero_grad()\n",
        "    \n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "#     print(outputs)\n",
        "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
        "\n",
        "    loss = criterion_focus(outputs, labels) \n",
        "    loss.backward()\n",
        "    optimizer_focus.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    mini = 60\n",
        "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
        "      epoch_loss.append(running_loss/mini)\n",
        "      running_loss = 0.0\n",
        "    cnt=cnt+1\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  if(np.mean(epoch_loss) <= 0.03):\n",
        "      break;\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    col1.append(epoch)\n",
        "    col2.append(argmax_more_than_half)\n",
        "    col3.append(argmax_less_than_half)\n",
        "    col4.append(focus_true_pred_true)\n",
        "    col5.append(focus_false_pred_true)\n",
        "    col6.append(focus_true_pred_false)\n",
        "    col7.append(focus_false_pred_false)\n",
        "  \n",
        "    #************************************************************************\n",
        "    #testing data set  \n",
        "    with torch.no_grad():\n",
        "      focus_true_pred_true =0\n",
        "      focus_false_pred_true =0\n",
        "      focus_true_pred_false =0\n",
        "      focus_false_pred_false =0\n",
        "\n",
        "      argmax_more_than_half = 0\n",
        "      argmax_less_than_half =0\n",
        "      for data in test_loader:\n",
        "        inputs, labels , fore_idx = data\n",
        "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "        alphas, avg_images = focus_net(inputs)\n",
        "        outputs = classify(avg_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range (batch):\n",
        "          focus = torch.argmax(alphas[j])\n",
        "\n",
        "          if(alphas[j][focus] >= 0.5):\n",
        "            argmax_more_than_half +=1\n",
        "          else:\n",
        "            argmax_less_than_half +=1\n",
        "\n",
        "          if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_true_pred_true += 1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "            focus_false_pred_true +=1\n",
        "\n",
        "          elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_true_pred_false +=1\n",
        "\n",
        "          elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "            focus_false_pred_false +=1\n",
        "      \n",
        "    col8.append(argmax_more_than_half)\n",
        "    col9.append(argmax_less_than_half)\n",
        "    col10.append(focus_true_pred_true)\n",
        "    col11.append(focus_false_pred_true)\n",
        "    col12.append(focus_true_pred_false)\n",
        "    col13.append(focus_false_pred_false)\n",
        "    \n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 1.128\n",
            "[1,   120] loss: 1.132\n",
            "[1,   180] loss: 1.130\n",
            "[1,   240] loss: 1.126\n",
            "[2,    60] loss: 1.127\n",
            "[2,   120] loss: 1.128\n",
            "[2,   180] loss: 1.130\n",
            "[2,   240] loss: 1.131\n",
            "[3,    60] loss: 1.128\n",
            "[3,   120] loss: 1.128\n",
            "[3,   180] loss: 1.131\n",
            "[3,   240] loss: 1.130\n",
            "[4,    60] loss: 1.124\n",
            "[4,   120] loss: 1.132\n",
            "[4,   180] loss: 1.130\n",
            "[4,   240] loss: 1.132\n",
            "[5,    60] loss: 1.127\n",
            "[5,   120] loss: 1.133\n",
            "[5,   180] loss: 1.127\n",
            "[5,   240] loss: 1.130\n",
            "[6,    60] loss: 1.129\n",
            "[6,   120] loss: 1.130\n",
            "[6,   180] loss: 1.130\n",
            "[6,   240] loss: 1.128\n",
            "[7,    60] loss: 1.132\n",
            "[7,   120] loss: 1.127\n",
            "[7,   180] loss: 1.129\n",
            "[7,   240] loss: 1.130\n",
            "[8,    60] loss: 1.131\n",
            "[8,   120] loss: 1.130\n",
            "[8,   180] loss: 1.124\n",
            "[8,   240] loss: 1.131\n",
            "[9,    60] loss: 1.129\n",
            "[9,   120] loss: 1.128\n",
            "[9,   180] loss: 1.131\n",
            "[9,   240] loss: 1.129\n",
            "[10,    60] loss: 1.127\n",
            "[10,   120] loss: 1.126\n",
            "[10,   180] loss: 1.135\n",
            "[10,   240] loss: 1.128\n",
            "[11,    60] loss: 1.128\n",
            "[11,   120] loss: 1.130\n",
            "[11,   180] loss: 1.132\n",
            "[11,   240] loss: 1.126\n",
            "[12,    60] loss: 1.126\n",
            "[12,   120] loss: 1.129\n",
            "[12,   180] loss: 1.132\n",
            "[12,   240] loss: 1.129\n",
            "[13,    60] loss: 1.134\n",
            "[13,   120] loss: 1.126\n",
            "[13,   180] loss: 1.130\n",
            "[13,   240] loss: 1.127\n",
            "[14,    60] loss: 1.127\n",
            "[14,   120] loss: 1.128\n",
            "[14,   180] loss: 1.127\n",
            "[14,   240] loss: 1.135\n",
            "[15,    60] loss: 1.131\n",
            "[15,   120] loss: 1.130\n",
            "[15,   180] loss: 1.126\n",
            "[15,   240] loss: 1.130\n",
            "[16,    60] loss: 1.131\n",
            "[16,   120] loss: 1.129\n",
            "[16,   180] loss: 1.127\n",
            "[16,   240] loss: 1.130\n",
            "[17,    60] loss: 1.133\n",
            "[17,   120] loss: 1.128\n",
            "[17,   180] loss: 1.129\n",
            "[17,   240] loss: 1.126\n",
            "[18,    60] loss: 1.130\n",
            "[18,   120] loss: 1.133\n",
            "[18,   180] loss: 1.125\n",
            "[18,   240] loss: 1.129\n",
            "[19,    60] loss: 1.124\n",
            "[19,   120] loss: 1.134\n",
            "[19,   180] loss: 1.128\n",
            "[19,   240] loss: 1.131\n",
            "[20,    60] loss: 1.127\n",
            "[20,   120] loss: 1.132\n",
            "[20,   180] loss: 1.128\n",
            "[20,   240] loss: 1.130\n",
            "[21,    60] loss: 1.127\n",
            "[21,   120] loss: 1.128\n",
            "[21,   180] loss: 1.129\n",
            "[21,   240] loss: 1.133\n",
            "[22,    60] loss: 1.132\n",
            "[22,   120] loss: 1.126\n",
            "[22,   180] loss: 1.126\n",
            "[22,   240] loss: 1.132\n",
            "[23,    60] loss: 1.132\n",
            "[23,   120] loss: 1.132\n",
            "[23,   180] loss: 1.123\n",
            "[23,   240] loss: 1.129\n",
            "[24,    60] loss: 1.125\n",
            "[24,   120] loss: 1.131\n",
            "[24,   180] loss: 1.128\n",
            "[24,   240] loss: 1.132\n",
            "[25,    60] loss: 1.132\n",
            "[25,   120] loss: 1.123\n",
            "[25,   180] loss: 1.126\n",
            "[25,   240] loss: 1.136\n",
            "[26,    60] loss: 1.131\n",
            "[26,   120] loss: 1.129\n",
            "[26,   180] loss: 1.122\n",
            "[26,   240] loss: 1.134\n",
            "[27,    60] loss: 1.130\n",
            "[27,   120] loss: 1.131\n",
            "[27,   180] loss: 1.132\n",
            "[27,   240] loss: 1.123\n",
            "[28,    60] loss: 1.130\n",
            "[28,   120] loss: 1.132\n",
            "[28,   180] loss: 1.129\n",
            "[28,   240] loss: 1.125\n",
            "[29,    60] loss: 1.128\n",
            "[29,   120] loss: 1.130\n",
            "[29,   180] loss: 1.128\n",
            "[29,   240] loss: 1.131\n",
            "[30,    60] loss: 1.130\n",
            "[30,   120] loss: 1.129\n",
            "[30,   180] loss: 1.128\n",
            "[30,   240] loss: 1.130\n",
            "[31,    60] loss: 1.128\n",
            "[31,   120] loss: 1.127\n",
            "[31,   180] loss: 1.132\n",
            "[31,   240] loss: 1.130\n",
            "[32,    60] loss: 1.130\n",
            "[32,   120] loss: 1.128\n",
            "[32,   180] loss: 1.128\n",
            "[32,   240] loss: 1.131\n",
            "[33,    60] loss: 1.131\n",
            "[33,   120] loss: 1.130\n",
            "[33,   180] loss: 1.127\n",
            "[33,   240] loss: 1.129\n",
            "[34,    60] loss: 1.131\n",
            "[34,   120] loss: 1.128\n",
            "[34,   180] loss: 1.130\n",
            "[34,   240] loss: 1.128\n",
            "[35,    60] loss: 1.129\n",
            "[35,   120] loss: 1.131\n",
            "[35,   180] loss: 1.130\n",
            "[35,   240] loss: 1.128\n",
            "[36,    60] loss: 1.126\n",
            "[36,   120] loss: 1.129\n",
            "[36,   180] loss: 1.129\n",
            "[36,   240] loss: 1.133\n",
            "[37,    60] loss: 1.131\n",
            "[37,   120] loss: 1.129\n",
            "[37,   180] loss: 1.127\n",
            "[37,   240] loss: 1.130\n",
            "[38,    60] loss: 1.130\n",
            "[38,   120] loss: 1.130\n",
            "[38,   180] loss: 1.128\n",
            "[38,   240] loss: 1.129\n",
            "[39,    60] loss: 1.128\n",
            "[39,   120] loss: 1.130\n",
            "[39,   180] loss: 1.127\n",
            "[39,   240] loss: 1.132\n",
            "[40,    60] loss: 1.126\n",
            "[40,   120] loss: 1.129\n",
            "[40,   180] loss: 1.128\n",
            "[40,   240] loss: 1.134\n",
            "[41,    60] loss: 1.130\n",
            "[41,   120] loss: 1.123\n",
            "[41,   180] loss: 1.130\n",
            "[41,   240] loss: 1.134\n",
            "[42,    60] loss: 1.129\n",
            "[42,   120] loss: 1.127\n",
            "[42,   180] loss: 1.131\n",
            "[42,   240] loss: 1.130\n",
            "[43,    60] loss: 1.129\n",
            "[43,   120] loss: 1.124\n",
            "[43,   180] loss: 1.133\n",
            "[43,   240] loss: 1.131\n",
            "[44,    60] loss: 1.132\n",
            "[44,   120] loss: 1.128\n",
            "[44,   180] loss: 1.130\n",
            "[44,   240] loss: 1.126\n",
            "[45,    60] loss: 1.132\n",
            "[45,   120] loss: 1.128\n",
            "[45,   180] loss: 1.125\n",
            "[45,   240] loss: 1.131\n",
            "[46,    60] loss: 1.126\n",
            "[46,   120] loss: 1.134\n",
            "[46,   180] loss: 1.127\n",
            "[46,   240] loss: 1.129\n",
            "[47,    60] loss: 1.128\n",
            "[47,   120] loss: 1.126\n",
            "[47,   180] loss: 1.132\n",
            "[47,   240] loss: 1.132\n",
            "[48,    60] loss: 1.128\n",
            "[48,   120] loss: 1.127\n",
            "[48,   180] loss: 1.132\n",
            "[48,   240] loss: 1.130\n",
            "[49,    60] loss: 1.130\n",
            "[49,   120] loss: 1.125\n",
            "[49,   180] loss: 1.135\n",
            "[49,   240] loss: 1.127\n",
            "[50,    60] loss: 1.129\n",
            "[50,   120] loss: 1.126\n",
            "[50,   180] loss: 1.130\n",
            "[50,   240] loss: 1.132\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urwhyQWLbXFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "465c7746-7a67-48eb-8700-565e526a452f"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params.requires_grad)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VToKa651tMtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7263624f-04a1-4769-9928-b2be8d669a13"
      },
      "source": [
        "for params in classify.parameters():\n",
        "  print(params)\n",
        "  break;"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.0156,  0.1159,  0.0410],\n",
            "          [-0.1563, -0.1572, -0.1408],\n",
            "          [-0.1151,  0.1371,  0.0656]],\n",
            "\n",
            "         [[ 0.0482, -0.0495, -0.1614],\n",
            "          [-0.1785, -0.1560,  0.0295],\n",
            "          [ 0.1733, -0.0512, -0.1101]],\n",
            "\n",
            "         [[-0.1752, -0.0922,  0.0216],\n",
            "          [ 0.1009, -0.1605, -0.0230],\n",
            "          [ 0.1828,  0.0740, -0.1501]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1835,  0.1559,  0.0706],\n",
            "          [ 0.0240, -0.0607, -0.0079],\n",
            "          [ 0.1309,  0.1401, -0.0030]],\n",
            "\n",
            "         [[ 0.0976,  0.0028, -0.1704],\n",
            "          [-0.0219, -0.0743, -0.1558],\n",
            "          [ 0.0786,  0.0969, -0.0716]],\n",
            "\n",
            "         [[-0.1034,  0.1893, -0.0273],\n",
            "          [-0.0317,  0.1182, -0.0102],\n",
            "          [ 0.0922, -0.0456, -0.0388]]],\n",
            "\n",
            "\n",
            "        [[[-0.1525, -0.0107, -0.1594],\n",
            "          [-0.0165, -0.0297,  0.0849],\n",
            "          [-0.1854, -0.1048,  0.0287]],\n",
            "\n",
            "         [[ 0.0820, -0.0330,  0.1505],\n",
            "          [-0.0193,  0.1298,  0.1412],\n",
            "          [-0.1885,  0.1099,  0.0713]],\n",
            "\n",
            "         [[-0.0696, -0.0180, -0.0397],\n",
            "          [-0.1065, -0.1760, -0.1626],\n",
            "          [ 0.0932,  0.1298, -0.1582]]],\n",
            "\n",
            "\n",
            "        [[[-0.1655,  0.0129,  0.0112],\n",
            "          [ 0.0632,  0.1445,  0.0918],\n",
            "          [-0.0033, -0.0952, -0.0882]],\n",
            "\n",
            "         [[ 0.1495,  0.0642,  0.0971],\n",
            "          [ 0.0344, -0.1380, -0.0613],\n",
            "          [-0.0776, -0.1490, -0.1411]],\n",
            "\n",
            "         [[-0.0518,  0.1250, -0.0349],\n",
            "          [-0.1415, -0.1777, -0.0529],\n",
            "          [ 0.0306,  0.0018,  0.0123]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0315,  0.1851, -0.0284],\n",
            "          [-0.1842, -0.1624,  0.0871],\n",
            "          [-0.0558,  0.1550, -0.0135]],\n",
            "\n",
            "         [[-0.1668, -0.0693, -0.0077],\n",
            "          [-0.1412, -0.0047, -0.0923],\n",
            "          [ 0.1048,  0.1649,  0.1669]],\n",
            "\n",
            "         [[-0.0663, -0.0182,  0.0987],\n",
            "          [-0.0161,  0.0186,  0.0146],\n",
            "          [ 0.1331,  0.1902,  0.0730]]],\n",
            "\n",
            "\n",
            "        [[[-0.0199,  0.0883, -0.1743],\n",
            "          [-0.0886,  0.1755, -0.0116],\n",
            "          [ 0.1657, -0.0474,  0.0350]],\n",
            "\n",
            "         [[ 0.0612,  0.1620, -0.1873],\n",
            "          [-0.0266, -0.0494,  0.1589],\n",
            "          [-0.1386,  0.1655,  0.1839]],\n",
            "\n",
            "         [[-0.1125,  0.0324,  0.0084],\n",
            "          [ 0.1219,  0.1416,  0.1689],\n",
            "          [ 0.1052,  0.0409,  0.1797]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1384, -0.0869,  0.0816],\n",
            "          [ 0.1772, -0.1604, -0.1237],\n",
            "          [ 0.1281,  0.1160,  0.1174]],\n",
            "\n",
            "         [[ 0.1491, -0.0515,  0.1312],\n",
            "          [ 0.1042, -0.0445, -0.0138],\n",
            "          [-0.1170, -0.0750,  0.1510]],\n",
            "\n",
            "         [[-0.0101, -0.0502, -0.0686],\n",
            "          [-0.0316,  0.0026, -0.0943],\n",
            "          [ 0.1259,  0.1583,  0.1369]]],\n",
            "\n",
            "\n",
            "        [[[-0.1884, -0.0295, -0.1406],\n",
            "          [ 0.0932,  0.0757,  0.1553],\n",
            "          [-0.0629, -0.1010, -0.0279]],\n",
            "\n",
            "         [[-0.1786, -0.1890, -0.0180],\n",
            "          [ 0.0517, -0.1706,  0.0613],\n",
            "          [ 0.0209, -0.1192, -0.1125]],\n",
            "\n",
            "         [[-0.0949, -0.0766,  0.1367],\n",
            "          [-0.0874,  0.0847,  0.1167],\n",
            "          [-0.1191, -0.0614,  0.0564]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0957,  0.0554, -0.0765],\n",
            "          [ 0.1606,  0.0348,  0.0745],\n",
            "          [ 0.0069,  0.1636,  0.1544]],\n",
            "\n",
            "         [[-0.0082,  0.0277,  0.0091],\n",
            "          [-0.0300,  0.1364,  0.1923],\n",
            "          [ 0.1719, -0.1033,  0.0112]],\n",
            "\n",
            "         [[-0.0248,  0.0031, -0.1885],\n",
            "          [-0.0515, -0.1492,  0.1894],\n",
            "          [-0.0094,  0.1157,  0.0780]]],\n",
            "\n",
            "\n",
            "        [[[-0.0639, -0.1186, -0.1712],\n",
            "          [ 0.1099, -0.0700, -0.1327],\n",
            "          [ 0.1128, -0.1402,  0.0697]],\n",
            "\n",
            "         [[ 0.0908,  0.0092,  0.1614],\n",
            "          [ 0.0273,  0.1293, -0.0143],\n",
            "          [-0.1789,  0.0474,  0.0549]],\n",
            "\n",
            "         [[-0.0154,  0.0255, -0.0249],\n",
            "          [-0.1686, -0.0578,  0.0906],\n",
            "          [-0.1409, -0.0493, -0.0598]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1327, -0.0552,  0.0719],\n",
            "          [ 0.1169,  0.1206, -0.0888],\n",
            "          [-0.1847, -0.0711, -0.0824]],\n",
            "\n",
            "         [[ 0.1505, -0.0359, -0.0636],\n",
            "          [-0.0425,  0.1068, -0.1349],\n",
            "          [ 0.1606,  0.0018, -0.1230]],\n",
            "\n",
            "         [[ 0.0555, -0.1460, -0.1906],\n",
            "          [ 0.1213, -0.0552,  0.1524],\n",
            "          [ 0.0677,  0.0160,  0.0833]]],\n",
            "\n",
            "\n",
            "        [[[-0.1309, -0.0228,  0.1652],\n",
            "          [ 0.0217,  0.1667,  0.0147],\n",
            "          [ 0.1179,  0.1445, -0.0148]],\n",
            "\n",
            "         [[-0.0993,  0.1020, -0.1564],\n",
            "          [ 0.0565,  0.0837,  0.1711],\n",
            "          [ 0.1319, -0.0688,  0.1647]],\n",
            "\n",
            "         [[ 0.1879, -0.0029,  0.0122],\n",
            "          [-0.0649,  0.1870,  0.1419],\n",
            "          [-0.1504,  0.1171, -0.1625]]],\n",
            "\n",
            "\n",
            "        [[[-0.0368, -0.1808, -0.1576],\n",
            "          [ 0.0072, -0.0401,  0.1415],\n",
            "          [-0.1737, -0.1856,  0.1323]],\n",
            "\n",
            "         [[-0.0663, -0.0723, -0.1185],\n",
            "          [ 0.0915,  0.1452,  0.0441],\n",
            "          [ 0.0802, -0.1466, -0.1460]],\n",
            "\n",
            "         [[-0.1115, -0.0251,  0.0483],\n",
            "          [-0.0822, -0.1408,  0.1835],\n",
            "          [ 0.0376, -0.0909, -0.0267]]],\n",
            "\n",
            "\n",
            "        [[[-0.0878,  0.0646, -0.1812],\n",
            "          [ 0.1650,  0.0965,  0.0693],\n",
            "          [-0.1484, -0.0651, -0.1263]],\n",
            "\n",
            "         [[-0.0509, -0.0951, -0.0142],\n",
            "          [ 0.0530, -0.1442,  0.0299],\n",
            "          [ 0.0840,  0.1304, -0.0735]],\n",
            "\n",
            "         [[ 0.1291,  0.0208, -0.1670],\n",
            "          [ 0.0518,  0.0964,  0.1552],\n",
            "          [-0.1410, -0.0946,  0.1140]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1685, -0.0363,  0.1153],\n",
            "          [-0.1923,  0.1411, -0.0956],\n",
            "          [-0.1019, -0.1701,  0.1425]],\n",
            "\n",
            "         [[ 0.0797, -0.0919,  0.0223],\n",
            "          [ 0.1460, -0.1455,  0.1324],\n",
            "          [-0.0794, -0.0233, -0.0388]],\n",
            "\n",
            "         [[-0.1091,  0.1767,  0.1660],\n",
            "          [-0.0909, -0.1251, -0.1592],\n",
            "          [-0.1838, -0.0522, -0.1426]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1144, -0.0257,  0.0602],\n",
            "          [ 0.0032,  0.1688,  0.0363],\n",
            "          [-0.1549,  0.0152,  0.1827]],\n",
            "\n",
            "         [[-0.1617, -0.0045,  0.0389],\n",
            "          [-0.0841,  0.0244,  0.0586],\n",
            "          [-0.1773, -0.0327, -0.0424]],\n",
            "\n",
            "         [[-0.1551,  0.0507, -0.0424],\n",
            "          [ 0.1841,  0.1769, -0.1480],\n",
            "          [-0.0035, -0.1767,  0.1169]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1841,  0.1798, -0.0084],\n",
            "          [-0.1695, -0.1048, -0.1317],\n",
            "          [-0.0003,  0.0691, -0.0389]],\n",
            "\n",
            "         [[-0.1433,  0.1551, -0.0366],\n",
            "          [ 0.1631,  0.1576,  0.1571],\n",
            "          [-0.1029, -0.0470, -0.1608]],\n",
            "\n",
            "         [[-0.1705,  0.0730,  0.1552],\n",
            "          [-0.0726, -0.0891, -0.0096],\n",
            "          [ 0.1312, -0.0471,  0.0587]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1116,  0.1525,  0.0747],\n",
            "          [-0.0680,  0.1072, -0.1389],\n",
            "          [ 0.0676, -0.0244,  0.1707]],\n",
            "\n",
            "         [[ 0.1171,  0.0466,  0.1583],\n",
            "          [ 0.0085, -0.0530,  0.1904],\n",
            "          [-0.0971, -0.1669,  0.1648]],\n",
            "\n",
            "         [[ 0.0267,  0.0379, -0.0461],\n",
            "          [-0.1814,  0.0189, -0.1121],\n",
            "          [-0.1600,  0.1492, -0.0961]]],\n",
            "\n",
            "\n",
            "        [[[-0.0617, -0.1437, -0.1508],\n",
            "          [ 0.1201,  0.1768, -0.0461],\n",
            "          [ 0.0982, -0.0291, -0.0947]],\n",
            "\n",
            "         [[-0.0974,  0.1554,  0.0408],\n",
            "          [ 0.0720, -0.0697, -0.0251],\n",
            "          [ 0.0322,  0.0936,  0.1644]],\n",
            "\n",
            "         [[-0.1664, -0.0883, -0.1066],\n",
            "          [-0.0579,  0.0544, -0.0924],\n",
            "          [-0.0889, -0.1760,  0.1256]]],\n",
            "\n",
            "\n",
            "        [[[-0.1477, -0.1690, -0.1853],\n",
            "          [-0.0386,  0.0114,  0.0280],\n",
            "          [ 0.0144, -0.0289,  0.1136]],\n",
            "\n",
            "         [[-0.1777, -0.1851,  0.1235],\n",
            "          [ 0.1006, -0.0616, -0.0994],\n",
            "          [ 0.0930, -0.0802, -0.0679]],\n",
            "\n",
            "         [[-0.0046, -0.0569,  0.0625],\n",
            "          [ 0.0597,  0.0650, -0.0592],\n",
            "          [ 0.1113, -0.1730, -0.0322]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0537,  0.1698,  0.0219],\n",
            "          [ 0.0959,  0.0354, -0.0264],\n",
            "          [-0.1671, -0.0129,  0.0860]],\n",
            "\n",
            "         [[ 0.1893,  0.1077,  0.0152],\n",
            "          [-0.1647, -0.1827, -0.0753],\n",
            "          [-0.0533,  0.1702, -0.0697]],\n",
            "\n",
            "         [[-0.0347,  0.1163, -0.0736],\n",
            "          [ 0.0152, -0.1779,  0.1586],\n",
            "          [ 0.1698,  0.0823,  0.0359]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0403,  0.1191,  0.0493],\n",
            "          [ 0.0266,  0.1087,  0.1331],\n",
            "          [-0.0191,  0.1472, -0.0047]],\n",
            "\n",
            "         [[ 0.1500, -0.0964,  0.0490],\n",
            "          [ 0.1823,  0.0187,  0.1151],\n",
            "          [ 0.0883, -0.0963, -0.1001]],\n",
            "\n",
            "         [[-0.0047,  0.1905, -0.0467],\n",
            "          [-0.0255,  0.0408,  0.0685],\n",
            "          [ 0.0553, -0.1425,  0.1278]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1058, -0.0152, -0.1273],\n",
            "          [-0.0741,  0.0596,  0.0062],\n",
            "          [-0.1505,  0.1628,  0.0253]],\n",
            "\n",
            "         [[-0.0942, -0.1393, -0.1552],\n",
            "          [-0.1547, -0.0705,  0.1388],\n",
            "          [-0.0107, -0.0527,  0.1119]],\n",
            "\n",
            "         [[ 0.0635,  0.0173,  0.0680],\n",
            "          [-0.0416,  0.1860,  0.0341],\n",
            "          [-0.1039,  0.0439,  0.0441]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1661, -0.0140,  0.0110],\n",
            "          [ 0.0052, -0.0717,  0.0538],\n",
            "          [ 0.0854,  0.0188,  0.0755]],\n",
            "\n",
            "         [[-0.0586, -0.0299,  0.0443],\n",
            "          [-0.0042,  0.0861,  0.1263],\n",
            "          [ 0.1624,  0.1545,  0.1235]],\n",
            "\n",
            "         [[ 0.1633, -0.0380, -0.0056],\n",
            "          [-0.0377, -0.1156, -0.0738],\n",
            "          [ 0.0627, -0.0864,  0.1396]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0924, -0.1090,  0.0501],\n",
            "          [ 0.1168,  0.0842,  0.1751],\n",
            "          [-0.1292,  0.0015,  0.1661]],\n",
            "\n",
            "         [[-0.0836, -0.1632,  0.1831],\n",
            "          [ 0.1052, -0.1005, -0.1397],\n",
            "          [ 0.0754, -0.0755,  0.1712]],\n",
            "\n",
            "         [[ 0.1536, -0.1792, -0.1187],\n",
            "          [-0.0611,  0.0760,  0.0775],\n",
            "          [-0.1140, -0.0431, -0.1458]]],\n",
            "\n",
            "\n",
            "        [[[-0.0232,  0.1835,  0.0745],\n",
            "          [ 0.1117, -0.0883, -0.1386],\n",
            "          [-0.1557,  0.1758, -0.0936]],\n",
            "\n",
            "         [[-0.0016, -0.0489, -0.1789],\n",
            "          [-0.0633, -0.0327, -0.0209],\n",
            "          [-0.0344, -0.1555,  0.1767]],\n",
            "\n",
            "         [[-0.0761, -0.1868, -0.1141],\n",
            "          [-0.1585,  0.0602, -0.0238],\n",
            "          [ 0.0859,  0.1493,  0.1338]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0246,  0.0528,  0.0173],\n",
            "          [-0.1369,  0.1246,  0.0543],\n",
            "          [-0.0981, -0.1195,  0.0366]],\n",
            "\n",
            "         [[ 0.0792, -0.0554,  0.0652],\n",
            "          [ 0.1514,  0.0854,  0.0888],\n",
            "          [-0.1700,  0.1094,  0.0109]],\n",
            "\n",
            "         [[-0.0795, -0.0438, -0.1501],\n",
            "          [ 0.0464,  0.0611, -0.1631],\n",
            "          [-0.0012, -0.0922, -0.1099]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0530,  0.1233,  0.0131],\n",
            "          [ 0.0589,  0.1036, -0.0108],\n",
            "          [-0.1690,  0.1131, -0.1043]],\n",
            "\n",
            "         [[ 0.0457, -0.0277,  0.0859],\n",
            "          [-0.0954, -0.0956,  0.1217],\n",
            "          [-0.0095, -0.1706, -0.0111]],\n",
            "\n",
            "         [[ 0.0052, -0.0206, -0.0942],\n",
            "          [ 0.1453, -0.0762, -0.0102],\n",
            "          [-0.0133, -0.0472, -0.0296]]],\n",
            "\n",
            "\n",
            "        [[[-0.0032,  0.1767, -0.1359],\n",
            "          [ 0.0095, -0.0147,  0.1706],\n",
            "          [ 0.0657, -0.0276,  0.0065]],\n",
            "\n",
            "         [[-0.1688,  0.0782,  0.0228],\n",
            "          [ 0.1471, -0.0263,  0.1305],\n",
            "          [ 0.1693, -0.1343,  0.1514]],\n",
            "\n",
            "         [[-0.0731, -0.0426,  0.1111],\n",
            "          [ 0.1197, -0.1028, -0.1659],\n",
            "          [ 0.1363,  0.0867,  0.0408]]],\n",
            "\n",
            "\n",
            "        [[[-0.1326, -0.1377, -0.1251],\n",
            "          [-0.1438,  0.0879,  0.0806],\n",
            "          [-0.1093, -0.0851,  0.0084]],\n",
            "\n",
            "         [[-0.1638,  0.0462, -0.0785],\n",
            "          [-0.1418, -0.0246,  0.1373],\n",
            "          [ 0.0300, -0.0012,  0.0693]],\n",
            "\n",
            "         [[ 0.0011, -0.0709, -0.0437],\n",
            "          [ 0.0789,  0.0093,  0.1753],\n",
            "          [-0.0658,  0.0923, -0.0706]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1880,  0.1886,  0.0199],\n",
            "          [-0.1486, -0.1509,  0.0211],\n",
            "          [ 0.1125,  0.1696, -0.0596]],\n",
            "\n",
            "         [[-0.1832, -0.1260, -0.0459],\n",
            "          [-0.1565,  0.0077, -0.1587],\n",
            "          [ 0.0859,  0.0331,  0.0812]],\n",
            "\n",
            "         [[ 0.1637,  0.0628, -0.1320],\n",
            "          [ 0.1461, -0.1573, -0.0135],\n",
            "          [ 0.0994,  0.1162,  0.1150]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1168,  0.1048,  0.1275],\n",
            "          [-0.1507, -0.1773, -0.1313],\n",
            "          [ 0.0992, -0.0936, -0.0489]],\n",
            "\n",
            "         [[-0.0222,  0.0873, -0.0327],\n",
            "          [-0.1858, -0.0051,  0.1830],\n",
            "          [ 0.1878, -0.0448,  0.1308]],\n",
            "\n",
            "         [[-0.1856, -0.1460,  0.1094],\n",
            "          [-0.1686,  0.0692,  0.0391],\n",
            "          [-0.1914, -0.1477,  0.1868]]]], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBkrx7vTnEJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"7_focus_pretrained_classify_random_train_focus\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5kPCVrwpM3b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54bbcb0f-8d8c-4eb4-a245-2bfa6d6e9a66"
      },
      "source": [
        "print(name)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7_focus_pretrained_classify_random_train_focus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIAJ3UZN8rPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(classify.state_dict(),\"/content/drive/My Drive/Research/Cheating_data/16_experiments_on_cnn_6_3_layers/\"+name+\".pt\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgQKXW-8MH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKphM888Y5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrWoEGXZ8cBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train[columns[0]] = col1\n",
        "df_train[columns[1]] = col2\n",
        "df_train[columns[2]] = col3\n",
        "df_train[columns[3]] = col4\n",
        "df_train[columns[4]] = col5\n",
        "df_train[columns[5]] = col6\n",
        "df_train[columns[6]] = col7\n",
        "\n",
        "df_test[columns[0]] = col1\n",
        "df_test[columns[1]] = col8\n",
        "df_test[columns[2]] = col9\n",
        "df_test[columns[3]] = col10\n",
        "df_test[columns[4]] = col11\n",
        "df_test[columns[5]] = col12\n",
        "df_test[columns[6]] = col13"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJoMFcK8eTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "346daaad-9d23-4b77-980d-361fa1f6b7f0"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9984</td>\n",
              "      <td>0</td>\n",
              "      <td>20016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9983</td>\n",
              "      <td>1</td>\n",
              "      <td>20014</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>29999</td>\n",
              "      <td>1</td>\n",
              "      <td>9982</td>\n",
              "      <td>2</td>\n",
              "      <td>20009</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>29999</td>\n",
              "      <td>1</td>\n",
              "      <td>9979</td>\n",
              "      <td>5</td>\n",
              "      <td>20014</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>29999</td>\n",
              "      <td>1</td>\n",
              "      <td>9983</td>\n",
              "      <td>1</td>\n",
              "      <td>20011</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20</td>\n",
              "      <td>29999</td>\n",
              "      <td>1</td>\n",
              "      <td>9983</td>\n",
              "      <td>1</td>\n",
              "      <td>20014</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>25</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9984</td>\n",
              "      <td>0</td>\n",
              "      <td>20013</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>30</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9981</td>\n",
              "      <td>3</td>\n",
              "      <td>20011</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>35</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9983</td>\n",
              "      <td>1</td>\n",
              "      <td>20012</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>40</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9982</td>\n",
              "      <td>2</td>\n",
              "      <td>20013</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>45</td>\n",
              "      <td>30000</td>\n",
              "      <td>0</td>\n",
              "      <td>9983</td>\n",
              "      <td>1</td>\n",
              "      <td>20015</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0         30000  ...                  20016                       0\n",
              "1        0         30000  ...                  20014                       2\n",
              "2        5         29999  ...                  20009                       7\n",
              "3       10         29999  ...                  20014                       2\n",
              "4       15         29999  ...                  20011                       5\n",
              "5       20         29999  ...                  20014                       2\n",
              "6       25         30000  ...                  20013                       3\n",
              "7       30         30000  ...                  20011                       5\n",
              "8       35         30000  ...                  20012                       4\n",
              "9       40         30000  ...                  20013                       3\n",
              "10      45         30000  ...                  20015                       1\n",
              "\n",
              "[11 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9HVQBZ8gn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "5360578c-9f39-4b38-9017-5ecdd590afe1"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col2, label='argmax > 0.5')\n",
        "plt.plot(col1,col3, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.title(\"On Training set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col4, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col5, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col6, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col7, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Training set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"training data\")\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKYVO8i8ivA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "6229052c-805f-4999-c749-058de7131394"
      },
      "source": [
        "df_test"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9999</td>\n",
              "      <td>1</td>\n",
              "      <td>3273</td>\n",
              "      <td>1</td>\n",
              "      <td>6724</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3274</td>\n",
              "      <td>0</td>\n",
              "      <td>6724</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3274</td>\n",
              "      <td>0</td>\n",
              "      <td>6724</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3274</td>\n",
              "      <td>0</td>\n",
              "      <td>6726</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3274</td>\n",
              "      <td>0</td>\n",
              "      <td>6725</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3274</td>\n",
              "      <td>0</td>\n",
              "      <td>6724</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>25</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3273</td>\n",
              "      <td>1</td>\n",
              "      <td>6724</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>30</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3274</td>\n",
              "      <td>0</td>\n",
              "      <td>6724</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>35</td>\n",
              "      <td>9999</td>\n",
              "      <td>1</td>\n",
              "      <td>3274</td>\n",
              "      <td>0</td>\n",
              "      <td>6724</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>40</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3273</td>\n",
              "      <td>1</td>\n",
              "      <td>6723</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>45</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>3274</td>\n",
              "      <td>0</td>\n",
              "      <td>6724</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0        0          9999  ...                   6724                       2\n",
              "1        0         10000  ...                   6724                       2\n",
              "2        5         10000  ...                   6724                       2\n",
              "3       10         10000  ...                   6726                       0\n",
              "4       15         10000  ...                   6725                       1\n",
              "5       20         10000  ...                   6724                       2\n",
              "6       25         10000  ...                   6724                       2\n",
              "7       30         10000  ...                   6724                       2\n",
              "8       35          9999  ...                   6724                       2\n",
              "9       40         10000  ...                   6723                       3\n",
              "10      45         10000  ...                   6724                       2\n",
              "\n",
              "[11 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRlpgnjy8k1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "488f77de-704e-4f9b-fb88-74823fc7eea4"
      },
      "source": [
        "# plt.figure(12,12)\n",
        "plt.plot(col1,col8, label='argmax > 0.5')\n",
        "plt.plot(col1,col9, label='argmax < 0.5')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(col1,col10, label =\"focus_true_pred_true \")\n",
        "plt.plot(col1,col11, label =\"focus_false_pred_true \")\n",
        "plt.plot(col1,col12, label =\"focus_true_pred_false \")\n",
        "plt.plot(col1,col13, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Testing set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Testing data\")\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ANVZc6AB6Sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "c2150f01-24c3-4fc7-9e67-e0a267b9826b"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 33 %\n",
            "total correct 9984\n",
            "total train set images 30000\n",
            "focus_true_pred_true 9983 =============> FTPT : 33 %\n",
            "focus_false_pred_true 1 =============> FFPT : 0 %\n",
            "focus_true_pred_false 20012 =============> FTPF : 66 %\n",
            "focus_false_pred_false 4 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  30000\n",
            "argmax_less_than_half ==================>  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIkxwKHWB9kn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "541d3c58-dadf-42ea-fecd-c1e14dcf187d"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "flag = 1\n",
        "focus_true_pred_true =0\n",
        "focus_false_pred_true =0\n",
        "focus_true_pred_false =0\n",
        "focus_false_pred_false =0\n",
        "\n",
        "argmax_more_than_half = 0\n",
        "argmax_less_than_half =0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels , fore_idx = inputs.to(\"cuda\"),labels.to(\"cuda\"), fore_idx.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    for j in range(labels.size(0)):\n",
        "      focus = torch.argmax(alphas[j])\n",
        "      if alphas[j][focus] >= 0.5 :\n",
        "        argmax_more_than_half += 1\n",
        "      else:\n",
        "        argmax_less_than_half += 1\n",
        "\n",
        "      if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "        focus_false_pred_true += 1\n",
        "      elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_true_pred_false += 1\n",
        "      elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "        focus_false_pred_false += 1\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)\n",
        "\n",
        "print(\"focus_true_pred_true %d =============> FTPT : %d %%\" % (focus_true_pred_true , (100 * focus_true_pred_true / total) ) )\n",
        "print(\"focus_false_pred_true %d =============> FFPT : %d %%\" % (focus_false_pred_true, (100 * focus_false_pred_true / total) ) )\n",
        "print(\"focus_true_pred_false %d =============> FTPF : %d %%\" %( focus_true_pred_false , ( 100 * focus_true_pred_false / total) ) )\n",
        "print(\"focus_false_pred_false %d =============> FFPF : %d %%\" % (focus_false_pred_false, ( 100 * focus_false_pred_false / total) ) )\n",
        "\n",
        "print(\"argmax_more_than_half ==================> \",argmax_more_than_half)\n",
        "print(\"argmax_less_than_half ==================> \",argmax_less_than_half)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 32 %\n",
            "total correct 3274\n",
            "total train set images 10000\n",
            "focus_true_pred_true 3274 =============> FTPT : 32 %\n",
            "focus_false_pred_true 0 =============> FFPT : 0 %\n",
            "focus_true_pred_false 6723 =============> FTPF : 67 %\n",
            "focus_false_pred_false 3 =============> FFPF : 0 %\n",
            "argmax_more_than_half ==================>  10000\n",
            "argmax_less_than_half ==================>  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJEMJnUI9FP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1fc9d749-bfa4-4928-a0c4-8b2b7019ca0d"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in train_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 30000 train images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 30000 train images: 33 %\n",
            "total correct 9984\n",
            "total train set images 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7qmNLB-Ilb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "18815e6a-8ed7-4877-b298-690a47806c98"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels , fore_idx = data\n",
        "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "    alphas, avg_images = focus_net(inputs)\n",
        "    outputs = classify(avg_images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total))\n",
        "print(\"total correct\", correct)\n",
        "print(\"total train set images\", total)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 32 %\n",
            "total correct 3274\n",
            "total train set images 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}