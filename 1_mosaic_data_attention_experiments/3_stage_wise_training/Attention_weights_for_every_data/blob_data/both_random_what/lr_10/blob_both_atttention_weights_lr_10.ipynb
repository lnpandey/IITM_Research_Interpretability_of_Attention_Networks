{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "blob_both_atttention_weights_lr_10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIyC9Ip_bcq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGVy-1EllAc_"
      },
      "source": [
        "train_data = np.load(\"train_blob_data.npy\",allow_pickle=True)\n",
        "\n",
        "test_data = np.load(\"test_blob_data.npy\",allow_pickle=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL771xuGZC5Q"
      },
      "source": [
        "mosaic_list_of_images = train_data[0][\"mosaic_list\"]\n",
        "mosaic_label = train_data[0][\"mosaic_label\"]\n",
        "fore_idx = train_data[0][\"fore_idx\"]\n",
        "\n",
        "\n",
        "test_mosaic_list_of_images = test_data[0][\"mosaic_list\"]\n",
        "test_mosaic_label = test_data[0][\"mosaic_label\"]\n",
        "test_fore_idx = test_data[0][\"fore_idx\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qfRXfNZCao"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf76JwkxZCT0"
      },
      "source": [
        "batch = 250\n",
        "train_dataset = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=False)\n",
        "test_dataset = MosaicDataset1(test_mosaic_list_of_images, test_mosaic_label, test_fore_idx)\n",
        "test_loader = DataLoader(test_dataset,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpZfj1bq7wN"
      },
      "source": [
        "bg = []\n",
        "for i in range(12):\n",
        "  torch.manual_seed(i)\n",
        "  betag = torch.randn(250,9)#torch.ones((250,9))/9\n",
        "  bg.append( betag.requires_grad_() )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzb3ii4drXpu",
        "outputId": "a57b12c3-75f9-4957-8359-59961341ff0c"
      },
      "source": [
        "bg"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-1.1258, -1.1524, -0.2506,  ..., -0.3160, -2.1152,  0.3223],\n",
              "         [-1.2633,  0.3500,  0.3081,  ..., -0.2473, -1.3527, -1.6959],\n",
              "         [ 0.5667,  0.7935,  0.5988,  ...,  0.7502, -0.5855, -0.1734],\n",
              "         ...,\n",
              "         [ 0.8374, -0.7942, -0.3622,  ...,  0.0121,  0.8032, -0.6962],\n",
              "         [-1.0645,  0.2384, -0.3385,  ...,  0.9635, -1.0340,  0.1894],\n",
              "         [ 0.8253,  1.1038, -1.2491,  ..., -0.5940, -1.7125,  0.3617]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.5256, -0.7502, -0.6540,  ..., -0.9798, -1.6091, -0.7121],\n",
              "         [ 0.3037, -0.7773, -0.2515,  ...,  0.4676, -0.6970, -1.1608],\n",
              "         [ 0.6995,  0.1991,  0.8657,  ...,  1.1017, -0.1759, -2.2456],\n",
              "         ...,\n",
              "         [-0.4302,  0.1508,  0.6937,  ...,  0.0314,  2.6645,  0.1189],\n",
              "         [ 1.4484, -0.0213, -1.3367,  ...,  0.6279, -1.4719, -1.0291],\n",
              "         [ 0.9081, -1.2433,  1.6062,  ..., -0.1177, -0.5548, -0.0595]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.0408,  0.9166, -1.3042,  ..., -1.0574, -0.1188, -0.9078],\n",
              "         [ 0.3452, -0.5713, -0.2351,  ..., -0.4327, -1.5071, -0.4586],\n",
              "         [-0.8480,  0.5266,  0.0299,  ...,  0.4640, -0.4986,  0.1289],\n",
              "         ...,\n",
              "         [ 1.5719,  1.0154, -2.1620,  ..., -1.0790,  1.5801, -1.6557],\n",
              "         [-1.1613,  0.3672, -0.3078,  ..., -1.2456, -0.1125,  0.6222],\n",
              "         [ 0.4521, -0.2505,  2.3728,  ..., -0.1377, -0.8815, -0.1671]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.0766,  0.3599, -0.7820,  ...,  1.6206, -1.5967, -0.0517],\n",
              "         [-0.3060,  0.2485, -0.2226,  ...,  0.4163,  0.2615,  0.9311],\n",
              "         [-0.5145, -1.6517,  1.0460,  ...,  0.5638,  2.2566,  1.8693],\n",
              "         ...,\n",
              "         [ 2.1181,  0.1464, -0.0447,  ...,  1.3816,  0.4975,  0.2814],\n",
              "         [-0.7639, -1.4938, -1.1430,  ...,  0.6355,  0.6700,  1.5335],\n",
              "         [-0.0191, -0.3568,  0.4536,  ..., -0.9493,  2.0439, -0.3827]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.9414,  1.2632, -0.1838,  ..., -2.6021,  0.6245, -0.8684],\n",
              "         [-0.2051,  0.3976,  0.6699,  ..., -2.1205,  1.5191, -0.6682],\n",
              "         [ 0.0031, -0.1535,  1.1396,  ..., -0.7588, -0.1853, -0.8558],\n",
              "         ...,\n",
              "         [ 1.6794, -0.5509,  0.4118,  ...,  0.9084, -0.8626, -0.6553],\n",
              "         [ 0.6058, -0.5888,  0.9448,  ...,  0.0072, -0.2579,  1.7659],\n",
              "         [-1.2965,  0.2970, -0.5833,  ...,  1.7838, -0.4794,  0.5579]],\n",
              "        requires_grad=True),\n",
              " tensor([[ 1.8423,  0.5189, -1.7119,  ..., -0.1307, -1.4374,  0.3908],\n",
              "         [-0.0190, -1.3527, -0.7308,  ..., -0.7823,  2.7799,  1.2220],\n",
              "         [-0.3364, -0.9651, -0.1297,  ..., -0.4374,  0.7792, -0.0583],\n",
              "         ...,\n",
              "         [ 0.6700, -0.5400,  0.2353,  ..., -1.0840, -0.6141, -0.0155],\n",
              "         [ 0.4779, -0.4648, -0.1366,  ...,  0.1162,  3.0351, -0.2885],\n",
              "         [-0.6777, -0.1373, -0.7330,  ...,  0.6185, -0.3036, -1.0850]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.2113,  0.6304, -1.4713,  ...,  0.3295,  0.3264, -0.4806],\n",
              "         [ 1.1032,  2.5485,  0.3006,  ..., -1.6279, -1.4801, -1.0631],\n",
              "         [ 0.3630,  0.3995,  0.1457,  ..., -1.3437,  0.8535,  0.8811],\n",
              "         ...,\n",
              "         [-0.5519,  0.2253,  0.4891,  ..., -0.0110, -0.6023, -0.7230],\n",
              "         [-1.1593, -0.6551,  1.6578,  ...,  0.4795, -1.3562,  0.2920],\n",
              "         [ 0.3474, -0.9874, -0.0130,  ...,  0.6061,  0.8639, -0.9552]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.8201,  0.3956,  0.8989,  ..., -0.6411, -0.8937,  0.9265],\n",
              "         [-0.5355, -1.1597, -0.4602,  ...,  1.0902, -1.5827, -0.3246],\n",
              "         [ 1.9264, -0.3300,  0.1984,  ..., -0.2093, -0.2153, -1.8157],\n",
              "         ...,\n",
              "         [-0.6910,  0.3328,  2.2102,  ..., -0.0383,  0.4400, -0.8350],\n",
              "         [-0.2194, -0.7611, -0.0921,  ..., -0.3143, -0.4196,  1.1570],\n",
              "         [-0.8934, -1.7705,  0.3805,  ...,  0.1963, -0.7307,  1.3581]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.1892,  1.3932,  2.1059,  ...,  2.1414,  0.1317, -0.6388],\n",
              "         [ 1.3384, -1.1908, -0.7601,  ..., -0.1051,  0.4414,  0.6590],\n",
              "         [-0.7585, -0.6001, -0.3948,  ..., -1.7526,  0.3920,  0.8295],\n",
              "         ...,\n",
              "         [-0.0557, -0.1032, -0.4624,  ..., -0.1339, -1.6662, -0.4955],\n",
              "         [ 1.0884, -0.4479, -0.0847,  ...,  1.7487, -1.6152, -1.8258],\n",
              "         [ 1.7062,  1.1041, -1.3736,  ..., -1.5244,  0.4869, -1.7420]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.0674, -0.7172,  1.0897,  ..., -0.7737, -2.4656,  0.9968],\n",
              "         [ 0.4524, -0.3464, -0.7245,  ...,  0.2331, -1.1433,  0.8289],\n",
              "         [ 0.9534,  0.2948,  1.5159,  ...,  0.3971,  0.4058, -0.5274],\n",
              "         ...,\n",
              "         [-0.3297, -0.3700,  1.9490,  ..., -0.0443,  1.8073, -0.6388],\n",
              "         [ 0.0977,  0.1862,  1.4303,  ..., -1.9735, -1.1663,  1.7066],\n",
              "         [-0.8396, -2.5271, -1.0791,  ...,  0.1053,  1.2463, -0.7709]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.8173, -0.5556, -0.8267,  ..., -0.5133,  2.6278, -0.7465],\n",
              "         [ 1.0051, -0.2568,  0.4765,  ..., -0.2496,  0.8298,  1.1209],\n",
              "         [ 0.9999,  1.1167,  1.0763,  ...,  0.0562,  0.2456,  0.9535],\n",
              "         ...,\n",
              "         [-1.0042, -0.7732,  0.9129,  ..., -0.4342,  1.3256, -0.6357],\n",
              "         [-0.5979,  1.2285,  1.0288,  ..., -1.4067,  0.2403,  0.5257],\n",
              "         [-1.7332, -0.2443,  0.1425,  ..., -0.9291,  1.4324, -0.2338]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.5108,  1.0283, -0.3532,  ...,  0.1421, -0.5243, -0.2487],\n",
              "         [-0.5252,  2.8922, -0.5947,  ..., -0.0080,  0.2479,  1.5727],\n",
              "         [-1.6395, -1.5925, -0.1546,  ..., -0.3935,  0.6171,  0.7528],\n",
              "         ...,\n",
              "         [-0.3538,  0.1294,  1.1873,  ..., -0.2866, -0.3111,  0.2674],\n",
              "         [ 1.7757, -0.1730,  0.6679,  ..., -0.2519,  0.8360, -0.4348],\n",
              "         [ 0.4242,  0.7649, -0.5807,  ..., -0.7654, -0.1086,  0.4636]],\n",
              "        requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrMidFCla6h"
      },
      "source": [
        "class Module2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Module2, self).__init__()\n",
        "    self.linear1 = nn.Linear(5,100)\n",
        "    self.linear2 = nn.Linear(100,3)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = self.linear2(x)\n",
        "    return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqj2VELllkX"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "what_net = Module2().double()\n",
        "\n",
        "#what_net.load_state_dict(torch.load(\"type4_what_net.pt\"))\n",
        "what_net = what_net.to(\"cuda\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d8Wch99l4yB"
      },
      "source": [
        "def attn_avg(x,beta):\n",
        "  y = torch.zeros([batch,5], dtype=torch.float64)\n",
        "  y = y.to(\"cuda\")\n",
        "  alpha = F.softmax(beta,dim=1)   # alphas\n",
        "  #print(alpha[0],x[0,:])\n",
        "  for i in range(9):            \n",
        "    alpha1 = alpha[:,i]      \n",
        "    y = y + torch.mul(alpha1[:,None],x[:,i])\n",
        "  return y,alpha\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz1Kpw12loV6"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,criter):\n",
        "  what.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  correct = 0\n",
        "  tot = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx= data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      beta = bg[i]  # beta for ith batch\n",
        "      inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "      avg,alpha = attn_avg(inputs,beta)\n",
        "      alpha = alpha.to(\"cuda\")\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += sum(predicted == labels)\n",
        "      tot += len(predicted)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis,correct.item(),tot,correct.item()/tot"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAY-x6UAwrwE"
      },
      "source": [
        "# for param in what_net.parameters():\n",
        "#     param.requires_grad = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_toCktPanH0S"
      },
      "source": [
        "\n",
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S633XgMToeN3"
      },
      "source": [
        "optim1 = []\n",
        "for i in range(12):\n",
        "  optim1.append(optim.RMSprop([bg[i]], lr=10))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPaYaojinMTA",
        "outputId": "f1fccba1-960d-4455-edee-7ccd4c6d9010"
      },
      "source": [
        "# instantiate optimizer\n",
        "optimizer_what = optim.RMSprop(what_net.parameters(), lr=0.001)#, momentum=0.9)#,nesterov=True)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "acti = []\n",
        "analysis_data_tr = []\n",
        "analysis_data_tst = []\n",
        "loss_curi_tr = []\n",
        "loss_curi_tst = []\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "# calculate zeroth epoch loss and FTPT values\n",
        "running_loss,anlys_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(0,running_loss,correct,total,accuracy)) \n",
        "loss_curi_tr.append(running_loss)\n",
        "analysis_data_tr.append(anlys_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training starts \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what_net.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_  = data\n",
        "    inputs = inputs.double()\n",
        "    beta = bg[i] # alpha for ith batch\n",
        "    #print(labels)\n",
        "    inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "        \n",
        "    # zero the parameter gradients\n",
        "    optimizer_what.zero_grad()\n",
        "    optim1[i].zero_grad()\n",
        "      \n",
        "    # forward + backward + optimize\n",
        "    avg,alpha = attn_avg(inputs,beta)\n",
        "    outputs = what_net(avg)     \n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    #alpha.retain_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer_what.step()\n",
        "    optim1[i].step()\n",
        "\n",
        "\n",
        "  running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "  analysis_data_tr.append(anls_data)\n",
        "  loss_curi_tr.append(running_loss_tr)   #loss per epoch\n",
        "  print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(epoch+1,running_loss_tr,correct,total,accuracy)) \n",
        "\n",
        "\n",
        "  \n",
        "  if running_loss_tr<=0.08:\n",
        "    break\n",
        "print('Finished Training run ')\n",
        "analysis_data_tr = np.array(analysis_data_tr)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training epoch: [0 ] loss: 1.759 correct: 935.000, total: 3000.000, accuracy: 0.312\n",
            "training epoch: [1 ] loss: 1.231 correct: 1260.000, total: 3000.000, accuracy: 0.420\n",
            "training epoch: [2 ] loss: 1.082 correct: 1545.000, total: 3000.000, accuracy: 0.515\n",
            "training epoch: [3 ] loss: 1.042 correct: 1727.000, total: 3000.000, accuracy: 0.576\n",
            "training epoch: [4 ] loss: 1.033 correct: 1718.000, total: 3000.000, accuracy: 0.573\n",
            "training epoch: [5 ] loss: 1.022 correct: 1717.000, total: 3000.000, accuracy: 0.572\n",
            "training epoch: [6 ] loss: 1.013 correct: 1718.000, total: 3000.000, accuracy: 0.573\n",
            "training epoch: [7 ] loss: 1.007 correct: 1731.000, total: 3000.000, accuracy: 0.577\n",
            "training epoch: [8 ] loss: 1.001 correct: 1738.000, total: 3000.000, accuracy: 0.579\n",
            "training epoch: [9 ] loss: 0.999 correct: 1741.000, total: 3000.000, accuracy: 0.580\n",
            "training epoch: [10 ] loss: 0.995 correct: 1744.000, total: 3000.000, accuracy: 0.581\n",
            "training epoch: [11 ] loss: 0.992 correct: 1748.000, total: 3000.000, accuracy: 0.583\n",
            "training epoch: [12 ] loss: 0.989 correct: 1756.000, total: 3000.000, accuracy: 0.585\n",
            "training epoch: [13 ] loss: 0.986 correct: 1765.000, total: 3000.000, accuracy: 0.588\n",
            "training epoch: [14 ] loss: 0.984 correct: 1772.000, total: 3000.000, accuracy: 0.591\n",
            "training epoch: [15 ] loss: 0.981 correct: 1784.000, total: 3000.000, accuracy: 0.595\n",
            "training epoch: [16 ] loss: 0.979 correct: 1785.000, total: 3000.000, accuracy: 0.595\n",
            "training epoch: [17 ] loss: 0.977 correct: 1791.000, total: 3000.000, accuracy: 0.597\n",
            "training epoch: [18 ] loss: 0.976 correct: 1792.000, total: 3000.000, accuracy: 0.597\n",
            "training epoch: [19 ] loss: 0.974 correct: 1799.000, total: 3000.000, accuracy: 0.600\n",
            "training epoch: [20 ] loss: 0.972 correct: 1802.000, total: 3000.000, accuracy: 0.601\n",
            "training epoch: [21 ] loss: 0.971 correct: 1803.000, total: 3000.000, accuracy: 0.601\n",
            "training epoch: [22 ] loss: 0.970 correct: 1808.000, total: 3000.000, accuracy: 0.603\n",
            "training epoch: [23 ] loss: 0.967 correct: 1807.000, total: 3000.000, accuracy: 0.602\n",
            "training epoch: [24 ] loss: 0.967 correct: 1818.000, total: 3000.000, accuracy: 0.606\n",
            "training epoch: [25 ] loss: 0.965 correct: 1820.000, total: 3000.000, accuracy: 0.607\n",
            "training epoch: [26 ] loss: 0.963 correct: 1820.000, total: 3000.000, accuracy: 0.607\n",
            "training epoch: [27 ] loss: 0.962 correct: 1828.000, total: 3000.000, accuracy: 0.609\n",
            "training epoch: [28 ] loss: 0.961 correct: 1832.000, total: 3000.000, accuracy: 0.611\n",
            "training epoch: [29 ] loss: 0.959 correct: 1834.000, total: 3000.000, accuracy: 0.611\n",
            "training epoch: [30 ] loss: 0.959 correct: 1831.000, total: 3000.000, accuracy: 0.610\n",
            "training epoch: [31 ] loss: 0.957 correct: 1835.000, total: 3000.000, accuracy: 0.612\n",
            "training epoch: [32 ] loss: 0.957 correct: 1837.000, total: 3000.000, accuracy: 0.612\n",
            "training epoch: [33 ] loss: 0.954 correct: 1837.000, total: 3000.000, accuracy: 0.612\n",
            "training epoch: [34 ] loss: 0.954 correct: 1840.000, total: 3000.000, accuracy: 0.613\n",
            "training epoch: [35 ] loss: 0.953 correct: 1844.000, total: 3000.000, accuracy: 0.615\n",
            "training epoch: [36 ] loss: 0.953 correct: 1844.000, total: 3000.000, accuracy: 0.615\n",
            "training epoch: [37 ] loss: 0.952 correct: 1843.000, total: 3000.000, accuracy: 0.614\n",
            "training epoch: [38 ] loss: 0.952 correct: 1842.000, total: 3000.000, accuracy: 0.614\n",
            "training epoch: [39 ] loss: 0.950 correct: 1847.000, total: 3000.000, accuracy: 0.616\n",
            "training epoch: [40 ] loss: 0.949 correct: 1852.000, total: 3000.000, accuracy: 0.617\n",
            "training epoch: [41 ] loss: 0.949 correct: 1851.000, total: 3000.000, accuracy: 0.617\n",
            "training epoch: [42 ] loss: 0.947 correct: 1849.000, total: 3000.000, accuracy: 0.616\n",
            "training epoch: [43 ] loss: 0.946 correct: 1852.000, total: 3000.000, accuracy: 0.617\n",
            "training epoch: [44 ] loss: 0.946 correct: 1853.000, total: 3000.000, accuracy: 0.618\n",
            "training epoch: [45 ] loss: 0.944 correct: 1855.000, total: 3000.000, accuracy: 0.618\n",
            "training epoch: [46 ] loss: 0.943 correct: 1858.000, total: 3000.000, accuracy: 0.619\n",
            "training epoch: [47 ] loss: 0.943 correct: 1860.000, total: 3000.000, accuracy: 0.620\n",
            "training epoch: [48 ] loss: 0.942 correct: 1858.000, total: 3000.000, accuracy: 0.619\n",
            "training epoch: [49 ] loss: 0.941 correct: 1863.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [50 ] loss: 0.941 correct: 1861.000, total: 3000.000, accuracy: 0.620\n",
            "training epoch: [51 ] loss: 0.940 correct: 1859.000, total: 3000.000, accuracy: 0.620\n",
            "training epoch: [52 ] loss: 0.939 correct: 1859.000, total: 3000.000, accuracy: 0.620\n",
            "training epoch: [53 ] loss: 0.938 correct: 1860.000, total: 3000.000, accuracy: 0.620\n",
            "training epoch: [54 ] loss: 0.938 correct: 1860.000, total: 3000.000, accuracy: 0.620\n",
            "training epoch: [55 ] loss: 0.937 correct: 1862.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [56 ] loss: 0.936 correct: 1862.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [57 ] loss: 0.936 correct: 1863.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [58 ] loss: 0.935 correct: 1864.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [59 ] loss: 0.935 correct: 1864.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [60 ] loss: 0.934 correct: 1860.000, total: 3000.000, accuracy: 0.620\n",
            "training epoch: [61 ] loss: 0.934 correct: 1860.000, total: 3000.000, accuracy: 0.620\n",
            "training epoch: [62 ] loss: 0.934 correct: 1860.000, total: 3000.000, accuracy: 0.620\n",
            "training epoch: [63 ] loss: 0.933 correct: 1864.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [64 ] loss: 0.933 correct: 1870.000, total: 3000.000, accuracy: 0.623\n",
            "training epoch: [65 ] loss: 0.932 correct: 1872.000, total: 3000.000, accuracy: 0.624\n",
            "training epoch: [66 ] loss: 0.932 correct: 1877.000, total: 3000.000, accuracy: 0.626\n",
            "training epoch: [67 ] loss: 0.931 correct: 1876.000, total: 3000.000, accuracy: 0.625\n",
            "training epoch: [68 ] loss: 0.931 correct: 1876.000, total: 3000.000, accuracy: 0.625\n",
            "training epoch: [69 ] loss: 0.931 correct: 1874.000, total: 3000.000, accuracy: 0.625\n",
            "training epoch: [70 ] loss: 0.930 correct: 1877.000, total: 3000.000, accuracy: 0.626\n",
            "training epoch: [71 ] loss: 0.929 correct: 1877.000, total: 3000.000, accuracy: 0.626\n",
            "training epoch: [72 ] loss: 0.928 correct: 1878.000, total: 3000.000, accuracy: 0.626\n",
            "training epoch: [73 ] loss: 0.925 correct: 1885.000, total: 3000.000, accuracy: 0.628\n",
            "training epoch: [74 ] loss: 0.924 correct: 1885.000, total: 3000.000, accuracy: 0.628\n",
            "training epoch: [75 ] loss: 0.924 correct: 1887.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [76 ] loss: 0.924 correct: 1887.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [77 ] loss: 0.923 correct: 1889.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [78 ] loss: 0.923 correct: 1890.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [79 ] loss: 0.922 correct: 1892.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [80 ] loss: 0.922 correct: 1892.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [81 ] loss: 0.921 correct: 1888.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [82 ] loss: 0.921 correct: 1888.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [83 ] loss: 0.921 correct: 1888.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [84 ] loss: 0.920 correct: 1889.000, total: 3000.000, accuracy: 0.630\n",
            "training epoch: [85 ] loss: 0.920 correct: 1888.000, total: 3000.000, accuracy: 0.629\n",
            "training epoch: [86 ] loss: 0.920 correct: 1893.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [87 ] loss: 0.919 correct: 1894.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [88 ] loss: 0.919 correct: 1894.000, total: 3000.000, accuracy: 0.631\n",
            "training epoch: [89 ] loss: 0.919 correct: 1896.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [90 ] loss: 0.919 correct: 1896.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [91 ] loss: 0.918 correct: 1898.000, total: 3000.000, accuracy: 0.633\n",
            "training epoch: [92 ] loss: 0.918 correct: 1900.000, total: 3000.000, accuracy: 0.633\n",
            "training epoch: [93 ] loss: 0.918 correct: 1899.000, total: 3000.000, accuracy: 0.633\n",
            "training epoch: [94 ] loss: 0.917 correct: 1897.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [95 ] loss: 0.917 correct: 1897.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [96 ] loss: 0.916 correct: 1896.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [97 ] loss: 0.916 correct: 1897.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [98 ] loss: 0.916 correct: 1897.000, total: 3000.000, accuracy: 0.632\n",
            "training epoch: [99 ] loss: 0.916 correct: 1902.000, total: 3000.000, accuracy: 0.634\n",
            "training epoch: [100 ] loss: 0.915 correct: 1902.000, total: 3000.000, accuracy: 0.634\n",
            "training epoch: [101 ] loss: 0.915 correct: 1903.000, total: 3000.000, accuracy: 0.634\n",
            "training epoch: [102 ] loss: 0.915 correct: 1903.000, total: 3000.000, accuracy: 0.634\n",
            "training epoch: [103 ] loss: 0.914 correct: 1905.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [104 ] loss: 0.914 correct: 1905.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [105 ] loss: 0.914 correct: 1905.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [106 ] loss: 0.914 correct: 1906.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [107 ] loss: 0.914 correct: 1905.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [108 ] loss: 0.913 correct: 1905.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [109 ] loss: 0.913 correct: 1905.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [110 ] loss: 0.913 correct: 1905.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [111 ] loss: 0.912 correct: 1906.000, total: 3000.000, accuracy: 0.635\n",
            "training epoch: [112 ] loss: 0.911 correct: 1907.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [113 ] loss: 0.911 correct: 1907.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [114 ] loss: 0.911 correct: 1909.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [115 ] loss: 0.911 correct: 1909.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [116 ] loss: 0.910 correct: 1907.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [117 ] loss: 0.910 correct: 1908.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [118 ] loss: 0.909 correct: 1908.000, total: 3000.000, accuracy: 0.636\n",
            "training epoch: [119 ] loss: 0.909 correct: 1910.000, total: 3000.000, accuracy: 0.637\n",
            "training epoch: [120 ] loss: 0.909 correct: 1910.000, total: 3000.000, accuracy: 0.637\n",
            "training epoch: [121 ] loss: 0.909 correct: 1911.000, total: 3000.000, accuracy: 0.637\n",
            "training epoch: [122 ] loss: 0.908 correct: 1910.000, total: 3000.000, accuracy: 0.637\n",
            "training epoch: [123 ] loss: 0.908 correct: 1910.000, total: 3000.000, accuracy: 0.637\n",
            "training epoch: [124 ] loss: 0.907 correct: 1913.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [125 ] loss: 0.907 correct: 1913.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [126 ] loss: 0.907 correct: 1913.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [127 ] loss: 0.906 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [128 ] loss: 0.906 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [129 ] loss: 0.906 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [130 ] loss: 0.906 correct: 1914.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [131 ] loss: 0.905 correct: 1915.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [132 ] loss: 0.905 correct: 1913.000, total: 3000.000, accuracy: 0.638\n",
            "training epoch: [133 ] loss: 0.905 correct: 1918.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [134 ] loss: 0.905 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [135 ] loss: 0.906 correct: 1917.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [136 ] loss: 0.905 correct: 1918.000, total: 3000.000, accuracy: 0.639\n",
            "training epoch: [137 ] loss: 0.903 correct: 1921.000, total: 3000.000, accuracy: 0.640\n",
            "training epoch: [138 ] loss: 0.903 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [139 ] loss: 0.902 correct: 1922.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [140 ] loss: 0.902 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [141 ] loss: 0.902 correct: 1928.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [142 ] loss: 0.901 correct: 1929.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [143 ] loss: 0.901 correct: 1928.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [144 ] loss: 0.901 correct: 1924.000, total: 3000.000, accuracy: 0.641\n",
            "training epoch: [145 ] loss: 0.900 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [146 ] loss: 0.900 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [147 ] loss: 0.900 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [148 ] loss: 0.900 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [149 ] loss: 0.898 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [150 ] loss: 0.898 correct: 1935.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [151 ] loss: 0.899 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [152 ] loss: 0.899 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [153 ] loss: 0.899 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [154 ] loss: 0.898 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [155 ] loss: 0.898 correct: 1928.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [156 ] loss: 0.898 correct: 1925.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [157 ] loss: 0.898 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [158 ] loss: 0.898 correct: 1926.000, total: 3000.000, accuracy: 0.642\n",
            "training epoch: [159 ] loss: 0.897 correct: 1930.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [160 ] loss: 0.897 correct: 1930.000, total: 3000.000, accuracy: 0.643\n",
            "training epoch: [161 ] loss: 0.897 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [162 ] loss: 0.897 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [163 ] loss: 0.896 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [164 ] loss: 0.896 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [165 ] loss: 0.896 correct: 1935.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [166 ] loss: 0.896 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [167 ] loss: 0.895 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [168 ] loss: 0.895 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [169 ] loss: 0.895 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [170 ] loss: 0.895 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [171 ] loss: 0.895 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [172 ] loss: 0.894 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [173 ] loss: 0.894 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [174 ] loss: 0.894 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [175 ] loss: 0.894 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [176 ] loss: 0.894 correct: 1931.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [177 ] loss: 0.893 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [178 ] loss: 0.893 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [179 ] loss: 0.893 correct: 1932.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [180 ] loss: 0.893 correct: 1933.000, total: 3000.000, accuracy: 0.644\n",
            "training epoch: [181 ] loss: 0.893 correct: 1936.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [182 ] loss: 0.892 correct: 1937.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [183 ] loss: 0.892 correct: 1938.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [184 ] loss: 0.891 correct: 1936.000, total: 3000.000, accuracy: 0.645\n",
            "training epoch: [185 ] loss: 0.891 correct: 1940.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [186 ] loss: 0.891 correct: 1939.000, total: 3000.000, accuracy: 0.646\n",
            "training epoch: [187 ] loss: 0.891 correct: 1940.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [188 ] loss: 0.890 correct: 1941.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [189 ] loss: 0.889 correct: 1942.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [190 ] loss: 0.890 correct: 1942.000, total: 3000.000, accuracy: 0.647\n",
            "training epoch: [191 ] loss: 0.889 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [192 ] loss: 0.889 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [193 ] loss: 0.889 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [194 ] loss: 0.889 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [195 ] loss: 0.889 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [196 ] loss: 0.888 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [197 ] loss: 0.888 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [198 ] loss: 0.888 correct: 1943.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [199 ] loss: 0.888 correct: 1944.000, total: 3000.000, accuracy: 0.648\n",
            "training epoch: [200 ] loss: 0.888 correct: 1946.000, total: 3000.000, accuracy: 0.649\n",
            "Finished Training run \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciJnAh5nfug"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train[columns[0]] = np.arange(0,epoch+2)\n",
        "df_train[columns[1]] = analysis_data_tr[:,-2]\n",
        "df_train[columns[2]] = analysis_data_tr[:,-1]\n",
        "df_train[columns[3]] = analysis_data_tr[:,0]\n",
        "df_train[columns[4]] = analysis_data_tr[:,1]\n",
        "df_train[columns[5]] = analysis_data_tr[:,2]\n",
        "df_train[columns[6]] = analysis_data_tr[:,3]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "NoQpS_6scRsC",
        "outputId": "c412d9b0-f029-49a7-9af2-8db9bb25dc73"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>302</td>\n",
              "      <td>2698</td>\n",
              "      <td>79</td>\n",
              "      <td>856</td>\n",
              "      <td>235</td>\n",
              "      <td>1830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1473</td>\n",
              "      <td>1527</td>\n",
              "      <td>140</td>\n",
              "      <td>1120</td>\n",
              "      <td>208</td>\n",
              "      <td>1532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2979</td>\n",
              "      <td>21</td>\n",
              "      <td>248</td>\n",
              "      <td>1297</td>\n",
              "      <td>207</td>\n",
              "      <td>1248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2999</td>\n",
              "      <td>1</td>\n",
              "      <td>257</td>\n",
              "      <td>1470</td>\n",
              "      <td>176</td>\n",
              "      <td>1097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>257</td>\n",
              "      <td>1461</td>\n",
              "      <td>175</td>\n",
              "      <td>1107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>365</td>\n",
              "      <td>1578</td>\n",
              "      <td>71</td>\n",
              "      <td>986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>197</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>365</td>\n",
              "      <td>1578</td>\n",
              "      <td>71</td>\n",
              "      <td>986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>198</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>365</td>\n",
              "      <td>1578</td>\n",
              "      <td>71</td>\n",
              "      <td>986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>199</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>365</td>\n",
              "      <td>1579</td>\n",
              "      <td>71</td>\n",
              "      <td>985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>200</td>\n",
              "      <td>3000</td>\n",
              "      <td>0</td>\n",
              "      <td>365</td>\n",
              "      <td>1581</td>\n",
              "      <td>71</td>\n",
              "      <td>983</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>201 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0         0           302  ...                    235                    1830\n",
              "1         1          1473  ...                    208                    1532\n",
              "2         2          2979  ...                    207                    1248\n",
              "3         3          2999  ...                    176                    1097\n",
              "4         4          3000  ...                    175                    1107\n",
              "..      ...           ...  ...                    ...                     ...\n",
              "196     196          3000  ...                     71                     986\n",
              "197     197          3000  ...                     71                     986\n",
              "198     198          3000  ...                     71                     986\n",
              "199     199          3000  ...                     71                     985\n",
              "200     200          3000  ...                     71                     983\n",
              "\n",
              "[201 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "IMAhRdxOcVf6",
        "outputId": "60bdc06a-6f25-4b04-febf-641567087c40"
      },
      "source": [
        "fig= plt.figure(figsize=(6,6))\n",
        "plt.plot(df_train[columns[0]],df_train[columns[3]]/30, label =\"focus_true_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[4]]/30, label =\"focus_false_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[5]]/30, label =\"focus_true_pred_false \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[6]]/30, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Train set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"percentage of data\")\n",
        "plt.xticks([0,50,100,150,200])\n",
        "#plt.vlines(vline_list,min(min(df_train[columns[3]]/300),min(df_train[columns[4]]/300),min(df_train[columns[5]]/300),min(df_train[columns[6]]/300)), max(max(df_train[columns[3]]/300),max(df_train[columns[4]]/300),max(df_train[columns[5]]/300),max(df_train[columns[6]]/300)),linestyles='dotted')\n",
        "plt.show()\n",
        "fig.savefig(\"train_analysis.pdf\")\n",
        "fig.savefig(\"train_analysis.png\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCnS6r2_3WdU"
      },
      "source": [
        "aph = []\n",
        "for i in bg:\n",
        "  aph.append(F.softmax(i,dim=1).detach().numpy())\n",
        "  \n",
        "aph = np.concatenate(aph,axis=0)\n",
        "torch.save({\n",
        "            'epoch': 500,\n",
        "            'model_state_dict': what_net.state_dict(),\n",
        "            #'optimizer_state_dict': optimizer_what.state_dict(),\n",
        "            \"optimizer_alpha\":optim1,\n",
        "            \"FTPT_analysis\":analysis_data_tr,\n",
        "            \"alpha\":aph\n",
        "\n",
        "            }, \"type4_what_net_500.pt\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVzrDOGS4UxU",
        "outputId": "f63db5b0-025e-4ba3-e8ed-458229e5360d"
      },
      "source": [
        "aph[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.4735847e-11, 0.0000000e+00, 4.4058926e-40, 6.5015285e-20,\n",
              "       1.0000000e+00, 0.0000000e+00, 6.0658651e-15, 9.4884427e-11,\n",
              "       0.0000000e+00], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwTDpx6STIPh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}