{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "blob_both_atttention_weights_lr_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIyC9Ip_bcq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGVy-1EllAc_"
      },
      "source": [
        "train_data = np.load(\"train_blob_data.npy\",allow_pickle=True)\n",
        "\n",
        "test_data = np.load(\"test_blob_data.npy\",allow_pickle=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL771xuGZC5Q"
      },
      "source": [
        "mosaic_list_of_images = train_data[0][\"mosaic_list\"]\n",
        "mosaic_label = train_data[0][\"mosaic_label\"]\n",
        "fore_idx = train_data[0][\"fore_idx\"]\n",
        "\n",
        "\n",
        "test_mosaic_list_of_images = test_data[0][\"mosaic_list\"]\n",
        "test_mosaic_label = test_data[0][\"mosaic_label\"]\n",
        "test_fore_idx = test_data[0][\"fore_idx\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2qfRXfNZCao"
      },
      "source": [
        "class MosaicDataset1(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list, mosaic_label,fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx] , self.fore_idx[idx]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf76JwkxZCT0"
      },
      "source": [
        "batch = 250\n",
        "train_dataset = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=False)\n",
        "test_dataset = MosaicDataset1(test_mosaic_list_of_images, test_mosaic_label, test_fore_idx)\n",
        "test_loader = DataLoader(test_dataset,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpZfj1bq7wN"
      },
      "source": [
        "bg = []\n",
        "for i in range(12):\n",
        "  torch.manual_seed(i)\n",
        "  betag = torch.randn(250,9)#torch.ones((250,9))/9\n",
        "  bg.append( betag.requires_grad_() )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzb3ii4drXpu",
        "outputId": "b0e1f31a-ef4b-4472-a841-f73f6202a5be"
      },
      "source": [
        "bg"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-1.1258, -1.1524, -0.2506,  ..., -0.3160, -2.1152,  0.3223],\n",
              "         [-1.2633,  0.3500,  0.3081,  ..., -0.2473, -1.3527, -1.6959],\n",
              "         [ 0.5667,  0.7935,  0.5988,  ...,  0.7502, -0.5855, -0.1734],\n",
              "         ...,\n",
              "         [ 0.8374, -0.7942, -0.3622,  ...,  0.0121,  0.8032, -0.6962],\n",
              "         [-1.0645,  0.2384, -0.3385,  ...,  0.9635, -1.0340,  0.1894],\n",
              "         [ 0.8253,  1.1038, -1.2491,  ..., -0.5940, -1.7125,  0.3617]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.5256, -0.7502, -0.6540,  ..., -0.9798, -1.6091, -0.7121],\n",
              "         [ 0.3037, -0.7773, -0.2515,  ...,  0.4676, -0.6970, -1.1608],\n",
              "         [ 0.6995,  0.1991,  0.8657,  ...,  1.1017, -0.1759, -2.2456],\n",
              "         ...,\n",
              "         [-0.4302,  0.1508,  0.6937,  ...,  0.0314,  2.6645,  0.1189],\n",
              "         [ 1.4484, -0.0213, -1.3367,  ...,  0.6279, -1.4719, -1.0291],\n",
              "         [ 0.9081, -1.2433,  1.6062,  ..., -0.1177, -0.5548, -0.0595]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.0408,  0.9166, -1.3042,  ..., -1.0574, -0.1188, -0.9078],\n",
              "         [ 0.3452, -0.5713, -0.2351,  ..., -0.4327, -1.5071, -0.4586],\n",
              "         [-0.8480,  0.5266,  0.0299,  ...,  0.4640, -0.4986,  0.1289],\n",
              "         ...,\n",
              "         [ 1.5719,  1.0154, -2.1620,  ..., -1.0790,  1.5801, -1.6557],\n",
              "         [-1.1613,  0.3672, -0.3078,  ..., -1.2456, -0.1125,  0.6222],\n",
              "         [ 0.4521, -0.2505,  2.3728,  ..., -0.1377, -0.8815, -0.1671]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.0766,  0.3599, -0.7820,  ...,  1.6206, -1.5967, -0.0517],\n",
              "         [-0.3060,  0.2485, -0.2226,  ...,  0.4163,  0.2615,  0.9311],\n",
              "         [-0.5145, -1.6517,  1.0460,  ...,  0.5638,  2.2566,  1.8693],\n",
              "         ...,\n",
              "         [ 2.1181,  0.1464, -0.0447,  ...,  1.3816,  0.4975,  0.2814],\n",
              "         [-0.7639, -1.4938, -1.1430,  ...,  0.6355,  0.6700,  1.5335],\n",
              "         [-0.0191, -0.3568,  0.4536,  ..., -0.9493,  2.0439, -0.3827]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.9414,  1.2632, -0.1838,  ..., -2.6021,  0.6245, -0.8684],\n",
              "         [-0.2051,  0.3976,  0.6699,  ..., -2.1205,  1.5191, -0.6682],\n",
              "         [ 0.0031, -0.1535,  1.1396,  ..., -0.7588, -0.1853, -0.8558],\n",
              "         ...,\n",
              "         [ 1.6794, -0.5509,  0.4118,  ...,  0.9084, -0.8626, -0.6553],\n",
              "         [ 0.6058, -0.5888,  0.9448,  ...,  0.0072, -0.2579,  1.7659],\n",
              "         [-1.2965,  0.2970, -0.5833,  ...,  1.7838, -0.4794,  0.5579]],\n",
              "        requires_grad=True),\n",
              " tensor([[ 1.8423,  0.5189, -1.7119,  ..., -0.1307, -1.4374,  0.3908],\n",
              "         [-0.0190, -1.3527, -0.7308,  ..., -0.7823,  2.7799,  1.2220],\n",
              "         [-0.3364, -0.9651, -0.1297,  ..., -0.4374,  0.7792, -0.0583],\n",
              "         ...,\n",
              "         [ 0.6700, -0.5400,  0.2353,  ..., -1.0840, -0.6141, -0.0155],\n",
              "         [ 0.4779, -0.4648, -0.1366,  ...,  0.1162,  3.0351, -0.2885],\n",
              "         [-0.6777, -0.1373, -0.7330,  ...,  0.6185, -0.3036, -1.0850]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.2113,  0.6304, -1.4713,  ...,  0.3295,  0.3264, -0.4806],\n",
              "         [ 1.1032,  2.5485,  0.3006,  ..., -1.6279, -1.4801, -1.0631],\n",
              "         [ 0.3630,  0.3995,  0.1457,  ..., -1.3437,  0.8535,  0.8811],\n",
              "         ...,\n",
              "         [-0.5519,  0.2253,  0.4891,  ..., -0.0110, -0.6023, -0.7230],\n",
              "         [-1.1593, -0.6551,  1.6578,  ...,  0.4795, -1.3562,  0.2920],\n",
              "         [ 0.3474, -0.9874, -0.0130,  ...,  0.6061,  0.8639, -0.9552]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.8201,  0.3956,  0.8989,  ..., -0.6411, -0.8937,  0.9265],\n",
              "         [-0.5355, -1.1597, -0.4602,  ...,  1.0902, -1.5827, -0.3246],\n",
              "         [ 1.9264, -0.3300,  0.1984,  ..., -0.2093, -0.2153, -1.8157],\n",
              "         ...,\n",
              "         [-0.6910,  0.3328,  2.2102,  ..., -0.0383,  0.4400, -0.8350],\n",
              "         [-0.2194, -0.7611, -0.0921,  ..., -0.3143, -0.4196,  1.1570],\n",
              "         [-0.8934, -1.7705,  0.3805,  ...,  0.1963, -0.7307,  1.3581]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.1892,  1.3932,  2.1059,  ...,  2.1414,  0.1317, -0.6388],\n",
              "         [ 1.3384, -1.1908, -0.7601,  ..., -0.1051,  0.4414,  0.6590],\n",
              "         [-0.7585, -0.6001, -0.3948,  ..., -1.7526,  0.3920,  0.8295],\n",
              "         ...,\n",
              "         [-0.0557, -0.1032, -0.4624,  ..., -0.1339, -1.6662, -0.4955],\n",
              "         [ 1.0884, -0.4479, -0.0847,  ...,  1.7487, -1.6152, -1.8258],\n",
              "         [ 1.7062,  1.1041, -1.3736,  ..., -1.5244,  0.4869, -1.7420]],\n",
              "        requires_grad=True),\n",
              " tensor([[-1.0674, -0.7172,  1.0897,  ..., -0.7737, -2.4656,  0.9968],\n",
              "         [ 0.4524, -0.3464, -0.7245,  ...,  0.2331, -1.1433,  0.8289],\n",
              "         [ 0.9534,  0.2948,  1.5159,  ...,  0.3971,  0.4058, -0.5274],\n",
              "         ...,\n",
              "         [-0.3297, -0.3700,  1.9490,  ..., -0.0443,  1.8073, -0.6388],\n",
              "         [ 0.0977,  0.1862,  1.4303,  ..., -1.9735, -1.1663,  1.7066],\n",
              "         [-0.8396, -2.5271, -1.0791,  ...,  0.1053,  1.2463, -0.7709]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.8173, -0.5556, -0.8267,  ..., -0.5133,  2.6278, -0.7465],\n",
              "         [ 1.0051, -0.2568,  0.4765,  ..., -0.2496,  0.8298,  1.1209],\n",
              "         [ 0.9999,  1.1167,  1.0763,  ...,  0.0562,  0.2456,  0.9535],\n",
              "         ...,\n",
              "         [-1.0042, -0.7732,  0.9129,  ..., -0.4342,  1.3256, -0.6357],\n",
              "         [-0.5979,  1.2285,  1.0288,  ..., -1.4067,  0.2403,  0.5257],\n",
              "         [-1.7332, -0.2443,  0.1425,  ..., -0.9291,  1.4324, -0.2338]],\n",
              "        requires_grad=True),\n",
              " tensor([[-0.5108,  1.0283, -0.3532,  ...,  0.1421, -0.5243, -0.2487],\n",
              "         [-0.5252,  2.8922, -0.5947,  ..., -0.0080,  0.2479,  1.5727],\n",
              "         [-1.6395, -1.5925, -0.1546,  ..., -0.3935,  0.6171,  0.7528],\n",
              "         ...,\n",
              "         [-0.3538,  0.1294,  1.1873,  ..., -0.2866, -0.3111,  0.2674],\n",
              "         [ 1.7757, -0.1730,  0.6679,  ..., -0.2519,  0.8360, -0.4348],\n",
              "         [ 0.4242,  0.7649, -0.5807,  ..., -0.7654, -0.1086,  0.4636]],\n",
              "        requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrMidFCla6h"
      },
      "source": [
        "class Module2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Module2, self).__init__()\n",
        "    self.linear1 = nn.Linear(5,100)\n",
        "    self.linear2 = nn.Linear(100,3)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = self.linear2(x)\n",
        "    return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqj2VELllkX"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "what_net = Module2().double()\n",
        "\n",
        "what_net.load_state_dict(torch.load(\"blob_what_net.pt\"))\n",
        "what_net = what_net.to(\"cuda\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d8Wch99l4yB"
      },
      "source": [
        "def attn_avg(x,beta):\n",
        "  y = torch.zeros([batch,5], dtype=torch.float64)\n",
        "  y = y.to(\"cuda\")\n",
        "  alpha = F.softmax(beta,dim=1)   # alphas\n",
        "  #print(alpha[0],x[0,:])\n",
        "  for i in range(9):            \n",
        "    alpha1 = alpha[:,i]      \n",
        "    y = y + torch.mul(alpha1[:,None],x[:,i])\n",
        "  return y,alpha\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz1Kpw12loV6"
      },
      "source": [
        "def calculate_attn_loss(dataloader,what,criter):\n",
        "  what.eval()\n",
        "  r_loss = 0\n",
        "  alphas = []\n",
        "  lbls = []\n",
        "  pred = []\n",
        "  fidices = []\n",
        "  correct = 0\n",
        "  tot = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "      inputs, labels,fidx= data\n",
        "      lbls.append(labels)\n",
        "      fidices.append(fidx)\n",
        "      inputs = inputs.double()\n",
        "      beta = bg[i]  # beta for ith batch\n",
        "      inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "      avg,alpha = attn_avg(inputs,beta)\n",
        "      alpha = alpha.to(\"cuda\")\n",
        "      outputs = what(avg)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += sum(predicted == labels)\n",
        "      tot += len(predicted)\n",
        "      pred.append(predicted.cpu().numpy())\n",
        "      alphas.append(alpha.cpu().numpy())\n",
        "      loss = criter(outputs, labels)\n",
        "      r_loss += loss.item()\n",
        "  alphas = np.concatenate(alphas,axis=0)\n",
        "  pred = np.concatenate(pred,axis=0)\n",
        "  lbls = np.concatenate(lbls,axis=0)\n",
        "  fidices = np.concatenate(fidices,axis=0)\n",
        "  #print(alphas.shape,pred.shape,lbls.shape,fidices.shape) \n",
        "  analysis = analyse_data(alphas,lbls,pred,fidices)\n",
        "  return r_loss/i,analysis,correct.item(),tot,correct.item()/tot"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAY-x6UAwrwE"
      },
      "source": [
        "# for param in what_net.parameters():\n",
        "#     param.requires_grad = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_toCktPanH0S"
      },
      "source": [
        "\n",
        "def analyse_data(alphas,lbls,predicted,f_idx):\n",
        "    '''\n",
        "       analysis data is created here\n",
        "    '''\n",
        "    batch = len(predicted)\n",
        "    amth,alth,ftpt,ffpt,ftpf,ffpf = 0,0,0,0,0,0\n",
        "    for j in range (batch):\n",
        "      focus = np.argmax(alphas[j])\n",
        "      if(alphas[j][focus] >= 0.5):\n",
        "        amth +=1\n",
        "      else:\n",
        "        alth +=1\n",
        "      if(focus == f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ftpt += 1\n",
        "      elif(focus != f_idx[j] and predicted[j] == lbls[j]):\n",
        "        ffpt +=1\n",
        "      elif(focus == f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ftpf +=1\n",
        "      elif(focus != f_idx[j] and predicted[j] != lbls[j]):\n",
        "        ffpf +=1\n",
        "    #print(sum(predicted==lbls),ftpt+ffpt)\n",
        "    return [ftpt,ffpt,ftpf,ffpf,amth,alth]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S633XgMToeN3"
      },
      "source": [
        "optim1 = []\n",
        "for i in range(12):\n",
        "  optim1.append(optim.RMSprop([bg[i]], lr=1))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPaYaojinMTA",
        "outputId": "dca8bd20-ff99-4ab0-84e5-b29b4c86b7c5"
      },
      "source": [
        "# instantiate optimizer\n",
        "optimizer_what = optim.RMSprop(what_net.parameters(), lr=0.001)#, momentum=0.9)#,nesterov=True)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "acti = []\n",
        "analysis_data_tr = []\n",
        "analysis_data_tst = []\n",
        "loss_curi_tr = []\n",
        "loss_curi_tst = []\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "# calculate zeroth epoch loss and FTPT values\n",
        "running_loss,anlys_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(0,running_loss,correct,total,accuracy)) \n",
        "loss_curi_tr.append(running_loss)\n",
        "analysis_data_tr.append(anlys_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training starts \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  what_net.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_  = data\n",
        "    inputs = inputs.double()\n",
        "    beta = bg[i] # alpha for ith batch\n",
        "    #print(labels)\n",
        "    inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "        \n",
        "    # zero the parameter gradients\n",
        "    optimizer_what.zero_grad()\n",
        "    optim1[i].zero_grad()\n",
        "      \n",
        "    # forward + backward + optimize\n",
        "    avg,alpha = attn_avg(inputs,beta)\n",
        "    outputs = what_net(avg)     \n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    #alpha.retain_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer_what.step()\n",
        "    optim1[i].step()\n",
        "\n",
        "\n",
        "  running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,what_net,criterion)\n",
        "  analysis_data_tr.append(anls_data)\n",
        "  loss_curi_tr.append(running_loss_tr)   #loss per epoch\n",
        "  print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(epoch+1,running_loss_tr,correct,total,accuracy)) \n",
        "\n",
        "\n",
        "  \n",
        "  if running_loss_tr<=0.08:\n",
        "    break\n",
        "print('Finished Training run ')\n",
        "analysis_data_tr = np.array(analysis_data_tr)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training epoch: [0 ] loss: 12.050 correct: 1071.000, total: 3000.000, accuracy: 0.357\n",
            "training epoch: [1 ] loss: 2.314 correct: 1864.000, total: 3000.000, accuracy: 0.621\n",
            "training epoch: [2 ] loss: 1.086 correct: 2445.000, total: 3000.000, accuracy: 0.815\n",
            "training epoch: [3 ] loss: 0.666 correct: 2616.000, total: 3000.000, accuracy: 0.872\n",
            "training epoch: [4 ] loss: 0.530 correct: 2659.000, total: 3000.000, accuracy: 0.886\n",
            "training epoch: [5 ] loss: 0.459 correct: 2696.000, total: 3000.000, accuracy: 0.899\n",
            "training epoch: [6 ] loss: 0.399 correct: 2708.000, total: 3000.000, accuracy: 0.903\n",
            "training epoch: [7 ] loss: 0.370 correct: 2721.000, total: 3000.000, accuracy: 0.907\n",
            "training epoch: [8 ] loss: 0.341 correct: 2727.000, total: 3000.000, accuracy: 0.909\n",
            "training epoch: [9 ] loss: 0.329 correct: 2728.000, total: 3000.000, accuracy: 0.909\n",
            "training epoch: [10 ] loss: 0.326 correct: 2730.000, total: 3000.000, accuracy: 0.910\n",
            "training epoch: [11 ] loss: 0.319 correct: 2738.000, total: 3000.000, accuracy: 0.913\n",
            "training epoch: [12 ] loss: 0.321 correct: 2733.000, total: 3000.000, accuracy: 0.911\n",
            "training epoch: [13 ] loss: 0.311 correct: 2733.000, total: 3000.000, accuracy: 0.911\n",
            "training epoch: [14 ] loss: 0.295 correct: 2747.000, total: 3000.000, accuracy: 0.916\n",
            "training epoch: [15 ] loss: 0.296 correct: 2747.000, total: 3000.000, accuracy: 0.916\n",
            "training epoch: [16 ] loss: 0.286 correct: 2750.000, total: 3000.000, accuracy: 0.917\n",
            "training epoch: [17 ] loss: 0.285 correct: 2745.000, total: 3000.000, accuracy: 0.915\n",
            "training epoch: [18 ] loss: 0.288 correct: 2748.000, total: 3000.000, accuracy: 0.916\n",
            "training epoch: [19 ] loss: 0.286 correct: 2748.000, total: 3000.000, accuracy: 0.916\n",
            "training epoch: [20 ] loss: 0.288 correct: 2748.000, total: 3000.000, accuracy: 0.916\n",
            "training epoch: [21 ] loss: 0.282 correct: 2752.000, total: 3000.000, accuracy: 0.917\n",
            "training epoch: [22 ] loss: 0.273 correct: 2749.000, total: 3000.000, accuracy: 0.916\n",
            "training epoch: [23 ] loss: 0.270 correct: 2754.000, total: 3000.000, accuracy: 0.918\n",
            "training epoch: [24 ] loss: 0.269 correct: 2751.000, total: 3000.000, accuracy: 0.917\n",
            "training epoch: [25 ] loss: 0.272 correct: 2752.000, total: 3000.000, accuracy: 0.917\n",
            "training epoch: [26 ] loss: 0.271 correct: 2751.000, total: 3000.000, accuracy: 0.917\n",
            "training epoch: [27 ] loss: 0.271 correct: 2753.000, total: 3000.000, accuracy: 0.918\n",
            "training epoch: [28 ] loss: 0.267 correct: 2760.000, total: 3000.000, accuracy: 0.920\n",
            "training epoch: [29 ] loss: 0.267 correct: 2760.000, total: 3000.000, accuracy: 0.920\n",
            "training epoch: [30 ] loss: 0.267 correct: 2759.000, total: 3000.000, accuracy: 0.920\n",
            "training epoch: [31 ] loss: 0.267 correct: 2752.000, total: 3000.000, accuracy: 0.917\n",
            "training epoch: [32 ] loss: 0.265 correct: 2759.000, total: 3000.000, accuracy: 0.920\n",
            "training epoch: [33 ] loss: 0.267 correct: 2751.000, total: 3000.000, accuracy: 0.917\n",
            "training epoch: [34 ] loss: 0.259 correct: 2758.000, total: 3000.000, accuracy: 0.919\n",
            "training epoch: [35 ] loss: 0.257 correct: 2753.000, total: 3000.000, accuracy: 0.918\n",
            "training epoch: [36 ] loss: 0.255 correct: 2764.000, total: 3000.000, accuracy: 0.921\n",
            "training epoch: [37 ] loss: 0.254 correct: 2765.000, total: 3000.000, accuracy: 0.922\n",
            "training epoch: [38 ] loss: 0.256 correct: 2771.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [39 ] loss: 0.261 correct: 2767.000, total: 3000.000, accuracy: 0.922\n",
            "training epoch: [40 ] loss: 0.250 correct: 2767.000, total: 3000.000, accuracy: 0.922\n",
            "training epoch: [41 ] loss: 0.251 correct: 2771.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [42 ] loss: 0.257 correct: 2769.000, total: 3000.000, accuracy: 0.923\n",
            "training epoch: [43 ] loss: 0.260 correct: 2766.000, total: 3000.000, accuracy: 0.922\n",
            "training epoch: [44 ] loss: 0.252 correct: 2772.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [45 ] loss: 0.249 correct: 2775.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [46 ] loss: 0.251 correct: 2773.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [47 ] loss: 0.251 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [48 ] loss: 0.249 correct: 2772.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [49 ] loss: 0.250 correct: 2773.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [50 ] loss: 0.247 correct: 2775.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [51 ] loss: 0.244 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [52 ] loss: 0.244 correct: 2774.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [53 ] loss: 0.243 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [54 ] loss: 0.243 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [55 ] loss: 0.248 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [56 ] loss: 0.249 correct: 2773.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [57 ] loss: 0.248 correct: 2773.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [58 ] loss: 0.241 correct: 2774.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [59 ] loss: 0.246 correct: 2773.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [60 ] loss: 0.246 correct: 2774.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [61 ] loss: 0.247 correct: 2772.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [62 ] loss: 0.246 correct: 2774.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [63 ] loss: 0.244 correct: 2775.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [64 ] loss: 0.237 correct: 2775.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [65 ] loss: 0.244 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [66 ] loss: 0.243 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [67 ] loss: 0.236 correct: 2775.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [68 ] loss: 0.236 correct: 2775.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [69 ] loss: 0.236 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [70 ] loss: 0.237 correct: 2775.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [71 ] loss: 0.236 correct: 2774.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [72 ] loss: 0.235 correct: 2773.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [73 ] loss: 0.231 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [74 ] loss: 0.235 correct: 2773.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [75 ] loss: 0.237 correct: 2778.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [76 ] loss: 0.238 correct: 2778.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [77 ] loss: 0.240 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [78 ] loss: 0.236 correct: 2783.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [79 ] loss: 0.235 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [80 ] loss: 0.235 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [81 ] loss: 0.235 correct: 2783.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [82 ] loss: 0.234 correct: 2780.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [83 ] loss: 0.238 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [84 ] loss: 0.231 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [85 ] loss: 0.237 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [86 ] loss: 0.235 correct: 2781.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [87 ] loss: 0.234 correct: 2781.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [88 ] loss: 0.234 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [89 ] loss: 0.232 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [90 ] loss: 0.231 correct: 2774.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [91 ] loss: 0.231 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [92 ] loss: 0.230 correct: 2778.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [93 ] loss: 0.233 correct: 2773.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [94 ] loss: 0.227 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [95 ] loss: 0.232 correct: 2769.000, total: 3000.000, accuracy: 0.923\n",
            "training epoch: [96 ] loss: 0.232 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [97 ] loss: 0.232 correct: 2774.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [98 ] loss: 0.236 correct: 2771.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [99 ] loss: 0.229 correct: 2778.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [100 ] loss: 0.231 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [101 ] loss: 0.229 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [102 ] loss: 0.231 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [103 ] loss: 0.231 correct: 2775.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [104 ] loss: 0.228 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [105 ] loss: 0.231 correct: 2774.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [106 ] loss: 0.233 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [107 ] loss: 0.223 correct: 2781.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [108 ] loss: 0.225 correct: 2780.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [109 ] loss: 0.226 correct: 2774.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [110 ] loss: 0.228 correct: 2773.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [111 ] loss: 0.227 correct: 2772.000, total: 3000.000, accuracy: 0.924\n",
            "training epoch: [112 ] loss: 0.232 correct: 2767.000, total: 3000.000, accuracy: 0.922\n",
            "training epoch: [113 ] loss: 0.225 correct: 2775.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [114 ] loss: 0.227 correct: 2774.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [115 ] loss: 0.227 correct: 2775.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [116 ] loss: 0.225 correct: 2775.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [117 ] loss: 0.227 correct: 2778.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [118 ] loss: 0.227 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [119 ] loss: 0.226 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [120 ] loss: 0.225 correct: 2781.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [121 ] loss: 0.224 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [122 ] loss: 0.222 correct: 2778.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [123 ] loss: 0.221 correct: 2783.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [124 ] loss: 0.221 correct: 2776.000, total: 3000.000, accuracy: 0.925\n",
            "training epoch: [125 ] loss: 0.225 correct: 2781.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [126 ] loss: 0.225 correct: 2777.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [127 ] loss: 0.223 correct: 2778.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [128 ] loss: 0.222 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [129 ] loss: 0.219 correct: 2780.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [130 ] loss: 0.219 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [131 ] loss: 0.223 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [132 ] loss: 0.222 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [133 ] loss: 0.222 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [134 ] loss: 0.223 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [135 ] loss: 0.222 correct: 2783.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [136 ] loss: 0.220 correct: 2781.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [137 ] loss: 0.222 correct: 2784.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [138 ] loss: 0.221 correct: 2781.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [139 ] loss: 0.218 correct: 2781.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [140 ] loss: 0.221 correct: 2783.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [141 ] loss: 0.221 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [142 ] loss: 0.219 correct: 2784.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [143 ] loss: 0.216 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [144 ] loss: 0.216 correct: 2783.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [145 ] loss: 0.216 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [146 ] loss: 0.215 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [147 ] loss: 0.215 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [148 ] loss: 0.215 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [149 ] loss: 0.214 correct: 2784.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [150 ] loss: 0.212 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [151 ] loss: 0.214 correct: 2788.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [152 ] loss: 0.213 correct: 2790.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [153 ] loss: 0.213 correct: 2789.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [154 ] loss: 0.214 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [155 ] loss: 0.213 correct: 2785.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [156 ] loss: 0.213 correct: 2785.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [157 ] loss: 0.212 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [158 ] loss: 0.214 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [159 ] loss: 0.215 correct: 2789.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [160 ] loss: 0.213 correct: 2785.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [161 ] loss: 0.213 correct: 2784.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [162 ] loss: 0.213 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [163 ] loss: 0.213 correct: 2785.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [164 ] loss: 0.216 correct: 2785.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [165 ] loss: 0.217 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [166 ] loss: 0.215 correct: 2789.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [167 ] loss: 0.215 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [168 ] loss: 0.216 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [169 ] loss: 0.215 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [170 ] loss: 0.215 correct: 2788.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [171 ] loss: 0.215 correct: 2788.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [172 ] loss: 0.215 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [173 ] loss: 0.216 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [174 ] loss: 0.214 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [175 ] loss: 0.215 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [176 ] loss: 0.215 correct: 2791.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [177 ] loss: 0.216 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [178 ] loss: 0.217 correct: 2785.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [179 ] loss: 0.216 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [180 ] loss: 0.217 correct: 2781.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [181 ] loss: 0.216 correct: 2785.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [182 ] loss: 0.215 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [183 ] loss: 0.217 correct: 2779.000, total: 3000.000, accuracy: 0.926\n",
            "training epoch: [184 ] loss: 0.216 correct: 2782.000, total: 3000.000, accuracy: 0.927\n",
            "training epoch: [185 ] loss: 0.213 correct: 2790.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [186 ] loss: 0.215 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [187 ] loss: 0.215 correct: 2788.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [188 ] loss: 0.214 correct: 2790.000, total: 3000.000, accuracy: 0.930\n",
            "training epoch: [189 ] loss: 0.214 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [190 ] loss: 0.215 correct: 2788.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [191 ] loss: 0.215 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [192 ] loss: 0.214 correct: 2784.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [193 ] loss: 0.215 correct: 2785.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [194 ] loss: 0.215 correct: 2784.000, total: 3000.000, accuracy: 0.928\n",
            "training epoch: [195 ] loss: 0.217 correct: 2787.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [196 ] loss: 0.215 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [197 ] loss: 0.213 correct: 2792.000, total: 3000.000, accuracy: 0.931\n",
            "training epoch: [198 ] loss: 0.213 correct: 2786.000, total: 3000.000, accuracy: 0.929\n",
            "training epoch: [199 ] loss: 0.211 correct: 2794.000, total: 3000.000, accuracy: 0.931\n",
            "training epoch: [200 ] loss: 0.212 correct: 2792.000, total: 3000.000, accuracy: 0.931\n",
            "Finished Training run \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciJnAh5nfug"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train[columns[0]] = np.arange(0,epoch+2)\n",
        "df_train[columns[1]] = analysis_data_tr[:,-2]\n",
        "df_train[columns[2]] = analysis_data_tr[:,-1]\n",
        "df_train[columns[3]] = analysis_data_tr[:,0]\n",
        "df_train[columns[4]] = analysis_data_tr[:,1]\n",
        "df_train[columns[5]] = analysis_data_tr[:,2]\n",
        "df_train[columns[6]] = analysis_data_tr[:,3]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "NoQpS_6scRsC",
        "outputId": "b6796c0f-f185-401a-fa63-0966d52612a2"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>302</td>\n",
              "      <td>2698</td>\n",
              "      <td>135</td>\n",
              "      <td>936</td>\n",
              "      <td>179</td>\n",
              "      <td>1750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1264</td>\n",
              "      <td>1736</td>\n",
              "      <td>283</td>\n",
              "      <td>1581</td>\n",
              "      <td>172</td>\n",
              "      <td>964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2239</td>\n",
              "      <td>761</td>\n",
              "      <td>561</td>\n",
              "      <td>1884</td>\n",
              "      <td>44</td>\n",
              "      <td>511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2366</td>\n",
              "      <td>634</td>\n",
              "      <td>662</td>\n",
              "      <td>1954</td>\n",
              "      <td>28</td>\n",
              "      <td>356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2405</td>\n",
              "      <td>595</td>\n",
              "      <td>706</td>\n",
              "      <td>1953</td>\n",
              "      <td>27</td>\n",
              "      <td>314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>2686</td>\n",
              "      <td>314</td>\n",
              "      <td>876</td>\n",
              "      <td>1910</td>\n",
              "      <td>6</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>197</td>\n",
              "      <td>2691</td>\n",
              "      <td>309</td>\n",
              "      <td>877</td>\n",
              "      <td>1915</td>\n",
              "      <td>6</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>198</td>\n",
              "      <td>2690</td>\n",
              "      <td>310</td>\n",
              "      <td>878</td>\n",
              "      <td>1908</td>\n",
              "      <td>6</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>199</td>\n",
              "      <td>2690</td>\n",
              "      <td>310</td>\n",
              "      <td>877</td>\n",
              "      <td>1917</td>\n",
              "      <td>6</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>200</td>\n",
              "      <td>2696</td>\n",
              "      <td>304</td>\n",
              "      <td>877</td>\n",
              "      <td>1915</td>\n",
              "      <td>6</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>201 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0         0           302  ...                    179                    1750\n",
              "1         1          1264  ...                    172                     964\n",
              "2         2          2239  ...                     44                     511\n",
              "3         3          2366  ...                     28                     356\n",
              "4         4          2405  ...                     27                     314\n",
              "..      ...           ...  ...                    ...                     ...\n",
              "196     196          2686  ...                      6                     208\n",
              "197     197          2691  ...                      6                     202\n",
              "198     198          2690  ...                      6                     208\n",
              "199     199          2690  ...                      6                     200\n",
              "200     200          2696  ...                      6                     202\n",
              "\n",
              "[201 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "IMAhRdxOcVf6",
        "outputId": "cbecd071-481f-4210-e820-9962a032fcfe"
      },
      "source": [
        "fig= plt.figure(figsize=(6,6))\n",
        "plt.plot(df_train[columns[0]],df_train[columns[3]]/30, label =\"focus_true_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[4]]/30, label =\"focus_false_pred_true \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[5]]/30, label =\"focus_true_pred_false \")\n",
        "plt.plot(df_train[columns[0]],df_train[columns[6]]/30, label =\"focus_false_pred_false \")\n",
        "plt.title(\"On Train set\")\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"percentage of data\")\n",
        "plt.xticks([0,50,100,150,200])\n",
        "#plt.vlines(vline_list,min(min(df_train[columns[3]]/300),min(df_train[columns[4]]/300),min(df_train[columns[5]]/300),min(df_train[columns[6]]/300)), max(max(df_train[columns[3]]/300),max(df_train[columns[4]]/300),max(df_train[columns[5]]/300),max(df_train[columns[6]]/300)),linestyles='dotted')\n",
        "plt.show()\n",
        "fig.savefig(\"train_analysis.pdf\")\n",
        "fig.savefig(\"train_analysis.png\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCnS6r2_3WdU"
      },
      "source": [
        "aph = []\n",
        "for i in bg:\n",
        "  aph.append(F.softmax(i,dim=1).detach().numpy())\n",
        "  \n",
        "aph = np.concatenate(aph,axis=0)\n",
        "torch.save({\n",
        "            'epoch': 500,\n",
        "            'model_state_dict': what_net.state_dict(),\n",
        "            #'optimizer_state_dict': optimizer_what.state_dict(),\n",
        "            \"optimizer_alpha\":optim1,\n",
        "            \"FTPT_analysis\":analysis_data_tr,\n",
        "            \"alpha\":aph\n",
        "\n",
        "            }, \"type4_what_net_500.pt\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVzrDOGS4UxU",
        "outputId": "b8ad5415-3b51-4817-9a04-6cd94220d42f"
      },
      "source": [
        "aph[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.32141507e-08, 1.35936725e-05, 1.47228696e-09, 3.02196739e-17,\n",
              "       1.08838513e-16, 5.69787717e-10, 3.41521898e-17, 5.62035477e-18,\n",
              "       9.99986410e-01], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwTDpx6STIPh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}