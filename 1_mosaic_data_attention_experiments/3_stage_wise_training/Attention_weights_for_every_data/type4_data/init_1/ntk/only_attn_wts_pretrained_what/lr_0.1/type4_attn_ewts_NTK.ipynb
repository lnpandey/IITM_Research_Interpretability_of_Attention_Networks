{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "type4_attn_ewts_NTK.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pI7PJ8XATdT",
        "outputId": "b6d7193e-2de8-4ae2-9592-850ad022f085"
      },
      "source": [
        "/from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9qVDQd_BBqS",
        "outputId": "a5428dbf-409d-493c-bc90-67049872b05b"
      },
      "source": [
        "%cd /content/drive/MyDrive/Neural_Tangent_Kernel/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Neural_Tangent_Kernel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIyC9Ip_bcq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "from myrmsprop import MyRmsprop\n",
        "from utils import plot_decision_boundary,attn_avg,plot_analysis\n",
        "from synthetic_dataset import MosaicDataset1\n",
        "from eval_model import calculate_attn_loss,analyse_data\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGVy-1EllAc_"
      },
      "source": [
        "train_data = np.load(\"train_type4_data.npy\",allow_pickle=True)\n",
        "\n",
        "test_data = np.load(\"test_type4_data.npy\",allow_pickle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL771xuGZC5Q"
      },
      "source": [
        "mosaic_list_of_images = train_data[0][\"mosaic_list\"]\n",
        "mosaic_label = train_data[0][\"mosaic_label\"]\n",
        "fore_idx = train_data[0][\"fore_idx\"]\n",
        "\n",
        "\n",
        "test_mosaic_list_of_images = test_data[0][\"mosaic_list\"]\n",
        "test_mosaic_label = test_data[0][\"mosaic_label\"]\n",
        "test_fore_idx = test_data[0][\"fore_idx\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf76JwkxZCT0"
      },
      "source": [
        "batch = 3000\n",
        "train_dataset = MosaicDataset1(mosaic_list_of_images, mosaic_label, fore_idx)\n",
        "train_loader = DataLoader( train_dataset,batch_size= batch ,shuffle=False)\n",
        "#batch = 2000\n",
        "#test_dataset = MosaicDataset1(test_mosaic_list_of_images, test_mosaic_label, test_fore_idx)\n",
        "#test_loader = DataLoader(test_dataset,batch_size= batch ,shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-Lv8nHoB8z-"
      },
      "source": [
        "# NTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmGjlMfTBp3F"
      },
      "source": [
        "data = np.load(\"NTK_1.npy\",allow_pickle=True)\n",
        "# H = data[0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beyk_-qYB_Ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe0a3db-3af6-4455-b7a3-e0fc9c0b9358"
      },
      "source": [
        "print(data[0].keys())\n",
        "H = torch.tensor(data[0][\"NTK\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['NTK'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ULTAsyF6G6a"
      },
      "source": [
        "lr_1 = 1/1470559.2\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnqbuxdO2U4j"
      },
      "source": [
        "# p_vec = nn.utils.parameters_to_vector(where_func.parameters())\n",
        "# p, = p_vec.shape\n",
        "# n_m, n_obj,_ = inputs.shape  # number of mosaic images x number of objects in each mosaic  x d\n",
        "# # this is the transpose jacobian (grad y(w))^T)\n",
        "# features = torch.zeros(n_m*n_obj, p, requires_grad=False)\n",
        " \n",
        "# k = 0 \n",
        "\n",
        "\n",
        "# for i in range(27000):\n",
        "#     out = where_func(inpp[i])\n",
        "#     where_func.zero_grad()\n",
        "#     out.backward(retain_graph=False)\n",
        "#     p_grad = torch.tensor([], requires_grad=False)\n",
        "#     for p in where_func.parameters():\n",
        "#       p_grad = torch.cat((p_grad, p.grad.reshape(-1)))\n",
        "#     features[k,:] = p_grad\n",
        "#     k = k+1\n",
        "# tangent_kernel =  features@features.T"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SInPc5gk9XDH"
      },
      "source": [
        "# class Module1(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super(Module1, self).__init__()\n",
        "#     self.linear1 = nn.Linear(2,100)\n",
        "#     self.linear2 = nn.Linear(100,1)\n",
        "\n",
        "#   def forward(self,x):\n",
        "#     x = F.relu(self.linear1(x))\n",
        "#     x = self.linear2(x)\n",
        "#     return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW0lzy6i9wk0"
      },
      "source": [
        "# from tqdm import tqdm as tqdm"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cti_LAbE8-dn"
      },
      "source": [
        "# inputs,_,_ = iter(train_loader).next()\n",
        "# inputs = torch.reshape(inputs,(27000,2))\n",
        "# inputs = (inputs - torch.mean(inputs,dim=0,keepdims=True) )/torch.std(inputs,dim=0,keepdims=True)\n",
        "# where_net = Module1()\n",
        "# outputs = where_net(inputs)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-03FnsNP5bk"
      },
      "source": [
        "# feature1 = torch.zeros((27000,200))\n",
        "# feature2  = torch.zeros((27000,100))\n",
        "# for i in tqdm(range(27000)):\n",
        "#   where_net.zero_grad()\n",
        "#   outputs[i].backward(retain_graph=True)\n",
        "#   par = []\n",
        "#   j = 0\n",
        "#   for p in where_net.parameters():\n",
        "#     if j%2 == 0:\n",
        "#       vec = torch.nn.utils.parameters_to_vector(p)\n",
        "#       p_grad = p.grad.reshape(-1)\n",
        "#       par.append(p_grad)\n",
        "#     j = j+1\n",
        "#   feature1[i,:] = par[0]\n",
        "#   feature2[i,:] = par[1]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI20WxiR-zCi"
      },
      "source": [
        "# H = feature1@feature1.T + feature2@feature2.T"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWIBQfQly25h"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrMidFCla6h"
      },
      "source": [
        "class Module2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Module2, self).__init__()\n",
        "    self.linear1 = nn.Linear(2,100)\n",
        "    self.linear2 = nn.Linear(100,3)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = self.linear2(x)\n",
        "    return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXpnLkMoCocj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af99edcb-ab09-4a4a-c9b4-7197aef83c84"
      },
      "source": [
        "print(H)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[75.1031, 35.6146, 79.1224,  ..., 63.2880, 38.2985, 72.4251],\n",
            "        [35.6146, 21.1840, 42.9770,  ..., 33.6579, 25.0675, 44.2191],\n",
            "        [79.1224, 42.9770, 92.8314,  ..., 73.0225, 48.9726, 88.7758],\n",
            "        ...,\n",
            "        [63.2880, 33.6579, 73.0225,  ..., 58.0862, 38.0167, 69.3583],\n",
            "        [38.2985, 25.0675, 48.9726,  ..., 38.0167, 34.9229, 54.7437],\n",
            "        [72.4251, 44.2191, 88.7758,  ..., 69.3583, 54.7437, 95.1200]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRDhoG3rEp_w"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqj2VELllkX"
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "what_net = Module2().double()\n",
        "\n",
        "what_net.load_state_dict(torch.load(\"type4_what_net.pt\"))\n",
        "what_net = what_net.to(\"cuda\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc1pKMEVfhat"
      },
      "source": [
        "for param in what_net.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpZfj1bq7wN"
      },
      "source": [
        "n_batches = 3000//batch\n",
        "bg = []\n",
        "for i in range(n_batches):\n",
        "  torch.manual_seed(i)\n",
        "  betag = torch.randn(3000,9)#torch.ones((250,9))/9\n",
        "  bg.append( betag.requires_grad_() )"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76PwzSMACDDj"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S633XgMToeN3"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lrDkUUaDFCR"
      },
      "source": [
        "optim1 = []\n",
        "H= H.to(\"cpu\")\n",
        "for i in range(n_batches):\n",
        "  optim1.append(MyRmsprop([bg[i]],H=H,lr=0.1))\n",
        "# instantiate what net optimizer\n",
        "#optimizer_what = optim.RMSprop(what_net.parameters(), lr=0.0001)#, momentum=0.9)#,nesterov=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPaYaojinMTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1536de73-fc1f-4783-fd6a-6be139870829"
      },
      "source": [
        "\n",
        "acti = []\n",
        "analysis_data_tr = []\n",
        "analysis_data_tst = []\n",
        "loss_curi_tr = []\n",
        "loss_curi_tst = []\n",
        "epochs = 2500\n",
        "\n",
        "\n",
        "# calculate zeroth epoch loss and FTPT values\n",
        "running_loss,anlys_data,correct,total,accuracy = calculate_attn_loss(train_loader,bg,what_net,criterion)\n",
        "print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(0,running_loss,correct,total,accuracy)) \n",
        "loss_curi_tr.append(running_loss)\n",
        "analysis_data_tr.append(anlys_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training starts \n",
        "for epoch in range(epochs): # loop over the dataset multiple times\n",
        "  ep_lossi = []\n",
        "  running_loss = 0.0\n",
        "  #what_net.train()\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels,_  = data\n",
        "    inputs = inputs.double()\n",
        "    beta = bg[i] # alpha for ith batch\n",
        "    #print(labels)\n",
        "    inputs, labels,beta = inputs.to(\"cuda\"),labels.to(\"cuda\"),beta.to(\"cuda\")\n",
        "        \n",
        "    # zero the parameter gradients\n",
        "    #optimizer_what.zero_grad()\n",
        "    optim1[i].zero_grad()\n",
        "      \n",
        "    # forward + backward + optimize\n",
        "    avg,alpha = attn_avg(inputs,beta)\n",
        "    outputs = what_net(avg)     \n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    #alpha.retain_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    #optimizer_what.step()\n",
        "    optim1[i].step()\n",
        "\n",
        "\n",
        "  running_loss_tr,anls_data,correct,total,accuracy = calculate_attn_loss(train_loader,bg,what_net,criterion)\n",
        "  analysis_data_tr.append(anls_data)\n",
        "  loss_curi_tr.append(running_loss_tr)   #loss per epoch\n",
        "  print('training epoch: [%d ] loss: %.3f correct: %.3f, total: %.3f, accuracy: %.3f' %(epoch+1,running_loss_tr,correct,total,accuracy)) \n",
        "\n",
        "\n",
        "  \n",
        "  if running_loss_tr<=0.08:\n",
        "    break\n",
        "print('Finished Training run ')\n",
        "analysis_data_tr = np.array(analysis_data_tr)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training epoch: [0 ] loss: 10.201 correct: 1133.000, total: 3000.000, accuracy: 0.378\n",
            "training epoch: [1 ] loss: 14.079 correct: 1086.000, total: 3000.000, accuracy: 0.362\n",
            "training epoch: [2 ] loss: 7.695 correct: 1153.000, total: 3000.000, accuracy: 0.384\n",
            "training epoch: [3 ] loss: 6.700 correct: 1197.000, total: 3000.000, accuracy: 0.399\n",
            "training epoch: [4 ] loss: 5.774 correct: 1254.000, total: 3000.000, accuracy: 0.418\n",
            "training epoch: [5 ] loss: 5.448 correct: 1273.000, total: 3000.000, accuracy: 0.424\n",
            "training epoch: [6 ] loss: 5.207 correct: 1275.000, total: 3000.000, accuracy: 0.425\n",
            "training epoch: [7 ] loss: 5.037 correct: 1286.000, total: 3000.000, accuracy: 0.429\n",
            "training epoch: [8 ] loss: 4.905 correct: 1292.000, total: 3000.000, accuracy: 0.431\n",
            "training epoch: [9 ] loss: 4.809 correct: 1294.000, total: 3000.000, accuracy: 0.431\n",
            "training epoch: [10 ] loss: 4.736 correct: 1292.000, total: 3000.000, accuracy: 0.431\n",
            "training epoch: [11 ] loss: 4.682 correct: 1295.000, total: 3000.000, accuracy: 0.432\n",
            "training epoch: [12 ] loss: 4.639 correct: 1300.000, total: 3000.000, accuracy: 0.433\n",
            "training epoch: [13 ] loss: 4.605 correct: 1301.000, total: 3000.000, accuracy: 0.434\n",
            "training epoch: [14 ] loss: 4.580 correct: 1304.000, total: 3000.000, accuracy: 0.435\n",
            "training epoch: [15 ] loss: 4.560 correct: 1306.000, total: 3000.000, accuracy: 0.435\n",
            "training epoch: [16 ] loss: 4.544 correct: 1312.000, total: 3000.000, accuracy: 0.437\n",
            "training epoch: [17 ] loss: 4.528 correct: 1315.000, total: 3000.000, accuracy: 0.438\n",
            "training epoch: [18 ] loss: 4.514 correct: 1316.000, total: 3000.000, accuracy: 0.439\n",
            "training epoch: [19 ] loss: 4.501 correct: 1318.000, total: 3000.000, accuracy: 0.439\n",
            "training epoch: [20 ] loss: 4.488 correct: 1320.000, total: 3000.000, accuracy: 0.440\n",
            "training epoch: [21 ] loss: 4.477 correct: 1321.000, total: 3000.000, accuracy: 0.440\n",
            "training epoch: [22 ] loss: 4.465 correct: 1321.000, total: 3000.000, accuracy: 0.440\n",
            "training epoch: [23 ] loss: 4.455 correct: 1319.000, total: 3000.000, accuracy: 0.440\n",
            "training epoch: [24 ] loss: 4.444 correct: 1322.000, total: 3000.000, accuracy: 0.441\n",
            "training epoch: [25 ] loss: 4.433 correct: 1325.000, total: 3000.000, accuracy: 0.442\n",
            "training epoch: [26 ] loss: 4.421 correct: 1330.000, total: 3000.000, accuracy: 0.443\n",
            "training epoch: [27 ] loss: 4.410 correct: 1335.000, total: 3000.000, accuracy: 0.445\n",
            "training epoch: [28 ] loss: 4.398 correct: 1335.000, total: 3000.000, accuracy: 0.445\n",
            "training epoch: [29 ] loss: 4.386 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [30 ] loss: 4.375 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [31 ] loss: 4.363 correct: 1343.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [32 ] loss: 4.350 correct: 1346.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [33 ] loss: 4.338 correct: 1346.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [34 ] loss: 4.326 correct: 1347.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [35 ] loss: 4.314 correct: 1347.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [36 ] loss: 4.302 correct: 1352.000, total: 3000.000, accuracy: 0.451\n",
            "training epoch: [37 ] loss: 4.290 correct: 1353.000, total: 3000.000, accuracy: 0.451\n",
            "training epoch: [38 ] loss: 4.277 correct: 1354.000, total: 3000.000, accuracy: 0.451\n",
            "training epoch: [39 ] loss: 4.264 correct: 1353.000, total: 3000.000, accuracy: 0.451\n",
            "training epoch: [40 ] loss: 4.251 correct: 1355.000, total: 3000.000, accuracy: 0.452\n",
            "training epoch: [41 ] loss: 4.238 correct: 1359.000, total: 3000.000, accuracy: 0.453\n",
            "training epoch: [42 ] loss: 4.225 correct: 1362.000, total: 3000.000, accuracy: 0.454\n",
            "training epoch: [43 ] loss: 4.212 correct: 1361.000, total: 3000.000, accuracy: 0.454\n",
            "training epoch: [44 ] loss: 4.198 correct: 1363.000, total: 3000.000, accuracy: 0.454\n",
            "training epoch: [45 ] loss: 4.183 correct: 1368.000, total: 3000.000, accuracy: 0.456\n",
            "training epoch: [46 ] loss: 4.169 correct: 1370.000, total: 3000.000, accuracy: 0.457\n",
            "training epoch: [47 ] loss: 4.154 correct: 1369.000, total: 3000.000, accuracy: 0.456\n",
            "training epoch: [48 ] loss: 4.140 correct: 1372.000, total: 3000.000, accuracy: 0.457\n",
            "training epoch: [49 ] loss: 4.126 correct: 1375.000, total: 3000.000, accuracy: 0.458\n",
            "training epoch: [50 ] loss: 4.112 correct: 1380.000, total: 3000.000, accuracy: 0.460\n",
            "training epoch: [51 ] loss: 4.098 correct: 1384.000, total: 3000.000, accuracy: 0.461\n",
            "training epoch: [52 ] loss: 4.084 correct: 1387.000, total: 3000.000, accuracy: 0.462\n",
            "training epoch: [53 ] loss: 4.070 correct: 1388.000, total: 3000.000, accuracy: 0.463\n",
            "training epoch: [54 ] loss: 4.055 correct: 1389.000, total: 3000.000, accuracy: 0.463\n",
            "training epoch: [55 ] loss: 4.040 correct: 1391.000, total: 3000.000, accuracy: 0.464\n",
            "training epoch: [56 ] loss: 4.024 correct: 1396.000, total: 3000.000, accuracy: 0.465\n",
            "training epoch: [57 ] loss: 4.009 correct: 1398.000, total: 3000.000, accuracy: 0.466\n",
            "training epoch: [58 ] loss: 3.994 correct: 1401.000, total: 3000.000, accuracy: 0.467\n",
            "training epoch: [59 ] loss: 3.980 correct: 1405.000, total: 3000.000, accuracy: 0.468\n",
            "training epoch: [60 ] loss: 3.965 correct: 1406.000, total: 3000.000, accuracy: 0.469\n",
            "training epoch: [61 ] loss: 3.949 correct: 1407.000, total: 3000.000, accuracy: 0.469\n",
            "training epoch: [62 ] loss: 3.933 correct: 1411.000, total: 3000.000, accuracy: 0.470\n",
            "training epoch: [63 ] loss: 3.916 correct: 1418.000, total: 3000.000, accuracy: 0.473\n",
            "training epoch: [64 ] loss: 3.899 correct: 1424.000, total: 3000.000, accuracy: 0.475\n",
            "training epoch: [65 ] loss: 3.883 correct: 1425.000, total: 3000.000, accuracy: 0.475\n",
            "training epoch: [66 ] loss: 3.866 correct: 1428.000, total: 3000.000, accuracy: 0.476\n",
            "training epoch: [67 ] loss: 3.849 correct: 1429.000, total: 3000.000, accuracy: 0.476\n",
            "training epoch: [68 ] loss: 3.832 correct: 1431.000, total: 3000.000, accuracy: 0.477\n",
            "training epoch: [69 ] loss: 3.814 correct: 1429.000, total: 3000.000, accuracy: 0.476\n",
            "training epoch: [70 ] loss: 3.796 correct: 1433.000, total: 3000.000, accuracy: 0.478\n",
            "training epoch: [71 ] loss: 3.776 correct: 1434.000, total: 3000.000, accuracy: 0.478\n",
            "training epoch: [72 ] loss: 3.757 correct: 1440.000, total: 3000.000, accuracy: 0.480\n",
            "training epoch: [73 ] loss: 3.738 correct: 1444.000, total: 3000.000, accuracy: 0.481\n",
            "training epoch: [74 ] loss: 3.720 correct: 1445.000, total: 3000.000, accuracy: 0.482\n",
            "training epoch: [75 ] loss: 3.702 correct: 1449.000, total: 3000.000, accuracy: 0.483\n",
            "training epoch: [76 ] loss: 3.684 correct: 1455.000, total: 3000.000, accuracy: 0.485\n",
            "training epoch: [77 ] loss: 3.666 correct: 1458.000, total: 3000.000, accuracy: 0.486\n",
            "training epoch: [78 ] loss: 3.648 correct: 1459.000, total: 3000.000, accuracy: 0.486\n",
            "training epoch: [79 ] loss: 3.630 correct: 1459.000, total: 3000.000, accuracy: 0.486\n",
            "training epoch: [80 ] loss: 3.612 correct: 1464.000, total: 3000.000, accuracy: 0.488\n",
            "training epoch: [81 ] loss: 3.593 correct: 1469.000, total: 3000.000, accuracy: 0.490\n",
            "training epoch: [82 ] loss: 3.574 correct: 1474.000, total: 3000.000, accuracy: 0.491\n",
            "training epoch: [83 ] loss: 3.555 correct: 1478.000, total: 3000.000, accuracy: 0.493\n",
            "training epoch: [84 ] loss: 3.535 correct: 1478.000, total: 3000.000, accuracy: 0.493\n",
            "training epoch: [85 ] loss: 3.517 correct: 1482.000, total: 3000.000, accuracy: 0.494\n",
            "training epoch: [86 ] loss: 3.497 correct: 1484.000, total: 3000.000, accuracy: 0.495\n",
            "training epoch: [87 ] loss: 3.478 correct: 1489.000, total: 3000.000, accuracy: 0.496\n",
            "training epoch: [88 ] loss: 3.458 correct: 1496.000, total: 3000.000, accuracy: 0.499\n",
            "training epoch: [89 ] loss: 3.438 correct: 1499.000, total: 3000.000, accuracy: 0.500\n",
            "training epoch: [90 ] loss: 3.419 correct: 1499.000, total: 3000.000, accuracy: 0.500\n",
            "training epoch: [91 ] loss: 3.400 correct: 1507.000, total: 3000.000, accuracy: 0.502\n",
            "training epoch: [92 ] loss: 3.381 correct: 1510.000, total: 3000.000, accuracy: 0.503\n",
            "training epoch: [93 ] loss: 3.362 correct: 1516.000, total: 3000.000, accuracy: 0.505\n",
            "training epoch: [94 ] loss: 3.344 correct: 1515.000, total: 3000.000, accuracy: 0.505\n",
            "training epoch: [95 ] loss: 3.326 correct: 1520.000, total: 3000.000, accuracy: 0.507\n",
            "training epoch: [96 ] loss: 3.310 correct: 1529.000, total: 3000.000, accuracy: 0.510\n",
            "training epoch: [97 ] loss: 3.293 correct: 1540.000, total: 3000.000, accuracy: 0.513\n",
            "training epoch: [98 ] loss: 3.278 correct: 1553.000, total: 3000.000, accuracy: 0.518\n",
            "training epoch: [99 ] loss: 3.264 correct: 1558.000, total: 3000.000, accuracy: 0.519\n",
            "training epoch: [100 ] loss: 3.251 correct: 1559.000, total: 3000.000, accuracy: 0.520\n",
            "training epoch: [101 ] loss: 3.239 correct: 1564.000, total: 3000.000, accuracy: 0.521\n",
            "training epoch: [102 ] loss: 3.228 correct: 1573.000, total: 3000.000, accuracy: 0.524\n",
            "training epoch: [103 ] loss: 3.218 correct: 1582.000, total: 3000.000, accuracy: 0.527\n",
            "training epoch: [104 ] loss: 3.210 correct: 1585.000, total: 3000.000, accuracy: 0.528\n",
            "training epoch: [105 ] loss: 3.202 correct: 1585.000, total: 3000.000, accuracy: 0.528\n",
            "training epoch: [106 ] loss: 3.196 correct: 1587.000, total: 3000.000, accuracy: 0.529\n",
            "training epoch: [107 ] loss: 3.190 correct: 1593.000, total: 3000.000, accuracy: 0.531\n",
            "training epoch: [108 ] loss: 3.186 correct: 1598.000, total: 3000.000, accuracy: 0.533\n",
            "training epoch: [109 ] loss: 3.182 correct: 1603.000, total: 3000.000, accuracy: 0.534\n",
            "training epoch: [110 ] loss: 3.179 correct: 1601.000, total: 3000.000, accuracy: 0.534\n",
            "training epoch: [111 ] loss: 3.177 correct: 1604.000, total: 3000.000, accuracy: 0.535\n",
            "training epoch: [112 ] loss: 3.175 correct: 1606.000, total: 3000.000, accuracy: 0.535\n",
            "training epoch: [113 ] loss: 3.174 correct: 1606.000, total: 3000.000, accuracy: 0.535\n",
            "training epoch: [114 ] loss: 3.173 correct: 1605.000, total: 3000.000, accuracy: 0.535\n",
            "training epoch: [115 ] loss: 3.173 correct: 1608.000, total: 3000.000, accuracy: 0.536\n",
            "training epoch: [116 ] loss: 3.174 correct: 1611.000, total: 3000.000, accuracy: 0.537\n",
            "training epoch: [117 ] loss: 3.175 correct: 1610.000, total: 3000.000, accuracy: 0.537\n",
            "training epoch: [118 ] loss: 3.178 correct: 1610.000, total: 3000.000, accuracy: 0.537\n",
            "training epoch: [119 ] loss: 3.182 correct: 1607.000, total: 3000.000, accuracy: 0.536\n",
            "training epoch: [120 ] loss: 3.187 correct: 1610.000, total: 3000.000, accuracy: 0.537\n",
            "training epoch: [121 ] loss: 3.193 correct: 1609.000, total: 3000.000, accuracy: 0.536\n",
            "training epoch: [122 ] loss: 3.200 correct: 1603.000, total: 3000.000, accuracy: 0.534\n",
            "training epoch: [123 ] loss: 3.209 correct: 1602.000, total: 3000.000, accuracy: 0.534\n",
            "training epoch: [124 ] loss: 3.218 correct: 1600.000, total: 3000.000, accuracy: 0.533\n",
            "training epoch: [125 ] loss: 3.229 correct: 1592.000, total: 3000.000, accuracy: 0.531\n",
            "training epoch: [126 ] loss: 3.241 correct: 1588.000, total: 3000.000, accuracy: 0.529\n",
            "training epoch: [127 ] loss: 3.254 correct: 1591.000, total: 3000.000, accuracy: 0.530\n",
            "training epoch: [128 ] loss: 3.269 correct: 1584.000, total: 3000.000, accuracy: 0.528\n",
            "training epoch: [129 ] loss: 3.285 correct: 1573.000, total: 3000.000, accuracy: 0.524\n",
            "training epoch: [130 ] loss: 3.301 correct: 1566.000, total: 3000.000, accuracy: 0.522\n",
            "training epoch: [131 ] loss: 3.318 correct: 1562.000, total: 3000.000, accuracy: 0.521\n",
            "training epoch: [132 ] loss: 3.335 correct: 1559.000, total: 3000.000, accuracy: 0.520\n",
            "training epoch: [133 ] loss: 3.354 correct: 1555.000, total: 3000.000, accuracy: 0.518\n",
            "training epoch: [134 ] loss: 3.372 correct: 1556.000, total: 3000.000, accuracy: 0.519\n",
            "training epoch: [135 ] loss: 3.392 correct: 1556.000, total: 3000.000, accuracy: 0.519\n",
            "training epoch: [136 ] loss: 3.412 correct: 1546.000, total: 3000.000, accuracy: 0.515\n",
            "training epoch: [137 ] loss: 3.432 correct: 1539.000, total: 3000.000, accuracy: 0.513\n",
            "training epoch: [138 ] loss: 3.452 correct: 1540.000, total: 3000.000, accuracy: 0.513\n",
            "training epoch: [139 ] loss: 3.471 correct: 1543.000, total: 3000.000, accuracy: 0.514\n",
            "training epoch: [140 ] loss: 3.491 correct: 1545.000, total: 3000.000, accuracy: 0.515\n",
            "training epoch: [141 ] loss: 3.510 correct: 1540.000, total: 3000.000, accuracy: 0.513\n",
            "training epoch: [142 ] loss: 3.530 correct: 1528.000, total: 3000.000, accuracy: 0.509\n",
            "training epoch: [143 ] loss: 3.549 correct: 1523.000, total: 3000.000, accuracy: 0.508\n",
            "training epoch: [144 ] loss: 3.568 correct: 1522.000, total: 3000.000, accuracy: 0.507\n",
            "training epoch: [145 ] loss: 3.586 correct: 1517.000, total: 3000.000, accuracy: 0.506\n",
            "training epoch: [146 ] loss: 3.604 correct: 1510.000, total: 3000.000, accuracy: 0.503\n",
            "training epoch: [147 ] loss: 3.622 correct: 1506.000, total: 3000.000, accuracy: 0.502\n",
            "training epoch: [148 ] loss: 3.640 correct: 1501.000, total: 3000.000, accuracy: 0.500\n",
            "training epoch: [149 ] loss: 3.657 correct: 1495.000, total: 3000.000, accuracy: 0.498\n",
            "training epoch: [150 ] loss: 3.674 correct: 1492.000, total: 3000.000, accuracy: 0.497\n",
            "training epoch: [151 ] loss: 3.690 correct: 1493.000, total: 3000.000, accuracy: 0.498\n",
            "training epoch: [152 ] loss: 3.706 correct: 1488.000, total: 3000.000, accuracy: 0.496\n",
            "training epoch: [153 ] loss: 3.721 correct: 1486.000, total: 3000.000, accuracy: 0.495\n",
            "training epoch: [154 ] loss: 3.737 correct: 1484.000, total: 3000.000, accuracy: 0.495\n",
            "training epoch: [155 ] loss: 3.752 correct: 1480.000, total: 3000.000, accuracy: 0.493\n",
            "training epoch: [156 ] loss: 3.766 correct: 1475.000, total: 3000.000, accuracy: 0.492\n",
            "training epoch: [157 ] loss: 3.781 correct: 1468.000, total: 3000.000, accuracy: 0.489\n",
            "training epoch: [158 ] loss: 3.795 correct: 1466.000, total: 3000.000, accuracy: 0.489\n",
            "training epoch: [159 ] loss: 3.809 correct: 1464.000, total: 3000.000, accuracy: 0.488\n",
            "training epoch: [160 ] loss: 3.823 correct: 1460.000, total: 3000.000, accuracy: 0.487\n",
            "training epoch: [161 ] loss: 3.836 correct: 1458.000, total: 3000.000, accuracy: 0.486\n",
            "training epoch: [162 ] loss: 3.849 correct: 1456.000, total: 3000.000, accuracy: 0.485\n",
            "training epoch: [163 ] loss: 3.862 correct: 1454.000, total: 3000.000, accuracy: 0.485\n",
            "training epoch: [164 ] loss: 3.875 correct: 1452.000, total: 3000.000, accuracy: 0.484\n",
            "training epoch: [165 ] loss: 3.888 correct: 1447.000, total: 3000.000, accuracy: 0.482\n",
            "training epoch: [166 ] loss: 3.901 correct: 1445.000, total: 3000.000, accuracy: 0.482\n",
            "training epoch: [167 ] loss: 3.913 correct: 1441.000, total: 3000.000, accuracy: 0.480\n",
            "training epoch: [168 ] loss: 3.925 correct: 1440.000, total: 3000.000, accuracy: 0.480\n",
            "training epoch: [169 ] loss: 3.937 correct: 1441.000, total: 3000.000, accuracy: 0.480\n",
            "training epoch: [170 ] loss: 3.949 correct: 1438.000, total: 3000.000, accuracy: 0.479\n",
            "training epoch: [171 ] loss: 3.960 correct: 1437.000, total: 3000.000, accuracy: 0.479\n",
            "training epoch: [172 ] loss: 3.972 correct: 1432.000, total: 3000.000, accuracy: 0.477\n",
            "training epoch: [173 ] loss: 3.983 correct: 1429.000, total: 3000.000, accuracy: 0.476\n",
            "training epoch: [174 ] loss: 3.995 correct: 1425.000, total: 3000.000, accuracy: 0.475\n",
            "training epoch: [175 ] loss: 4.006 correct: 1421.000, total: 3000.000, accuracy: 0.474\n",
            "training epoch: [176 ] loss: 4.017 correct: 1419.000, total: 3000.000, accuracy: 0.473\n",
            "training epoch: [177 ] loss: 4.028 correct: 1418.000, total: 3000.000, accuracy: 0.473\n",
            "training epoch: [178 ] loss: 4.039 correct: 1417.000, total: 3000.000, accuracy: 0.472\n",
            "training epoch: [179 ] loss: 4.050 correct: 1415.000, total: 3000.000, accuracy: 0.472\n",
            "training epoch: [180 ] loss: 4.060 correct: 1415.000, total: 3000.000, accuracy: 0.472\n",
            "training epoch: [181 ] loss: 4.071 correct: 1414.000, total: 3000.000, accuracy: 0.471\n",
            "training epoch: [182 ] loss: 4.082 correct: 1410.000, total: 3000.000, accuracy: 0.470\n",
            "training epoch: [183 ] loss: 4.092 correct: 1408.000, total: 3000.000, accuracy: 0.469\n",
            "training epoch: [184 ] loss: 4.102 correct: 1408.000, total: 3000.000, accuracy: 0.469\n",
            "training epoch: [185 ] loss: 4.113 correct: 1402.000, total: 3000.000, accuracy: 0.467\n",
            "training epoch: [186 ] loss: 4.123 correct: 1401.000, total: 3000.000, accuracy: 0.467\n",
            "training epoch: [187 ] loss: 4.133 correct: 1399.000, total: 3000.000, accuracy: 0.466\n",
            "training epoch: [188 ] loss: 4.143 correct: 1394.000, total: 3000.000, accuracy: 0.465\n",
            "training epoch: [189 ] loss: 4.152 correct: 1392.000, total: 3000.000, accuracy: 0.464\n",
            "training epoch: [190 ] loss: 4.162 correct: 1391.000, total: 3000.000, accuracy: 0.464\n",
            "training epoch: [191 ] loss: 4.172 correct: 1387.000, total: 3000.000, accuracy: 0.462\n",
            "training epoch: [192 ] loss: 4.181 correct: 1385.000, total: 3000.000, accuracy: 0.462\n",
            "training epoch: [193 ] loss: 4.190 correct: 1383.000, total: 3000.000, accuracy: 0.461\n",
            "training epoch: [194 ] loss: 4.199 correct: 1381.000, total: 3000.000, accuracy: 0.460\n",
            "training epoch: [195 ] loss: 4.209 correct: 1380.000, total: 3000.000, accuracy: 0.460\n",
            "training epoch: [196 ] loss: 4.217 correct: 1381.000, total: 3000.000, accuracy: 0.460\n",
            "training epoch: [197 ] loss: 4.226 correct: 1381.000, total: 3000.000, accuracy: 0.460\n",
            "training epoch: [198 ] loss: 4.235 correct: 1377.000, total: 3000.000, accuracy: 0.459\n",
            "training epoch: [199 ] loss: 4.244 correct: 1374.000, total: 3000.000, accuracy: 0.458\n",
            "training epoch: [200 ] loss: 4.252 correct: 1375.000, total: 3000.000, accuracy: 0.458\n",
            "training epoch: [201 ] loss: 4.260 correct: 1374.000, total: 3000.000, accuracy: 0.458\n",
            "training epoch: [202 ] loss: 4.269 correct: 1371.000, total: 3000.000, accuracy: 0.457\n",
            "training epoch: [203 ] loss: 4.277 correct: 1367.000, total: 3000.000, accuracy: 0.456\n",
            "training epoch: [204 ] loss: 4.285 correct: 1365.000, total: 3000.000, accuracy: 0.455\n",
            "training epoch: [205 ] loss: 4.293 correct: 1365.000, total: 3000.000, accuracy: 0.455\n",
            "training epoch: [206 ] loss: 4.301 correct: 1366.000, total: 3000.000, accuracy: 0.455\n",
            "training epoch: [207 ] loss: 4.309 correct: 1366.000, total: 3000.000, accuracy: 0.455\n",
            "training epoch: [208 ] loss: 4.317 correct: 1367.000, total: 3000.000, accuracy: 0.456\n",
            "training epoch: [209 ] loss: 4.324 correct: 1366.000, total: 3000.000, accuracy: 0.455\n",
            "training epoch: [210 ] loss: 4.332 correct: 1366.000, total: 3000.000, accuracy: 0.455\n",
            "training epoch: [211 ] loss: 4.339 correct: 1364.000, total: 3000.000, accuracy: 0.455\n",
            "training epoch: [212 ] loss: 4.346 correct: 1362.000, total: 3000.000, accuracy: 0.454\n",
            "training epoch: [213 ] loss: 4.353 correct: 1360.000, total: 3000.000, accuracy: 0.453\n",
            "training epoch: [214 ] loss: 4.360 correct: 1361.000, total: 3000.000, accuracy: 0.454\n",
            "training epoch: [215 ] loss: 4.366 correct: 1360.000, total: 3000.000, accuracy: 0.453\n",
            "training epoch: [216 ] loss: 4.373 correct: 1360.000, total: 3000.000, accuracy: 0.453\n",
            "training epoch: [217 ] loss: 4.379 correct: 1359.000, total: 3000.000, accuracy: 0.453\n",
            "training epoch: [218 ] loss: 4.385 correct: 1358.000, total: 3000.000, accuracy: 0.453\n",
            "training epoch: [219 ] loss: 4.391 correct: 1359.000, total: 3000.000, accuracy: 0.453\n",
            "training epoch: [220 ] loss: 4.397 correct: 1359.000, total: 3000.000, accuracy: 0.453\n",
            "training epoch: [221 ] loss: 4.403 correct: 1358.000, total: 3000.000, accuracy: 0.453\n",
            "training epoch: [222 ] loss: 4.409 correct: 1356.000, total: 3000.000, accuracy: 0.452\n",
            "training epoch: [223 ] loss: 4.414 correct: 1357.000, total: 3000.000, accuracy: 0.452\n",
            "training epoch: [224 ] loss: 4.420 correct: 1355.000, total: 3000.000, accuracy: 0.452\n",
            "training epoch: [225 ] loss: 4.425 correct: 1357.000, total: 3000.000, accuracy: 0.452\n",
            "training epoch: [226 ] loss: 4.430 correct: 1355.000, total: 3000.000, accuracy: 0.452\n",
            "training epoch: [227 ] loss: 4.435 correct: 1353.000, total: 3000.000, accuracy: 0.451\n",
            "training epoch: [228 ] loss: 4.440 correct: 1349.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [229 ] loss: 4.445 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [230 ] loss: 4.449 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [231 ] loss: 4.454 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [232 ] loss: 4.458 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [233 ] loss: 4.462 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [234 ] loss: 4.467 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [235 ] loss: 4.471 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [236 ] loss: 4.475 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [237 ] loss: 4.480 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [238 ] loss: 4.484 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [239 ] loss: 4.488 correct: 1350.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [240 ] loss: 4.492 correct: 1349.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [241 ] loss: 4.496 correct: 1349.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [242 ] loss: 4.500 correct: 1349.000, total: 3000.000, accuracy: 0.450\n",
            "training epoch: [243 ] loss: 4.504 correct: 1348.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [244 ] loss: 4.508 correct: 1348.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [245 ] loss: 4.512 correct: 1348.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [246 ] loss: 4.515 correct: 1348.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [247 ] loss: 4.519 correct: 1345.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [248 ] loss: 4.522 correct: 1345.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [249 ] loss: 4.526 correct: 1345.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [250 ] loss: 4.529 correct: 1345.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [251 ] loss: 4.532 correct: 1345.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [252 ] loss: 4.536 correct: 1345.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [253 ] loss: 4.539 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [254 ] loss: 4.542 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [255 ] loss: 4.545 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [256 ] loss: 4.548 correct: 1345.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [257 ] loss: 4.551 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [258 ] loss: 4.554 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [259 ] loss: 4.556 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [260 ] loss: 4.559 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [261 ] loss: 4.562 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [262 ] loss: 4.565 correct: 1343.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [263 ] loss: 4.567 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [264 ] loss: 4.570 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [265 ] loss: 4.572 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [266 ] loss: 4.575 correct: 1347.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [267 ] loss: 4.577 correct: 1347.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [268 ] loss: 4.580 correct: 1347.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [269 ] loss: 4.582 correct: 1347.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [270 ] loss: 4.585 correct: 1347.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [271 ] loss: 4.587 correct: 1347.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [272 ] loss: 4.589 correct: 1347.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [273 ] loss: 4.592 correct: 1346.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [274 ] loss: 4.594 correct: 1346.000, total: 3000.000, accuracy: 0.449\n",
            "training epoch: [275 ] loss: 4.596 correct: 1345.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [276 ] loss: 4.598 correct: 1343.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [277 ] loss: 4.600 correct: 1343.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [278 ] loss: 4.602 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [279 ] loss: 4.604 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [280 ] loss: 4.606 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [281 ] loss: 4.608 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [282 ] loss: 4.610 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [283 ] loss: 4.612 correct: 1343.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [284 ] loss: 4.614 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [285 ] loss: 4.616 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [286 ] loss: 4.618 correct: 1344.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [287 ] loss: 4.619 correct: 1343.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [288 ] loss: 4.621 correct: 1343.000, total: 3000.000, accuracy: 0.448\n",
            "training epoch: [289 ] loss: 4.623 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [290 ] loss: 4.624 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [291 ] loss: 4.626 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [292 ] loss: 4.627 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [293 ] loss: 4.629 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [294 ] loss: 4.630 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [295 ] loss: 4.632 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [296 ] loss: 4.633 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [297 ] loss: 4.635 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [298 ] loss: 4.636 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [299 ] loss: 4.637 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [300 ] loss: 4.639 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [301 ] loss: 4.640 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [302 ] loss: 4.641 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [303 ] loss: 4.643 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [304 ] loss: 4.644 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [305 ] loss: 4.645 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [306 ] loss: 4.646 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [307 ] loss: 4.648 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [308 ] loss: 4.649 correct: 1338.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [309 ] loss: 4.650 correct: 1338.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [310 ] loss: 4.651 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [311 ] loss: 4.652 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [312 ] loss: 4.653 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [313 ] loss: 4.654 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [314 ] loss: 4.655 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [315 ] loss: 4.656 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [316 ] loss: 4.657 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [317 ] loss: 4.658 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [318 ] loss: 4.659 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [319 ] loss: 4.660 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [320 ] loss: 4.661 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [321 ] loss: 4.662 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [322 ] loss: 4.663 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [323 ] loss: 4.664 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [324 ] loss: 4.665 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [325 ] loss: 4.666 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [326 ] loss: 4.666 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [327 ] loss: 4.667 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [328 ] loss: 4.668 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [329 ] loss: 4.669 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [330 ] loss: 4.670 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [331 ] loss: 4.670 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [332 ] loss: 4.671 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [333 ] loss: 4.672 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [334 ] loss: 4.673 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [335 ] loss: 4.673 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [336 ] loss: 4.674 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [337 ] loss: 4.675 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [338 ] loss: 4.676 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [339 ] loss: 4.676 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [340 ] loss: 4.677 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [341 ] loss: 4.678 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [342 ] loss: 4.678 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [343 ] loss: 4.679 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [344 ] loss: 4.680 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [345 ] loss: 4.680 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [346 ] loss: 4.681 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [347 ] loss: 4.681 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [348 ] loss: 4.682 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [349 ] loss: 4.683 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [350 ] loss: 4.683 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [351 ] loss: 4.684 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [352 ] loss: 4.684 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [353 ] loss: 4.685 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [354 ] loss: 4.686 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [355 ] loss: 4.686 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [356 ] loss: 4.687 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [357 ] loss: 4.687 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [358 ] loss: 4.688 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [359 ] loss: 4.688 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [360 ] loss: 4.689 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [361 ] loss: 4.689 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [362 ] loss: 4.690 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [363 ] loss: 4.690 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [364 ] loss: 4.691 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [365 ] loss: 4.691 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [366 ] loss: 4.692 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [367 ] loss: 4.692 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [368 ] loss: 4.692 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [369 ] loss: 4.693 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [370 ] loss: 4.693 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [371 ] loss: 4.694 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [372 ] loss: 4.694 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [373 ] loss: 4.695 correct: 1342.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [374 ] loss: 4.695 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [375 ] loss: 4.696 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [376 ] loss: 4.696 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [377 ] loss: 4.696 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [378 ] loss: 4.697 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [379 ] loss: 4.697 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [380 ] loss: 4.698 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [381 ] loss: 4.698 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [382 ] loss: 4.698 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [383 ] loss: 4.699 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [384 ] loss: 4.699 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [385 ] loss: 4.700 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [386 ] loss: 4.700 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [387 ] loss: 4.700 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [388 ] loss: 4.701 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [389 ] loss: 4.701 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [390 ] loss: 4.701 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [391 ] loss: 4.702 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [392 ] loss: 4.702 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [393 ] loss: 4.703 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [394 ] loss: 4.703 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [395 ] loss: 4.703 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [396 ] loss: 4.704 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [397 ] loss: 4.704 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [398 ] loss: 4.704 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [399 ] loss: 4.704 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [400 ] loss: 4.705 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [401 ] loss: 4.705 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [402 ] loss: 4.705 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [403 ] loss: 4.706 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [404 ] loss: 4.706 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [405 ] loss: 4.706 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [406 ] loss: 4.707 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [407 ] loss: 4.707 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [408 ] loss: 4.707 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [409 ] loss: 4.708 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [410 ] loss: 4.708 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [411 ] loss: 4.708 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [412 ] loss: 4.708 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [413 ] loss: 4.709 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [414 ] loss: 4.709 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [415 ] loss: 4.709 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [416 ] loss: 4.710 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [417 ] loss: 4.710 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [418 ] loss: 4.710 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [419 ] loss: 4.710 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [420 ] loss: 4.711 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [421 ] loss: 4.711 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [422 ] loss: 4.711 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [423 ] loss: 4.711 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [424 ] loss: 4.712 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [425 ] loss: 4.712 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [426 ] loss: 4.712 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [427 ] loss: 4.712 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [428 ] loss: 4.713 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [429 ] loss: 4.713 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [430 ] loss: 4.713 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [431 ] loss: 4.713 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [432 ] loss: 4.713 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [433 ] loss: 4.714 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [434 ] loss: 4.714 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [435 ] loss: 4.714 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [436 ] loss: 4.714 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [437 ] loss: 4.714 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [438 ] loss: 4.715 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [439 ] loss: 4.715 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [440 ] loss: 4.715 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [441 ] loss: 4.715 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [442 ] loss: 4.715 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [443 ] loss: 4.715 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [444 ] loss: 4.716 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [445 ] loss: 4.716 correct: 1338.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [446 ] loss: 4.716 correct: 1338.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [447 ] loss: 4.716 correct: 1338.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [448 ] loss: 4.716 correct: 1338.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [449 ] loss: 4.716 correct: 1338.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [450 ] loss: 4.717 correct: 1338.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [451 ] loss: 4.717 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [452 ] loss: 4.717 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [453 ] loss: 4.717 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [454 ] loss: 4.717 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [455 ] loss: 4.717 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [456 ] loss: 4.717 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [457 ] loss: 4.718 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [458 ] loss: 4.718 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [459 ] loss: 4.718 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [460 ] loss: 4.718 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [461 ] loss: 4.718 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [462 ] loss: 4.718 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [463 ] loss: 4.718 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [464 ] loss: 4.719 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [465 ] loss: 4.719 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [466 ] loss: 4.719 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [467 ] loss: 4.719 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [468 ] loss: 4.719 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [469 ] loss: 4.719 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [470 ] loss: 4.719 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [471 ] loss: 4.719 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [472 ] loss: 4.719 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [473 ] loss: 4.720 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [474 ] loss: 4.720 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [475 ] loss: 4.720 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [476 ] loss: 4.720 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [477 ] loss: 4.720 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [478 ] loss: 4.720 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [479 ] loss: 4.720 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [480 ] loss: 4.720 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [481 ] loss: 4.720 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [482 ] loss: 4.720 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [483 ] loss: 4.720 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [484 ] loss: 4.721 correct: 1341.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [485 ] loss: 4.721 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [486 ] loss: 4.721 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [487 ] loss: 4.721 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [488 ] loss: 4.721 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [489 ] loss: 4.721 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [490 ] loss: 4.721 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [491 ] loss: 4.721 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [492 ] loss: 4.721 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [493 ] loss: 4.721 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [494 ] loss: 4.721 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [495 ] loss: 4.721 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [496 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [497 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [498 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [499 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [500 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [501 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [502 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [503 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [504 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [505 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [506 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [507 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [508 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [509 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [510 ] loss: 4.722 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [511 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [512 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [513 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [514 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [515 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [516 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [517 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [518 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [519 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [520 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [521 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [522 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [523 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [524 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [525 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [526 ] loss: 4.723 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [527 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [528 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [529 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [530 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [531 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [532 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [533 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [534 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [535 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [536 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [537 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [538 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [539 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [540 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [541 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [542 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [543 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [544 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [545 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [546 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [547 ] loss: 4.724 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [548 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [549 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [550 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [551 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [552 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [553 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [554 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [555 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [556 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [557 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [558 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [559 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [560 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [561 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [562 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [563 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [564 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [565 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [566 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [567 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [568 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [569 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [570 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [571 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [572 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [573 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [574 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [575 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [576 ] loss: 4.725 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [577 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [578 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [579 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [580 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [581 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [582 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [583 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [584 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [585 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [586 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [587 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [588 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [589 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [590 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [591 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [592 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [593 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [594 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [595 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [596 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [597 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [598 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [599 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [600 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [601 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [602 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [603 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [604 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [605 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [606 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [607 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [608 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [609 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [610 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [611 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [612 ] loss: 4.726 correct: 1340.000, total: 3000.000, accuracy: 0.447\n",
            "training epoch: [613 ] loss: 4.726 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [614 ] loss: 4.726 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [615 ] loss: 4.726 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [616 ] loss: 4.726 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [617 ] loss: 4.726 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [618 ] loss: 4.726 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [619 ] loss: 4.726 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [620 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [621 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [622 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [623 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [624 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [625 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [626 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [627 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [628 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [629 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [630 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [631 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [632 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [633 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [634 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [635 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [636 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [637 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [638 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [639 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [640 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [641 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [642 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [643 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [644 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [645 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [646 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [647 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [648 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [649 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [650 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [651 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [652 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [653 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [654 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [655 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [656 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [657 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [658 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [659 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [660 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [661 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [662 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [663 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [664 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [665 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [666 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [667 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [668 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [669 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [670 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [671 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [672 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [673 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [674 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [675 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [676 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [677 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [678 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [679 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [680 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [681 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [682 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [683 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [684 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [685 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [686 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [687 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [688 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [689 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [690 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [691 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [692 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [693 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [694 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [695 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [696 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [697 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [698 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [699 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [700 ] loss: 4.727 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [701 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [702 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [703 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [704 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [705 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [706 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [707 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [708 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [709 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [710 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [711 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [712 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [713 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [714 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [715 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [716 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [717 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [718 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [719 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [720 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [721 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [722 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [723 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [724 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [725 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [726 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [727 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [728 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [729 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [730 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [731 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [732 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [733 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [734 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [735 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [736 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [737 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [738 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [739 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [740 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [741 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [742 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [743 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [744 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [745 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [746 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [747 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [748 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [749 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [750 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [751 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [752 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [753 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [754 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [755 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [756 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [757 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [758 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [759 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [760 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [761 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [762 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [763 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [764 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [765 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [766 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [767 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [768 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [769 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [770 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [771 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [772 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [773 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [774 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [775 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [776 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [777 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [778 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [779 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [780 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [781 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [782 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [783 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [784 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [785 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [786 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [787 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [788 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [789 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [790 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [791 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [792 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [793 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [794 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [795 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [796 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [797 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [798 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [799 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [800 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [801 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [802 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [803 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [804 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [805 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [806 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [807 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [808 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [809 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [810 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [811 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [812 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [813 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [814 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [815 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [816 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [817 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [818 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [819 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [820 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [821 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [822 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [823 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [824 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [825 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [826 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [827 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [828 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [829 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [830 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [831 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [832 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [833 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [834 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [835 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [836 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [837 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [838 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [839 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [840 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [841 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [842 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [843 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [844 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [845 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [846 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [847 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [848 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [849 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [850 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [851 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [852 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [853 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [854 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [855 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [856 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [857 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [858 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [859 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [860 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [861 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [862 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [863 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [864 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [865 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [866 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [867 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [868 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [869 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [870 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [871 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [872 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [873 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [874 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [875 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [876 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [877 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [878 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [879 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [880 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [881 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [882 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [883 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [884 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [885 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [886 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [887 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [888 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [889 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [890 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [891 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [892 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [893 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [894 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [895 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [896 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [897 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [898 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [899 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [900 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [901 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [902 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [903 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [904 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [905 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [906 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [907 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [908 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [909 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [910 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [911 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [912 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [913 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [914 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [915 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [916 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [917 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [918 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [919 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [920 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [921 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [922 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [923 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [924 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [925 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [926 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [927 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [928 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [929 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [930 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [931 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [932 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [933 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [934 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [935 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [936 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [937 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [938 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [939 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [940 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [941 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [942 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [943 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [944 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [945 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [946 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [947 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [948 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [949 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [950 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [951 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [952 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [953 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [954 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [955 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [956 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [957 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [958 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [959 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [960 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [961 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [962 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [963 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [964 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [965 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [966 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [967 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [968 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [969 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [970 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [971 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [972 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [973 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [974 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [975 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [976 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [977 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [978 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [979 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [980 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [981 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [982 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [983 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [984 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [985 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [986 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [987 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [988 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [989 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [990 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [991 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [992 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [993 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [994 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [995 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [996 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [997 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [998 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [999 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1000 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1001 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1002 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1003 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1004 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1005 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1006 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1007 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1008 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1009 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1010 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1011 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1012 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1013 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1014 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1015 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1016 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1017 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1018 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1019 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1020 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1021 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1022 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1023 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1024 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1025 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1026 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1027 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1028 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1029 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1030 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1031 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1032 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1033 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1034 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1035 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1036 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1037 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1038 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1039 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1040 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1041 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1042 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1043 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1044 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1045 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1046 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1047 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1048 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1049 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1050 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1051 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1052 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1053 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1054 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1055 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1056 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1057 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1058 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1059 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1060 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1061 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1062 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1063 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1064 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1065 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1066 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1067 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1068 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1069 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1070 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1071 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1072 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1073 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1074 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1075 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1076 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1077 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1078 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1079 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1080 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1081 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1082 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1083 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1084 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1085 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1086 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1087 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1088 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1089 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1090 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1091 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1092 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1093 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1094 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1095 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1096 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1097 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1098 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1099 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1100 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1101 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1102 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1103 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1104 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1105 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1106 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1107 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1108 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1109 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1110 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1111 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1112 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1113 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1114 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1115 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1116 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1117 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1118 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1119 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1120 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1121 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1122 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1123 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1124 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1125 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1126 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1127 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1128 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1129 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1130 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1131 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1132 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1133 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1134 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1135 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1136 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1137 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1138 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1139 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1140 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1141 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1142 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1143 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1144 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1145 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1146 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1147 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1148 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1149 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1150 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1151 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1152 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1153 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1154 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1155 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1156 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1157 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1158 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1159 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1160 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1161 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1162 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1163 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1164 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1165 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1166 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1167 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1168 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1169 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1170 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1171 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1172 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1173 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1174 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1175 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1176 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1177 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1178 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1179 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1180 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1181 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1182 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1183 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1184 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1185 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1186 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1187 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1188 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1189 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1190 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1191 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1192 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1193 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1194 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1195 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1196 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1197 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1198 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1199 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1200 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1201 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1202 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1203 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1204 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1205 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1206 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1207 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1208 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1209 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1210 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1211 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1212 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1213 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1214 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1215 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1216 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1217 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1218 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1219 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1220 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1221 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1222 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1223 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1224 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1225 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1226 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1227 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1228 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1229 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1230 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1231 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1232 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1233 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1234 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1235 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1236 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1237 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1238 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1239 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1240 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1241 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1242 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1243 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1244 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1245 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1246 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1247 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1248 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1249 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1250 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1251 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1252 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1253 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1254 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1255 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1256 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1257 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1258 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1259 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1260 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1261 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1262 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1263 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1264 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1265 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1266 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1267 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1268 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1269 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1270 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1271 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1272 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1273 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1274 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1275 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1276 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1277 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1278 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1279 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1280 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1281 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1282 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1283 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1284 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1285 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1286 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1287 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1288 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1289 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1290 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1291 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1292 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1293 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1294 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1295 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1296 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1297 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1298 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1299 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1300 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1301 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1302 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1303 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1304 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1305 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1306 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1307 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1308 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1309 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1310 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1311 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1312 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1313 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1314 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1315 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1316 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1317 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1318 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1319 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1320 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1321 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1322 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1323 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1324 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1325 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1326 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1327 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1328 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1329 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1330 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1331 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1332 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1333 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1334 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1335 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1336 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1337 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1338 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1339 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1340 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1341 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1342 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1343 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1344 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1345 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1346 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1347 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1348 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1349 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1350 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1351 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1352 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1353 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1354 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1355 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1356 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1357 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1358 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1359 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1360 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1361 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1362 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1363 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1364 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1365 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1366 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1367 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1368 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1369 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1370 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1371 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1372 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1373 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1374 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1375 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1376 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1377 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1378 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1379 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1380 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1381 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1382 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1383 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1384 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1385 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1386 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1387 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1388 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1389 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1390 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1391 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1392 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1393 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1394 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1395 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1396 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1397 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1398 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1399 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1400 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1401 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1402 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1403 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1404 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1405 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1406 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1407 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1408 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1409 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1410 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1411 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1412 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1413 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1414 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1415 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1416 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1417 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1418 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1419 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1420 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1421 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1422 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1423 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1424 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1425 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1426 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1427 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1428 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1429 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1430 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1431 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1432 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1433 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1434 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1435 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1436 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1437 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1438 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1439 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1440 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1441 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1442 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1443 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1444 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1445 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1446 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1447 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1448 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1449 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1450 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1451 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1452 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1453 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1454 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1455 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1456 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1457 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1458 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1459 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1460 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1461 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1462 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1463 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1464 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1465 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1466 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1467 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1468 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1469 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1470 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1471 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1472 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1473 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1474 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1475 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1476 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1477 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1478 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1479 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1480 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1481 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1482 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1483 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1484 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1485 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1486 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1487 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1488 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1489 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1490 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1491 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1492 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1493 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1494 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1495 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1496 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1497 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1498 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1499 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1500 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1501 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1502 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1503 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1504 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1505 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1506 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1507 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1508 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1509 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1510 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1511 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1512 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1513 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1514 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1515 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1516 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1517 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1518 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1519 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1520 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1521 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1522 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1523 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1524 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1525 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1526 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1527 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1528 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1529 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1530 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1531 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1532 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1533 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1534 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1535 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1536 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1537 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1538 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1539 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1540 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1541 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1542 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1543 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1544 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1545 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1546 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1547 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1548 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1549 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1550 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1551 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1552 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1553 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1554 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1555 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1556 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1557 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1558 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1559 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1560 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1561 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1562 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1563 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1564 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1565 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1566 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1567 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1568 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1569 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1570 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1571 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1572 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1573 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1574 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1575 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1576 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1577 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1578 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1579 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1580 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1581 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1582 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1583 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1584 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1585 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1586 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1587 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1588 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1589 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1590 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1591 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1592 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1593 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1594 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1595 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1596 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1597 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1598 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1599 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1600 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1601 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1602 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1603 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1604 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1605 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1606 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1607 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1608 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1609 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1610 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1611 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1612 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1613 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1614 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1615 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1616 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1617 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1618 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1619 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1620 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1621 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1622 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1623 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1624 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1625 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1626 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1627 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1628 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1629 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1630 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1631 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1632 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1633 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1634 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1635 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1636 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1637 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1638 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1639 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1640 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1641 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1642 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1643 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1644 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1645 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1646 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1647 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1648 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1649 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1650 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1651 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1652 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1653 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1654 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1655 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1656 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1657 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1658 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1659 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1660 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1661 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1662 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1663 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1664 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1665 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1666 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1667 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1668 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1669 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1670 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1671 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1672 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1673 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1674 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1675 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1676 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1677 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1678 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1679 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1680 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1681 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1682 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1683 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1684 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1685 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1686 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1687 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1688 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1689 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1690 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1691 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1692 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1693 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1694 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1695 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1696 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1697 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1698 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1699 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1700 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1701 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1702 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1703 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1704 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1705 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1706 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1707 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1708 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1709 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1710 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1711 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1712 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1713 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1714 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1715 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1716 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1717 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1718 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1719 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1720 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1721 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1722 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1723 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1724 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1725 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1726 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1727 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1728 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1729 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1730 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1731 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1732 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1733 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1734 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1735 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1736 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1737 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1738 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1739 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1740 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1741 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1742 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1743 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1744 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1745 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1746 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1747 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1748 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1749 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1750 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1751 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1752 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1753 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1754 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1755 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1756 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1757 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1758 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1759 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1760 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1761 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1762 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1763 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1764 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1765 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1766 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1767 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1768 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1769 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1770 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1771 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1772 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1773 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1774 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1775 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1776 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1777 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1778 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1779 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1780 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1781 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1782 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1783 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1784 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1785 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1786 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1787 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1788 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1789 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1790 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1791 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1792 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1793 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1794 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1795 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1796 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1797 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1798 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1799 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1800 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1801 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1802 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1803 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1804 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1805 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1806 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1807 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1808 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1809 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1810 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1811 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1812 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1813 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1814 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1815 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1816 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1817 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1818 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1819 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1820 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1821 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1822 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1823 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1824 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1825 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1826 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1827 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1828 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1829 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1830 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1831 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1832 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1833 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1834 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1835 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1836 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1837 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1838 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1839 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1840 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1841 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1842 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1843 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1844 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1845 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1846 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1847 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1848 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1849 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1850 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1851 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1852 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1853 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1854 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1855 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1856 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1857 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1858 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1859 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1860 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1861 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1862 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1863 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1864 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1865 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1866 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1867 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1868 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1869 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1870 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1871 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1872 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1873 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1874 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1875 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1876 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1877 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1878 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1879 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1880 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1881 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1882 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1883 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1884 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1885 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1886 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1887 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1888 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1889 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1890 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1891 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1892 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1893 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1894 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1895 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1896 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1897 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1898 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1899 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1900 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1901 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1902 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1903 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1904 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1905 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1906 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1907 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1908 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1909 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1910 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1911 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1912 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1913 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1914 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1915 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1916 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1917 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1918 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1919 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1920 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1921 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1922 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1923 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1924 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1925 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1926 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1927 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1928 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1929 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1930 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1931 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1932 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1933 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1934 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1935 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1936 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1937 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1938 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1939 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1940 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1941 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1942 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1943 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1944 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1945 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1946 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1947 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1948 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1949 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1950 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1951 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1952 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1953 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1954 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1955 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1956 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1957 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1958 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1959 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1960 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1961 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1962 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1963 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1964 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1965 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1966 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1967 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1968 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1969 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1970 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1971 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1972 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1973 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1974 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1975 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1976 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1977 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1978 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1979 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1980 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1981 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1982 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1983 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1984 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1985 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1986 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1987 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1988 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1989 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1990 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1991 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1992 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1993 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1994 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1995 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1996 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1997 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1998 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [1999 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2000 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2001 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2002 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2003 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2004 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2005 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2006 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2007 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2008 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2009 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2010 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2011 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2012 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2013 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2014 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2015 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2016 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2017 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2018 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2019 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2020 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2021 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2022 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2023 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2024 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2025 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2026 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2027 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2028 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2029 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2030 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2031 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2032 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2033 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2034 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2035 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2036 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2037 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2038 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2039 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2040 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2041 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2042 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2043 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2044 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2045 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2046 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2047 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2048 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2049 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2050 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2051 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2052 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2053 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2054 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2055 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2056 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2057 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2058 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2059 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2060 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2061 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2062 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2063 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2064 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2065 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2066 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2067 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2068 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2069 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2070 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2071 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2072 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2073 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2074 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2075 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2076 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2077 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2078 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2079 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2080 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2081 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2082 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2083 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2084 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2085 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2086 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2087 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2088 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2089 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2090 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2091 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2092 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2093 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2094 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2095 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2096 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2097 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2098 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2099 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2100 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2101 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2102 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2103 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2104 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2105 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2106 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2107 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2108 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2109 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2110 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2111 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2112 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2113 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2114 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2115 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2116 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2117 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2118 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2119 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2120 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2121 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2122 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2123 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2124 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2125 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2126 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2127 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2128 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2129 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2130 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2131 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2132 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2133 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2134 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2135 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2136 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2137 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2138 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2139 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2140 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2141 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2142 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2143 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2144 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2145 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2146 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2147 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2148 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2149 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2150 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2151 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2152 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2153 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2154 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2155 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2156 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2157 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2158 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2159 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2160 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2161 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2162 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2163 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2164 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2165 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2166 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2167 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2168 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2169 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2170 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2171 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2172 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2173 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2174 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2175 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2176 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2177 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2178 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2179 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2180 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2181 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2182 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2183 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2184 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2185 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2186 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2187 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2188 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2189 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2190 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2191 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2192 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2193 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2194 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2195 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2196 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2197 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2198 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2199 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2200 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2201 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2202 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2203 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2204 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2205 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2206 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2207 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2208 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2209 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2210 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2211 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2212 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2213 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2214 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2215 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2216 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2217 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2218 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2219 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2220 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2221 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2222 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2223 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2224 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2225 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2226 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2227 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2228 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2229 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2230 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2231 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2232 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2233 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2234 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2235 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2236 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2237 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2238 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2239 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2240 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2241 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2242 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2243 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2244 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2245 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2246 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2247 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2248 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2249 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2250 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2251 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2252 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2253 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2254 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2255 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2256 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2257 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2258 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2259 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2260 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2261 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2262 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2263 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2264 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2265 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2266 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2267 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2268 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2269 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2270 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2271 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2272 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2273 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2274 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2275 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2276 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2277 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2278 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2279 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2280 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2281 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2282 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2283 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2284 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2285 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2286 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2287 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2288 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2289 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2290 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2291 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2292 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2293 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2294 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2295 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2296 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2297 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2298 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2299 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2300 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2301 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2302 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2303 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2304 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2305 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2306 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2307 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2308 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2309 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2310 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2311 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2312 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2313 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2314 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2315 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2316 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2317 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2318 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2319 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2320 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2321 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2322 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2323 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2324 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2325 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2326 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2327 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2328 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2329 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2330 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2331 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2332 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2333 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2334 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2335 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2336 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2337 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2338 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2339 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2340 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2341 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2342 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2343 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2344 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2345 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2346 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2347 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2348 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2349 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2350 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2351 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2352 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2353 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2354 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2355 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2356 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2357 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2358 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2359 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2360 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2361 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2362 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2363 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2364 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2365 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2366 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2367 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2368 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2369 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2370 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2371 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2372 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2373 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2374 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2375 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2376 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2377 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2378 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2379 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2380 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2381 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2382 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2383 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2384 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2385 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2386 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2387 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2388 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2389 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2390 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2391 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2392 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2393 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2394 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2395 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2396 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2397 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2398 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2399 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2400 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2401 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2402 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2403 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2404 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2405 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2406 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2407 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2408 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2409 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2410 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2411 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2412 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2413 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2414 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2415 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2416 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2417 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2418 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2419 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2420 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2421 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2422 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2423 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2424 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2425 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2426 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2427 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2428 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2429 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2430 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2431 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2432 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2433 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2434 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2435 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2436 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2437 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2438 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2439 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2440 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2441 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2442 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2443 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2444 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2445 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2446 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2447 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2448 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2449 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2450 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2451 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2452 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2453 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2454 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2455 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2456 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2457 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2458 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2459 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2460 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2461 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2462 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2463 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2464 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2465 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2466 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2467 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2468 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2469 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2470 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2471 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2472 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2473 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2474 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2475 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2476 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2477 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2478 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2479 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2480 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2481 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2482 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2483 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2484 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2485 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2486 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2487 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2488 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2489 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2490 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2491 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2492 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2493 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2494 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2495 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2496 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2497 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2498 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2499 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "training epoch: [2500 ] loss: 4.728 correct: 1339.000, total: 3000.000, accuracy: 0.446\n",
            "Finished Training run \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AciJnAh5nfug"
      },
      "source": [
        "columns = [\"epochs\", \"argmax > 0.5\" ,\"argmax < 0.5\", \"focus_true_pred_true\", \"focus_false_pred_true\", \"focus_true_pred_false\", \"focus_false_pred_false\" ]\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train[columns[0]] = np.arange(0,epoch+2)\n",
        "df_train[columns[1]] = analysis_data_tr[:,-2]/30\n",
        "df_train[columns[2]] = analysis_data_tr[:,-1]/30\n",
        "df_train[columns[3]] = analysis_data_tr[:,0]/30\n",
        "df_train[columns[4]] = analysis_data_tr[:,1]/30\n",
        "df_train[columns[5]] = analysis_data_tr[:,2]/30\n",
        "df_train[columns[6]] = analysis_data_tr[:,3]/30"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoQpS_6scRsC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "5e652850-90f0-424f-83df-7491e3ab51fd"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>argmax &lt; 0.5</th>\n",
              "      <th>focus_true_pred_true</th>\n",
              "      <th>focus_false_pred_true</th>\n",
              "      <th>focus_true_pred_false</th>\n",
              "      <th>focus_false_pred_false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>90.200000</td>\n",
              "      <td>5.233333</td>\n",
              "      <td>32.533333</td>\n",
              "      <td>6.533333</td>\n",
              "      <td>55.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29.700000</td>\n",
              "      <td>70.300000</td>\n",
              "      <td>7.166667</td>\n",
              "      <td>29.033333</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>62.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>27.500000</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>4.633333</td>\n",
              "      <td>33.800000</td>\n",
              "      <td>4.866667</td>\n",
              "      <td>56.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>40.066667</td>\n",
              "      <td>59.933333</td>\n",
              "      <td>7.533333</td>\n",
              "      <td>32.366667</td>\n",
              "      <td>4.833333</td>\n",
              "      <td>55.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>45.300000</td>\n",
              "      <td>54.700000</td>\n",
              "      <td>7.800000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>5.166667</td>\n",
              "      <td>53.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>2496</td>\n",
              "      <td>92.500000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>25.300000</td>\n",
              "      <td>19.333333</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>53.766667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>2497</td>\n",
              "      <td>92.500000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>25.300000</td>\n",
              "      <td>19.333333</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>53.766667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>2498</td>\n",
              "      <td>92.500000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>25.300000</td>\n",
              "      <td>19.333333</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>53.766667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>2499</td>\n",
              "      <td>92.500000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>25.300000</td>\n",
              "      <td>19.333333</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>53.766667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500</th>\n",
              "      <td>2500</td>\n",
              "      <td>92.500000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>25.300000</td>\n",
              "      <td>19.333333</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>53.766667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2501 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      epochs  argmax > 0.5  ...  focus_true_pred_false  focus_false_pred_false\n",
              "0          0      9.800000  ...               6.533333               55.700000\n",
              "1          1     29.700000  ...               1.666667               62.133333\n",
              "2          2     27.500000  ...               4.866667               56.700000\n",
              "3          3     40.066667  ...               4.833333               55.266667\n",
              "4          4     45.300000  ...               5.166667               53.033333\n",
              "...      ...           ...  ...                    ...                     ...\n",
              "2496    2496     92.500000  ...               1.600000               53.766667\n",
              "2497    2497     92.500000  ...               1.600000               53.766667\n",
              "2498    2498     92.500000  ...               1.600000               53.766667\n",
              "2499    2499     92.500000  ...               1.600000               53.766667\n",
              "2500    2500     92.500000  ...               1.600000               53.766667\n",
              "\n",
              "[2501 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY_j8B274vuH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "2ebaa44c-d5eb-4397-b807-efbfe88a7f00"
      },
      "source": [
        "%cd /content/\n",
        "plot_analysis(df_train,columns,[0,500,1000,1500,2000,2500])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCnS6r2_3WdU"
      },
      "source": [
        "aph = []\n",
        "for i in bg:\n",
        "  aph.append(F.softmax(i,dim=1).detach().numpy())\n",
        "  \n",
        "aph = np.concatenate(aph,axis=0)\n",
        "# torch.save({\n",
        "#             'epoch': 500,\n",
        "#             'model_state_dict': what_net.state_dict(),\n",
        "#             #'optimizer_state_dict': optimizer_what.state_dict(),\n",
        "#             \"optimizer_alpha\":optim1,\n",
        "#             \"FTPT_analysis\":analysis_data_tr,\n",
        "#             \"alpha\":aph\n",
        "\n",
        "#             }, \"type4_what_net_500.pt\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVzrDOGS4UxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28671bf0-5431-467a-f075-2a72191e1ad6"
      },
      "source": [
        "aph[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.5740100e-06, 6.3374254e-04, 9.6499157e-01, 6.9202935e-05,\n",
              "       3.4132890e-02, 1.3886258e-04, 2.6260859e-05, 5.3815766e-06,\n",
              "       5.2448314e-07], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ut6ZTAXbvqx"
      },
      "source": [
        "avrg = []\n",
        "avrg_lbls = []\n",
        "with torch.no_grad():\n",
        "  for i, data1 in  enumerate(train_loader):\n",
        "          inputs , labels , fore_idx = data1\n",
        "          inputs = inputs.double()\n",
        "          inputs = inputs.to(\"cuda\")\n",
        "          beta  = bg[i]\n",
        "          beta = beta.to(\"cuda\")\n",
        "          avg,alpha = attn_avg(inputs,beta)\n",
        "          \n",
        "          avrg.append(avg.detach().cpu().numpy())\n",
        "          avrg_lbls.append(labels.numpy())\n",
        "avrg= np.concatenate(avrg,axis=0)\n",
        "avrg_lbls = np.concatenate(avrg_lbls,axis=0)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KQFYlmTLG0N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c18a1d00-90ef-4522-b013-9876da50e9dd"
      },
      "source": [
        "%cd /content/drive/MyDrive/Neural_Tangent_Kernel/\n",
        "data = np.load(\"type_4_data.npy\",allow_pickle=True)\n",
        "%cd /content/\n",
        "plot_decision_boundary(what_net,[1,8,2,9],data,bg,avrg,avrg_lbls)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Neural_Tangent_Kernel\n",
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqS70WNvOcIw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f9b46808-a8c8-486d-ffad-bb6be7763503"
      },
      "source": [
        "plt.plot(loss_curi_tr)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f581afc2490>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GmyEWKD92_T"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZQMzXXJa8lB"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6WUeyvNO3iP"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQRNesx7O3Xr"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLPSDVK_QWId"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw2rtHfzFyFA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3lfGywVHL6S"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}