{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "linear_linear_adam_simultaneous_27_exp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2_J4Rw2r0SQ",
        "outputId": "ad1228a6-47aa-4c7c-b573-123444f8bf85"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6fjud_Fr0Sa"
      },
      "source": [
        "# Generate dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "CqdXHO0Cr0Sd",
        "outputId": "4b13cd4b-c032-4942-daf9-6411725eba91"
      },
      "source": [
        "np.random.seed(12)\n",
        "y = np.random.randint(0,10,5000)\n",
        "idx= []\n",
        "for i in range(10):\n",
        "    print(i,sum(y==i))\n",
        "    idx.append(y==i)\n",
        "x = np.zeros((5000,2))\n",
        "np.random.seed(12)\n",
        "x[idx[0],:] = np.random.multivariate_normal(mean = [-1,1],cov=[[0.1,0],[0,0.1]],size=sum(idx[0]))\n",
        "x[idx[1],:] = np.random.multivariate_normal(mean = [3,1],cov=[[0.1,0],[0,0.1]],size=sum(idx[1]))\n",
        "x[idx[2],:] = np.random.multivariate_normal(mean = [0.5,4],cov=[[0.1,0],[0,0.1]],size=sum(idx[2]))\n",
        "x[idx[3],:] = np.random.multivariate_normal(mean = [6,6],cov=[[0.1,0],[0,0.1]],size=sum(idx[3]))\n",
        "x[idx[4],:] = np.random.multivariate_normal(mean = [6,6],cov=[[0.1,0],[0,0.1]],size=sum(idx[4]))\n",
        "x[idx[5],:] = np.random.multivariate_normal(mean = [6,6],cov=[[0.1,0],[0,0.1]],size=sum(idx[5]))\n",
        "x[idx[6],:] = np.random.multivariate_normal(mean = [6,6],cov=[[0.1,0],[0,0.1]],size=sum(idx[6]))\n",
        "x[idx[7],:] = np.random.multivariate_normal(mean = [6,6],cov=[[0.1,0],[0,0.1]],size=sum(idx[7]))\n",
        "x[idx[8],:] = np.random.multivariate_normal(mean = [6,6],cov=[[0.1,0],[0,0.1]],size=sum(idx[8]))\n",
        "x[idx[9],:] = np.random.multivariate_normal(mean = [6,6],cov=[[0.1,0],[0,0.1]],size=sum(idx[9]))\n",
        "color = ['#1F77B4','orange', 'g','brown']\n",
        "name = [1,2,3,0]\n",
        "for i in range(10):\n",
        "  if i==3:\n",
        "    plt.scatter(x[idx[i],0],x[idx[i],1],c=color[3],label=\"D_\"+str(name[i]))\n",
        "  elif i>=4:\n",
        "    plt.scatter(x[idx[i],0],x[idx[i],1],c=color[3])\n",
        "  else:\n",
        "    plt.scatter(x[idx[i],0],x[idx[i],1],c=color[i],label=\"D_\"+str(name[i]))\n",
        "plt.legend()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 530\n",
            "1 463\n",
            "2 494\n",
            "3 517\n",
            "4 488\n",
            "5 497\n",
            "6 493\n",
            "7 507\n",
            "8 492\n",
            "9 519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe10af92ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddhXyODwr0Sk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "a5c370f0-d5f4-4995-9e94-9b52c493c2bd"
      },
      "source": [
        "bg_idx = [ np.where(idx[3] == True)[0], \n",
        "          np.where(idx[4] == True)[0], \n",
        "          np.where(idx[5] == True)[0],\n",
        "          np.where(idx[6] == True)[0], \n",
        "          np.where(idx[7] == True)[0], \n",
        "          np.where(idx[8] == True)[0],\n",
        "          np.where(idx[9] == True)[0]]\n",
        "\n",
        "bg_idx = np.concatenate(bg_idx, axis = 0)\n",
        "x = x - np.mean(x[bg_idx], axis = 0, keepdims = True)\n",
        "x = x/np.std(x[bg_idx], axis = 0, keepdims = True)\n",
        "color = ['#1F77B4','orange', 'g','brown']\n",
        "for i in range(10):\n",
        "  if i==3:\n",
        "    plt.scatter(x[idx[i],0],x[idx[i],1],c=color[3],label=\"D_\"+str(name[i]))\n",
        "  elif i>=4:\n",
        "    plt.scatter(x[idx[i],0],x[idx[i],1],c=color[3])\n",
        "  else:\n",
        "    plt.scatter(x[idx[i],0],x[idx[i],1],c=color[i],label=\"D_\"+str(name[i]))\n",
        "plt.legend()\n",
        "plt.xticks([-10, 0, 10], fontsize=14, fontweight = 'bold')\n",
        "plt.yticks([-6, 0, 8], fontsize=14, fontweight = 'bold')\n",
        "plt.xlabel(\"X1\", fontsize=14, fontweight = 'bold')\n",
        "plt.ylabel(\"X2\" , fontsize=14, fontweight = 'bold')\n",
        "# plt.savefig(fp_cin+\"ds2_data.png\", bbox_inches=\"tight\")\n",
        "# plt.savefig(fp_cin+\"ds2_data.pdf\", bbox_inches=\"tight\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'X2')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyV3N2DIr0Sp"
      },
      "source": [
        "foreground_classes = {'class_0','class_1', 'class_2'}\n",
        "\n",
        "background_classes = {'class_3','class_4', 'class_5', 'class_6','class_7', 'class_8', 'class_9'}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh1mDScsU07I"
      },
      "source": [
        "desired_num = 2000\n",
        "mosaic_list_of_images =[]\n",
        "mosaic_label = []\n",
        "fore_idx=[]\n",
        "for j in range(desired_num):\n",
        "    np.random.seed(j)\n",
        "    fg_class  = np.random.randint(0,3)\n",
        "    fg_idx = 0\n",
        "    a = []\n",
        "    for i in range(9):\n",
        "        if i == fg_idx:\n",
        "            b = np.random.choice(np.where(idx[fg_class]==True)[0],size=1)\n",
        "            a.append(x[b])\n",
        "#             print(\"foreground \"+str(fg_class)+\" present at \" + str(fg_idx))\n",
        "        else:\n",
        "            bg_class = np.random.randint(3,10)\n",
        "            b = np.random.choice(np.where(idx[bg_class]==True)[0],size=1)\n",
        "            a.append(x[b])\n",
        "#             print(\"background \"+str(bg_class)+\" present at \" + str(i))\n",
        "    a = np.concatenate(a,axis=0)\n",
        "    mosaic_list_of_images.append(np.reshape(a,(18,1)))\n",
        "    mosaic_label.append(fg_class)\n",
        "    fore_idx.append(fg_idx)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOsFmWfMr0TR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07fa06f-79c0-4e87-91f8-41c0b94b56d5"
      },
      "source": [
        "mosaic_list_of_images = np.concatenate(mosaic_list_of_images,axis=1).T\n",
        "mosaic_list_of_images[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.12794835e+01, -1.70827549e+01, -1.07177876e-01, -9.40161908e-01,\n",
              "        9.46851025e-01, -1.08338312e-01,  9.93009448e-01, -1.13787054e+00,\n",
              "        1.94337545e-02, -5.89946440e-02,  6.59178562e-01,  3.91575569e-01,\n",
              "        1.72459719e-01, -7.36957052e-01,  1.41670137e-01, -7.90224414e-01,\n",
              "       -6.38808433e-01, -1.14528944e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aIPMgLXNiXW",
        "outputId": "b0e92713-8370-4f3a-f02e-24525a141844"
      },
      "source": [
        "mosaic_list_of_images.shape, mosaic_list_of_images[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2000, 18),\n",
              " array([-2.12794835e+01, -1.70827549e+01, -1.07177876e-01, -9.40161908e-01,\n",
              "         9.46851025e-01, -1.08338312e-01,  9.93009448e-01, -1.13787054e+00,\n",
              "         1.94337545e-02, -5.89946440e-02,  6.59178562e-01,  3.91575569e-01,\n",
              "         1.72459719e-01, -7.36957052e-01,  1.41670137e-01, -7.90224414e-01,\n",
              "        -6.38808433e-01, -1.14528944e-01]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPoIwbMHx44n"
      },
      "source": [
        "class MosaicDataset(Dataset):\n",
        "  \"\"\"MosaicDataset dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "        csv_file (string): Path to the csv file with annotations.\n",
        "        root_dir (string): Directory with all the images.\n",
        "        transform (callable, optional): Optional transform to be applied\n",
        "            on a sample.\n",
        "    \"\"\"\n",
        "    self.mosaic = mosaic_list_of_images\n",
        "    self.label = mosaic_label\n",
        "    self.fore_idx = fore_idx\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOPAJQJeW8Ah"
      },
      "source": [
        "batch = 250\n",
        "msd1 = MosaicDataset(mosaic_list_of_images[0:1000], mosaic_label[0:1000] , fore_idx[0:1000])\n",
        "train_loader = DataLoader( msd1 ,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjNiQgxZW8bA"
      },
      "source": [
        "batch = 250\n",
        "msd2 = MosaicDataset(mosaic_list_of_images[1000:2000], mosaic_label[1000:2000] , fore_idx[1000:2000])\n",
        "test_loader = DataLoader( msd2 ,batch_size= batch ,shuffle=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30ZAjix3x8CM"
      },
      "source": [
        "class Focus(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(Focus,self).__init__()\n",
        "      self.fc1 = nn.Linear(2,1)\n",
        "\n",
        "  def forward(self,z):\n",
        "      x = torch.zeros([batch,9],dtype=torch.float64)\n",
        "      y = torch.zeros([batch,2], dtype=torch.float64)\n",
        "      x,y = x.to(\"cuda\"),y.to(\"cuda\")\n",
        "      for i in range(9):\n",
        "          x[:,i] = self.helper(z[:,2*i:2*i+2])[:,0]\n",
        "          #print(k[:,0].shape,x[:,i].shape)\n",
        "      x = F.softmax(x,dim=1)   # alphas\n",
        "      x1 = x[:,0]\n",
        "      for i in range(9):\n",
        "          x1 = x[:,i]          \n",
        "          #print()\n",
        "          y = y+torch.mul(x1[:,None],z[:,2*i:2*i+2])\n",
        "      # print(y.shape, x.shape)\n",
        "      return x , y\n",
        "    \n",
        "  def helper(self, x):\n",
        "    x = x.view(-1, 2)\n",
        "    # x = F.relu(self.fc1(x))\n",
        "    x = (self.fc1(x))\n",
        "\n",
        "    return x"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dYXnywAD-4l"
      },
      "source": [
        "class Classification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classification, self).__init__()\n",
        "    self.fc1 = nn.Linear(2, 3)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 2)\n",
        "    x = self.fc1(x)\n",
        "    # print(x.shape)\n",
        "    return x"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl41sE8vFERk"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train(train_loader, test_loader, focus_net, classify):    \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer_classify = optim.Adam(classify.parameters(), lr=0.01 ) #, momentum=0.9)\n",
        "  optimizer_focus = optim.Adam(focus_net.parameters(), lr=0.01 ) #, momentum=0.9)\n",
        "\n",
        "  print('-'*50)\n",
        "  print(focus_net.fc1.weight, classify.fc1.weight, classify.fc1.bias)\n",
        "  nos_epochs = 1000\n",
        "  loss_ret=0.0\n",
        "  for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    epoch_loss = []\n",
        "    cnt=0\n",
        "\n",
        "    iteration = desired_num // batch\n",
        "    \n",
        "    #training data set\n",
        "    \n",
        "    for i, data in  enumerate(train_loader):\n",
        "      inputs , labels , fore_idx = data\n",
        "      inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "      inputs = inputs.double()\n",
        "      labels = labels\n",
        "      # zero the parameter gradients\n",
        "      \n",
        "      optimizer_focus.zero_grad()\n",
        "      optimizer_classify.zero_grad()\n",
        "      \n",
        "      alphas, avg_images = focus_net(inputs)\n",
        "      outputs = classify(avg_images)\n",
        "\n",
        "      _,predicted = torch.max(outputs.data, 1)\n",
        "      # print(predicted)\n",
        "      # print(outputs.shape,labels.shape)\n",
        "      # print(outputs)\n",
        "      # print(labels)\n",
        "      loss = criterion(outputs, labels) \n",
        "      loss.backward()\n",
        "      optimizer_focus.step()\n",
        "      optimizer_classify.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      # mini = 3\n",
        "      # if cnt % mini == mini-1 :    # print every 40 mini-batches\n",
        "      epoch_loss.append(running_loss)\n",
        "      running_loss = 0.0\n",
        "      cnt=cnt+1\n",
        "    loss_ret = np.mean(epoch_loss)\n",
        "    if(epoch%200==0):\n",
        "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, np.mean(epoch_loss)))\n",
        "    if(np.mean(epoch_loss) <= 0.001):\n",
        "        break;\n",
        "\n",
        "  with torch.no_grad():\n",
        "    focus_true_pred_true =0\n",
        "    focus_false_pred_true =0\n",
        "    focus_true_pred_false =0\n",
        "    focus_false_pred_false =0\n",
        "\n",
        "    argmax_more_than_half = 0\n",
        "    argmax_less_than_half =0\n",
        "    for data in test_loader:\n",
        "      inputs, labels , fore_idx = data\n",
        "      inputs = inputs.double()\n",
        "      inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
        "      alphas, avg_images = focus_net(inputs)\n",
        "      outputs = classify(avg_images)\n",
        "      _,predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "      for j in range (batch):\n",
        "        focus = torch.argmax(alphas[j])\n",
        "\n",
        "        if(alphas[j][focus] >= 0.5):\n",
        "          argmax_more_than_half +=1\n",
        "        else:\n",
        "          argmax_less_than_half +=1\n",
        "\n",
        "        # print(focus, fore_idx[j], predicted[j], labels[j])\n",
        "        if(focus == fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_true_pred_true += 1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] == labels[j]):\n",
        "          focus_false_pred_true +=1\n",
        "\n",
        "        elif(focus == fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_true_pred_false +=1\n",
        "\n",
        "        elif(focus != fore_idx[j] and predicted[j] != labels[j]):\n",
        "          focus_false_pred_false +=1\n",
        "\n",
        "  print('Finished Training')  \n",
        "  return loss_ret, argmax_more_than_half/10, focus_true_pred_true/10, focus_false_pred_true/10, focus_true_pred_false/10 , focus_false_pred_false/10, focus_net.fc1.weight, classify.fc1.weight, classify.fc1.bias\n",
        "    \n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0rXlZZfUK3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c31906e-a6ed-4f28-c3b6-39626ba353db"
      },
      "source": [
        "torch.manual_seed(12)\n",
        "focus_net = Focus().double()\n",
        "focus_net.fc1.weight = torch.nn.Parameter(torch.tensor(np.array([[0.0, 0.0]])))\n",
        "torch.manual_seed(12)\n",
        "classify = Classification().double()\n",
        "classify.fc1.weight = torch.nn.Parameter(torch.tensor(np.array([[0.0, 0.0], [0.0, 0.0], [0.0, 0.0] ])))\n",
        "classify.fc1.bias = torch.nn.Parameter(torch.tensor(np.array([0.0, 0.0, 0.0])))\n",
        "focus_net = focus_net.to(\"cuda\")\n",
        "classify = classify.to(\"cuda\")\n",
        "# print(\"--\"*40,\"a,b,c = \",a[i],b[j],c[k])\n",
        "print(focus_net.fc1.weight, classify.fc1.weight, classify.fc1.bias)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[0., 0.]], device='cuda:0', dtype=torch.float64, requires_grad=True) Parameter containing:\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], device='cuda:0', dtype=torch.float64, requires_grad=True) Parameter containing:\n",
            "tensor([0., 0., 0.], device='cuda:0', dtype=torch.float64, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEXvq7EWUck2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c171ca59-6ce7-4685-fe80-000cbbe138ad"
      },
      "source": [
        "cost, alpha_per, ftpt, ffpt, ftpf, ffpf, f_a, f_b, f_c = train(train_loader, test_loader, focus_net, classify)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0., 0.]], device='cuda:0', dtype=torch.float64, requires_grad=True) Parameter containing:\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], device='cuda:0', dtype=torch.float64, requires_grad=True) Parameter containing:\n",
            "tensor([0., 0., 0.], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "[1,     5] loss: 1.081\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKmHjMED1jMR"
      },
      "source": [
        "def tensor_to_list1d(var):\n",
        "  r = var.shape[0]\n",
        "  res = []\n",
        "  for i in range(r):\n",
        "    res.append(np.round(var[i].item(),3))\n",
        "  return res"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-uuIPE90W_Z"
      },
      "source": [
        "def tensor_to_list2d(var):\n",
        "  r = var.shape[0]\n",
        "  c = var.shape[1]\n",
        "  res = []\n",
        "  for i in range(r):\n",
        "    temp=[]\n",
        "    for j in range(c):\n",
        "      temp.append(np.round(var[i][j].item(),3))\n",
        "    res.append(temp)\n",
        "  return res"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMp9RoCNz15_",
        "outputId": "599fd24d-2770-4e02-f037-975c7947c935"
      },
      "source": [
        "f_a[0][0].item(), f_a[0][1].item(), f_a, f_a.shape[0]"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.05899574000165298, -0.23169413344374595, Parameter containing:\n",
              " tensor([[-0.0590, -0.2317]], device='cuda:0', dtype=torch.float64,\n",
              "        requires_grad=True), 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdhsT7vX1VwI",
        "outputId": "fc3cfbdb-8780-4944-a5b8-136cbe80ef5d"
      },
      "source": [
        "f_c.shape"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_THOu8Xg4NaS",
        "outputId": "40e98dbc-3971-4782-d7a0-a13bbcff6749"
      },
      "source": [
        "tensor_to_list2d(f_a)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-0.052, -0.221]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm4ZxDs30-To",
        "outputId": "94eb7b03-ec4a-4f95-f01f-23c948919b7e"
      },
      "source": [
        "tensor_to_list1d(f_c)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-3.488, 1.78, 4.611]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd7ScJj9g6rl"
      },
      "source": [
        "a = [-0.1, 0.0, 0.1]\n",
        "b = [-0.1, 0.0, 0.1]\n",
        "c = [-0.1, 0.0, 0.1]"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo5QyZobhHpM",
        "outputId": "ecd93b14-0116-4491-cf1d-3d3dcbda5bfd"
      },
      "source": [
        "all_loss=[]\n",
        "all_alphas_more_than_half=[]\n",
        "all_ftpt=[]\n",
        "all_ffpt=[]\n",
        "all_ftpf = []\n",
        "all_ffpf= []\n",
        "init_a = []\n",
        "init_b = []\n",
        "init_c = []\n",
        "final_a=[]\n",
        "final_b = []\n",
        "final_c = []\n",
        "\n",
        "for i in range(3):\n",
        "  for j in range(3):\n",
        "    for k in range(3):\n",
        "      torch.manual_seed(12)\n",
        "      focus_net = Focus().double()\n",
        "      focus_net.fc1.weight = torch.nn.Parameter(torch.tensor(np.array([[a[i], b[j]]])))\n",
        "      torch.manual_seed(12)\n",
        "      classify = Classification().double()\n",
        "      classify.fc1.weight = torch.nn.Parameter(torch.tensor(np.array([[a[i], b[j]],[a[i], b[j]],[a[i], b[j]]])))\n",
        "      classify.fc1.bias = torch.nn.Parameter(torch.tensor(np.array([a[i], b[j], c[k]])))\n",
        "      focus_net = focus_net.to(\"cuda\")\n",
        "      classify = classify.to(\"cuda\")\n",
        "      print(\"--\"*40,\"a,b,c = \",a[i],b[j],c[k])\n",
        "      cost, alpha_per, ftpt, ffpt, ftpf, ffpf, f_a, f_b, f_c = train(train_loader, test_loader, focus_net, classify)\n",
        "      print(cost, alpha_per, ftpt, ffpt, ftpf, ffpf)\n",
        "      init_a.append([a[i], b[j]])\n",
        "      init_b.append([[a[i], b[j]],[a[i], b[j]],[a[i], b[j]]])\n",
        "      init_c.append([a[i], b[j], c[k]])\n",
        "      final_a.append(tensor_to_list2d(f_a))\n",
        "      final_b.append(tensor_to_list2d(f_b))\n",
        "      final_c.append(tensor_to_list1d(f_c))\n",
        "      all_loss.append(np.round(cost,3))\n",
        "      all_alphas_more_than_half.append(alpha_per)\n",
        "      all_ftpt.append(ftpt)\n",
        "      all_ffpt.append(ffpt)\n",
        "      all_ftpf.append(ftpf)\n",
        "      all_ffpf.append(ffpf)\n",
        "\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------------------- a,b,c =  -0.1 -0.1 -0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[-0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[-0.1000, -0.1000],\n",
            "        [-0.1000, -0.1000],\n",
            "        [-0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([-0.1000, -0.1000, -0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.031\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.000994904100129965 95.3 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  -0.1 -0.1 0.0\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[-0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[-0.1000, -0.1000],\n",
            "        [-0.1000, -0.1000],\n",
            "        [-0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([-0.1000, -0.1000,  0.0000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.027\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.000989827606941856 94.7 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  -0.1 -0.1 0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[-0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[-0.1000, -0.1000],\n",
            "        [-0.1000, -0.1000],\n",
            "        [-0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([-0.1000, -0.1000,  0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.023\n",
            "[201,     5] loss: 0.011\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009874746358544213 93.2 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  -0.1 0.0 -0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[-0.1000,  0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[-0.1000,  0.0000],\n",
            "        [-0.1000,  0.0000],\n",
            "        [-0.1000,  0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([-0.1000,  0.0000, -0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.033\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.004\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009892306504960787 100.0 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  -0.1 0.0 0.0\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[-0.1000,  0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[-0.1000,  0.0000],\n",
            "        [-0.1000,  0.0000],\n",
            "        [-0.1000,  0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([-0.1000,  0.0000,  0.0000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.034\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.000993082980102773 100.0 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  -0.1 0.0 0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[-0.1000,  0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[-0.1000,  0.0000],\n",
            "        [-0.1000,  0.0000],\n",
            "        [-0.1000,  0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([-0.1000,  0.0000,  0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.039\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009992350451253952 87.3 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  -0.1 0.1 -0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[-0.1000,  0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[-0.1000,  0.1000],\n",
            "        [-0.1000,  0.1000],\n",
            "        [-0.1000,  0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([-0.1000,  0.1000, -0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.053\n",
            "[201,     5] loss: 0.009\n",
            "[401,     5] loss: 0.004\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0014458321632960076 100.0 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  -0.1 0.1 0.0\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[-0.1000,  0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[-0.1000,  0.1000],\n",
            "        [-0.1000,  0.1000],\n",
            "        [-0.1000,  0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([-0.1000,  0.1000,  0.0000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.052\n",
            "[201,     5] loss: 0.009\n",
            "[401,     5] loss: 0.004\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.001409690484271552 100.0 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  -0.1 0.1 0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[-0.1000,  0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[-0.1000,  0.1000],\n",
            "        [-0.1000,  0.1000],\n",
            "        [-0.1000,  0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([-0.1000,  0.1000,  0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.054\n",
            "[201,     5] loss: 0.009\n",
            "[401,     5] loss: 0.004\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0014041455741361638 100.0 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.0 -0.1 -0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[ 0.0000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[ 0.0000, -0.1000],\n",
            "        [ 0.0000, -0.1000],\n",
            "        [ 0.0000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([ 0.0000, -0.1000, -0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.049\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.001088080763487966 99.9 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.0 -0.1 0.0\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[ 0.0000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[ 0.0000, -0.1000],\n",
            "        [ 0.0000, -0.1000],\n",
            "        [ 0.0000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([ 0.0000, -0.1000,  0.0000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.047\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.001100699995570405 99.9 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.0 -0.1 0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[ 0.0000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[ 0.0000, -0.1000],\n",
            "        [ 0.0000, -0.1000],\n",
            "        [ 0.0000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([ 0.0000, -0.1000,  0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.044\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0011138765227881136 99.8 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.0 0.0 -0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0., 0.]], device='cuda:0', dtype=torch.float64, requires_grad=True) Parameter containing:\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], device='cuda:0', dtype=torch.float64, requires_grad=True) Parameter containing:\n",
            "tensor([ 0.0000,  0.0000, -0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.081\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009961985553268503 93.5 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.0 0.0 0.0\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0., 0.]], device='cuda:0', dtype=torch.float64, requires_grad=True) Parameter containing:\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], device='cuda:0', dtype=torch.float64, requires_grad=True) Parameter containing:\n",
            "tensor([0., 0., 0.], device='cuda:0', dtype=torch.float64, requires_grad=True)\n",
            "[1,     5] loss: 1.081\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009898601926206629 93.1 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.0 0.0 0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0., 0.]], device='cuda:0', dtype=torch.float64, requires_grad=True) Parameter containing:\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], device='cuda:0', dtype=torch.float64, requires_grad=True) Parameter containing:\n",
            "tensor([0.0000, 0.0000, 0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.081\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009973951678850703 94.2 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.0 0.1 -0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0.0000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[0.0000, 0.1000],\n",
            "        [0.0000, 0.1000],\n",
            "        [0.0000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([ 0.0000,  0.1000, -0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.093\n",
            "[201,     5] loss: 0.011\n",
            "[401,     5] loss: 0.006\n",
            "[601,     5] loss: 0.005\n",
            "[801,     5] loss: 0.004\n",
            "Finished Training\n",
            "0.0028770556103530076 73.9 68.1 31.6 0.2 0.1\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.0 0.1 0.0\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0.0000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[0.0000, 0.1000],\n",
            "        [0.0000, 0.1000],\n",
            "        [0.0000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([0.0000, 0.1000, 0.0000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.092\n",
            "[201,     5] loss: 0.009\n",
            "[401,     5] loss: 0.004\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.001120575516885706 100.0 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.0 0.1 0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0.0000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[0.0000, 0.1000],\n",
            "        [0.0000, 0.1000],\n",
            "        [0.0000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([0.0000, 0.1000, 0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.093\n",
            "[201,     5] loss: 0.009\n",
            "[401,     5] loss: 0.004\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.00099687922888745 100.0 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.1 -0.1 -0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[ 0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[ 0.1000, -0.1000],\n",
            "        [ 0.1000, -0.1000],\n",
            "        [ 0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([ 0.1000, -0.1000, -0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.080\n",
            "[201,     5] loss: 0.015\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.002\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009808542137348594 67.0 69.2 30.8 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.1 -0.1 0.0\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[ 0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[ 0.1000, -0.1000],\n",
            "        [ 0.1000, -0.1000],\n",
            "        [ 0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([ 0.1000, -0.1000,  0.0000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.079\n",
            "[201,     5] loss: 0.014\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.002\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009980903952126533 67.0 70.8 29.2 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.1 -0.1 0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[ 0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[ 0.1000, -0.1000],\n",
            "        [ 0.1000, -0.1000],\n",
            "        [ 0.1000, -0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([ 0.1000, -0.1000,  0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.078\n",
            "[201,     5] loss: 0.012\n",
            "[401,     5] loss: 0.004\n",
            "[601,     5] loss: 0.002\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009860187525794935 67.0 69.2 30.8 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.1 0.0 -0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0.1000, 0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[0.1000, 0.0000],\n",
            "        [0.1000, 0.0000],\n",
            "        [0.1000, 0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([ 0.1000,  0.0000, -0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.097\n",
            "[201,     5] loss: 0.015\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.002\n",
            "[801,     5] loss: 0.001\n",
            "Finished Training\n",
            "0.00098580856879772 67.0 69.7 30.3 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.1 0.0 0.0\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0.1000, 0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[0.1000, 0.0000],\n",
            "        [0.1000, 0.0000],\n",
            "        [0.1000, 0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([0.1000, 0.0000, 0.0000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.095\n",
            "[201,     5] loss: 0.014\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.002\n",
            "[801,     5] loss: 0.001\n",
            "Finished Training\n",
            "0.0009844981063177002 67.0 69.7 30.3 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.1 0.0 0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0.1000, 0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[0.1000, 0.0000],\n",
            "        [0.1000, 0.0000],\n",
            "        [0.1000, 0.0000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([0.1000, 0.0000, 0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.096\n",
            "[201,     5] loss: 0.014\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.002\n",
            "[801,     5] loss: 0.001\n",
            "Finished Training\n",
            "0.0009914125799292098 67.0 69.7 30.3 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.1 0.1 -0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0.1000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[0.1000, 0.1000],\n",
            "        [0.1000, 0.1000],\n",
            "        [0.1000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([ 0.1000,  0.1000, -0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.100\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009897986470320571 98.9 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.1 0.1 0.0\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0.1000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[0.1000, 0.1000],\n",
            "        [0.1000, 0.1000],\n",
            "        [0.1000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([0.1000, 0.1000, 0.0000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.097\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009939857489467381 98.9 100.0 0.0 0.0 0.0\n",
            "-------------------------------------------------------------------------------- a,b,c =  0.1 0.1 0.1\n",
            "--------------------------------------------------\n",
            "Parameter containing:\n",
            "tensor([[0.1000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([[0.1000, 0.1000],\n",
            "        [0.1000, 0.1000],\n",
            "        [0.1000, 0.1000]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([0.1000, 0.1000, 0.1000], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n",
            "[1,     5] loss: 1.097\n",
            "[201,     5] loss: 0.010\n",
            "[401,     5] loss: 0.005\n",
            "[601,     5] loss: 0.003\n",
            "[801,     5] loss: 0.002\n",
            "Finished Training\n",
            "0.0009968109849870957 98.9 100.0 0.0 0.0 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gQoPST5zW2t"
      },
      "source": [
        "# df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In76SYH_zZHV"
      },
      "source": [
        "columns = [\"init_a\", \"init_b\", \"init_c\", \"final_a\", \"final_b\", \"final_c\", \"train_loss\", \"argmax > 0.5\" , \"ftpt\", \"ffpt\", \"ftpf\", \"ffpf\" ]"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS4HtOHEzZ0E"
      },
      "source": [
        "df_test[columns[0]] = init_a\n",
        "df_test[columns[1]] = init_b\n",
        "df_test[columns[2]] = init_c\n",
        "df_test[columns[3]] = final_a\n",
        "df_test[columns[4]] = final_b\n",
        "df_test[columns[5]] = final_c\n",
        "df_test[columns[6]] = all_loss\n",
        "df_test[columns[7]] = all_alphas_more_than_half\n",
        "df_test[columns[8]] = all_ftpt\n",
        "df_test[columns[9]] = all_ffpt\n",
        "df_test[columns[10]] = all_ftpf\n",
        "df_test[columns[11]] = all_ffpf"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tlaNFbwNGfju",
        "outputId": "34a2630a-5c7a-4df5-8364-ec5c5afdd682"
      },
      "source": [
        "df_test"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>init_a</th>\n",
              "      <th>init_b</th>\n",
              "      <th>init_c</th>\n",
              "      <th>final_a</th>\n",
              "      <th>final_b</th>\n",
              "      <th>final_c</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>argmax &gt; 0.5</th>\n",
              "      <th>ftpt</th>\n",
              "      <th>ffpt</th>\n",
              "      <th>ftpf</th>\n",
              "      <th>ffpf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.1, -0.1]</td>\n",
              "      <td>[[-0.1, -0.1], [-0.1, -0.1], [-0.1, -0.1]]</td>\n",
              "      <td>[-0.1, -0.1, -0.1]</td>\n",
              "      <td>[[-0.056, -0.22]]</td>\n",
              "      <td>[[-0.264, -0.707], [1.475, -2.01], [-1.361, 2....</td>\n",
              "      <td>[-3.931, 2.447, 4.165]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>95.3</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.1, -0.1]</td>\n",
              "      <td>[[-0.1, -0.1], [-0.1, -0.1], [-0.1, -0.1]]</td>\n",
              "      <td>[-0.1, -0.1, 0.0]</td>\n",
              "      <td>[[-0.052, -0.225]]</td>\n",
              "      <td>[[-0.251, -0.702], [1.489, -2.008], [-1.332, 2...</td>\n",
              "      <td>[-3.921, 2.419, 4.233]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>94.7</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.1, -0.1]</td>\n",
              "      <td>[[-0.1, -0.1], [-0.1, -0.1], [-0.1, -0.1]]</td>\n",
              "      <td>[-0.1, -0.1, 0.1]</td>\n",
              "      <td>[[-0.049, -0.23]]</td>\n",
              "      <td>[[-0.236, -0.694], [1.505, -2.005], [-1.3, 2.0...</td>\n",
              "      <td>[-3.913, 2.381, 4.292]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>93.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.1, 0.0]</td>\n",
              "      <td>[[-0.1, 0.0], [-0.1, 0.0], [-0.1, 0.0]]</td>\n",
              "      <td>[-0.1, 0.0, -0.1]</td>\n",
              "      <td>[[-0.161, -0.089]]</td>\n",
              "      <td>[[-0.293, -0.508], [1.444, -1.962], [-1.391, 2...</td>\n",
              "      <td>[-3.175, 1.199, 5.804]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-0.1, 0.0]</td>\n",
              "      <td>[[-0.1, 0.0], [-0.1, 0.0], [-0.1, 0.0]]</td>\n",
              "      <td>[-0.1, 0.0, 0.0]</td>\n",
              "      <td>[[-0.093, -0.167]]</td>\n",
              "      <td>[[-0.276, -0.497], [1.448, -1.932], [-1.346, 2...</td>\n",
              "      <td>[-3.109, 1.228, 5.458]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[-0.1, 0.0]</td>\n",
              "      <td>[[-0.1, 0.0], [-0.1, 0.0], [-0.1, 0.0]]</td>\n",
              "      <td>[-0.1, 0.0, 0.1]</td>\n",
              "      <td>[[-0.038, -0.244]]</td>\n",
              "      <td>[[-0.269, -0.473], [1.463, -1.911], [-1.314, 2...</td>\n",
              "      <td>[-3.112, 1.284, 5.237]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>87.3</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[-0.1, 0.1]</td>\n",
              "      <td>[[-0.1, 0.1], [-0.1, 0.1], [-0.1, 0.1]]</td>\n",
              "      <td>[-0.1, 0.1, -0.1]</td>\n",
              "      <td>[[-0.53, -0.13]]</td>\n",
              "      <td>[[-0.132, -0.588], [1.682, -2.148], [-1.418, 2...</td>\n",
              "      <td>[-2.855, 1.184, 5.524]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[-0.1, 0.1]</td>\n",
              "      <td>[[-0.1, 0.1], [-0.1, 0.1], [-0.1, 0.1]]</td>\n",
              "      <td>[-0.1, 0.1, 0.0]</td>\n",
              "      <td>[[-0.516, -0.137]]</td>\n",
              "      <td>[[-0.139, -0.544], [1.671, -2.103], [-1.402, 2...</td>\n",
              "      <td>[-2.836, 1.157, 5.746]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[-0.1, 0.1]</td>\n",
              "      <td>[[-0.1, 0.1], [-0.1, 0.1], [-0.1, 0.1]]</td>\n",
              "      <td>[-0.1, 0.1, 0.1]</td>\n",
              "      <td>[[-0.503, -0.144]]</td>\n",
              "      <td>[[-0.144, -0.514], [1.665, -2.073], [-1.398, 2...</td>\n",
              "      <td>[-2.822, 1.14, 5.804]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[0.0, -0.1]</td>\n",
              "      <td>[[0.0, -0.1], [0.0, -0.1], [0.0, -0.1]]</td>\n",
              "      <td>[0.0, -0.1, -0.1]</td>\n",
              "      <td>[[-0.088, -0.169]]</td>\n",
              "      <td>[[-0.038, -0.69], [1.744, -2.022], [-1.31, 2.3...</td>\n",
              "      <td>[-3.762, 2.708, 3.528]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>99.9</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[0.0, -0.1]</td>\n",
              "      <td>[[0.0, -0.1], [0.0, -0.1], [0.0, -0.1]]</td>\n",
              "      <td>[0.0, -0.1, 0.0]</td>\n",
              "      <td>[[-0.087, -0.172]]</td>\n",
              "      <td>[[-0.031, -0.672], [1.749, -2.012], [-1.3, 2.3...</td>\n",
              "      <td>[-3.729, 2.611, 3.54]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>99.9</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[0.0, -0.1]</td>\n",
              "      <td>[[0.0, -0.1], [0.0, -0.1], [0.0, -0.1]]</td>\n",
              "      <td>[0.0, -0.1, 0.1]</td>\n",
              "      <td>[[-0.084, -0.177]]</td>\n",
              "      <td>[[-0.027, -0.644], [1.751, -1.995], [-1.29, 2....</td>\n",
              "      <td>[-3.683, 2.48, 3.574]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>99.8</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[0.0, 0.0]</td>\n",
              "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]</td>\n",
              "      <td>[0.0, 0.0, -0.1]</td>\n",
              "      <td>[[-0.052, -0.223]]</td>\n",
              "      <td>[[-0.07, -0.456], [1.714, -1.893], [-1.21, 2.4...</td>\n",
              "      <td>[-3.433, 1.701, 4.551]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>93.5</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[0.0, 0.0]</td>\n",
              "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>[[-0.052, -0.221]]</td>\n",
              "      <td>[[-0.049, -0.456], [1.74, -1.899], [-1.198, 2....</td>\n",
              "      <td>[-3.413, 1.715, 4.537]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>93.1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[0.0, 0.0]</td>\n",
              "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]</td>\n",
              "      <td>[0.0, 0.0, 0.1]</td>\n",
              "      <td>[[-0.054, -0.217]]</td>\n",
              "      <td>[[-0.015, -0.473], [1.785, -1.925], [-1.182, 2...</td>\n",
              "      <td>[-3.399, 1.744, 4.471]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>94.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[0.0, 0.1]</td>\n",
              "      <td>[[0.0, 0.1], [0.0, 0.1], [0.0, 0.1]]</td>\n",
              "      <td>[0.0, 0.1, -0.1]</td>\n",
              "      <td>[[-0.846, 0.836]]</td>\n",
              "      <td>[[1.096, -2.234], [-0.583, 3.533], [-0.942, 1....</td>\n",
              "      <td>[-5.295, 4.153, -2.39]</td>\n",
              "      <td>0.003</td>\n",
              "      <td>73.9</td>\n",
              "      <td>68.1</td>\n",
              "      <td>31.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[0.0, 0.1]</td>\n",
              "      <td>[[0.0, 0.1], [0.0, 0.1], [0.0, 0.1]]</td>\n",
              "      <td>[0.0, 0.1, 0.0]</td>\n",
              "      <td>[[-0.234, -0.062]]</td>\n",
              "      <td>[[0.015, -0.46], [1.825, -2.009], [-1.208, 2.5...</td>\n",
              "      <td>[-3.009, 1.142, 5.617]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[0.0, 0.1]</td>\n",
              "      <td>[[0.0, 0.1], [0.0, 0.1], [0.0, 0.1]]</td>\n",
              "      <td>[0.0, 0.1, 0.1]</td>\n",
              "      <td>[[-0.145, -0.107]]</td>\n",
              "      <td>[[-0.096, -0.348], [1.682, -1.855], [-1.245, 2...</td>\n",
              "      <td>[-2.953, 1.222, 5.543]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[0.1, -0.1]</td>\n",
              "      <td>[[0.1, -0.1], [0.1, -0.1], [0.1, -0.1]]</td>\n",
              "      <td>[0.1, -0.1, -0.1]</td>\n",
              "      <td>[[0.233, -0.607]]</td>\n",
              "      <td>[[-0.857, 0.763], [1.129, -1.186], [0.329, 0.5...</td>\n",
              "      <td>[-4.611, -3.782, 5.131]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.2</td>\n",
              "      <td>30.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[0.1, -0.1]</td>\n",
              "      <td>[[0.1, -0.1], [0.1, -0.1], [0.1, -0.1]]</td>\n",
              "      <td>[0.1, -0.1, 0.0]</td>\n",
              "      <td>[[0.226, -0.611]]</td>\n",
              "      <td>[[-0.868, 0.753], [1.118, -1.185], [0.327, 0.5...</td>\n",
              "      <td>[-4.673, -3.838, 5.081]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>67.0</td>\n",
              "      <td>70.8</td>\n",
              "      <td>29.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[0.1, -0.1]</td>\n",
              "      <td>[[0.1, -0.1], [0.1, -0.1], [0.1, -0.1]]</td>\n",
              "      <td>[0.1, -0.1, 0.1]</td>\n",
              "      <td>[[0.23, -0.603]]</td>\n",
              "      <td>[[-0.883, 0.762], [1.103, -1.181], [0.304, 0.5...</td>\n",
              "      <td>[-4.798, -3.928, 5.022]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.2</td>\n",
              "      <td>30.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[0.1, 0.0]</td>\n",
              "      <td>[[0.1, 0.0], [0.1, 0.0], [0.1, 0.0]]</td>\n",
              "      <td>[0.1, 0.0, -0.1]</td>\n",
              "      <td>[[0.228, -0.602]]</td>\n",
              "      <td>[[-0.887, 0.81], [1.133, -1.17], [0.301, 0.628]]</td>\n",
              "      <td>[-4.279, -3.405, 5.55]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.7</td>\n",
              "      <td>30.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[0.1, 0.0]</td>\n",
              "      <td>[[0.1, 0.0], [0.1, 0.0], [0.1, 0.0]]</td>\n",
              "      <td>[0.1, 0.0, 0.0]</td>\n",
              "      <td>[[0.228, -0.602]]</td>\n",
              "      <td>[[-0.866, 0.807], [1.155, -1.174], [0.32, 0.627]]</td>\n",
              "      <td>[-4.259, -3.398, 5.568]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.7</td>\n",
              "      <td>30.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[0.1, 0.0]</td>\n",
              "      <td>[[0.1, 0.0], [0.1, 0.0], [0.1, 0.0]]</td>\n",
              "      <td>[0.1, 0.0, 0.1]</td>\n",
              "      <td>[[0.228, -0.601]]</td>\n",
              "      <td>[[-0.868, 0.806], [1.152, -1.174], [0.318, 0.6...</td>\n",
              "      <td>[-4.299, -3.437, 5.513]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>67.0</td>\n",
              "      <td>69.7</td>\n",
              "      <td>30.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[0.1, 0.1]</td>\n",
              "      <td>[[0.1, 0.1], [0.1, 0.1], [0.1, 0.1]]</td>\n",
              "      <td>[0.1, 0.1, -0.1]</td>\n",
              "      <td>[[-0.079, -0.177]]</td>\n",
              "      <td>[[0.272, -0.611], [2.15, -2.12], [-0.979, 2.411]]</td>\n",
              "      <td>[-3.54, 1.877, 3.988]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>98.9</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[0.1, 0.1]</td>\n",
              "      <td>[[0.1, 0.1], [0.1, 0.1], [0.1, 0.1]]</td>\n",
              "      <td>[0.1, 0.1, 0.0]</td>\n",
              "      <td>[[-0.079, -0.177]]</td>\n",
              "      <td>[[0.275, -0.614], [2.15, -2.117], [-0.973, 2.4...</td>\n",
              "      <td>[-3.495, 1.977, 4.029]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>98.9</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[0.1, 0.1]</td>\n",
              "      <td>[[0.1, 0.1], [0.1, 0.1], [0.1, 0.1]]</td>\n",
              "      <td>[0.1, 0.1, 0.1]</td>\n",
              "      <td>[[-0.078, -0.178]]</td>\n",
              "      <td>[[0.272, -0.611], [2.145, -2.11], [-0.974, 2.4...</td>\n",
              "      <td>[-3.474, 2.014, 4.047]</td>\n",
              "      <td>0.001</td>\n",
              "      <td>98.9</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          init_a                                      init_b  ... ftpf ffpf\n",
              "0   [-0.1, -0.1]  [[-0.1, -0.1], [-0.1, -0.1], [-0.1, -0.1]]  ...  0.0  0.0\n",
              "1   [-0.1, -0.1]  [[-0.1, -0.1], [-0.1, -0.1], [-0.1, -0.1]]  ...  0.0  0.0\n",
              "2   [-0.1, -0.1]  [[-0.1, -0.1], [-0.1, -0.1], [-0.1, -0.1]]  ...  0.0  0.0\n",
              "3    [-0.1, 0.0]     [[-0.1, 0.0], [-0.1, 0.0], [-0.1, 0.0]]  ...  0.0  0.0\n",
              "4    [-0.1, 0.0]     [[-0.1, 0.0], [-0.1, 0.0], [-0.1, 0.0]]  ...  0.0  0.0\n",
              "5    [-0.1, 0.0]     [[-0.1, 0.0], [-0.1, 0.0], [-0.1, 0.0]]  ...  0.0  0.0\n",
              "6    [-0.1, 0.1]     [[-0.1, 0.1], [-0.1, 0.1], [-0.1, 0.1]]  ...  0.0  0.0\n",
              "7    [-0.1, 0.1]     [[-0.1, 0.1], [-0.1, 0.1], [-0.1, 0.1]]  ...  0.0  0.0\n",
              "8    [-0.1, 0.1]     [[-0.1, 0.1], [-0.1, 0.1], [-0.1, 0.1]]  ...  0.0  0.0\n",
              "9    [0.0, -0.1]     [[0.0, -0.1], [0.0, -0.1], [0.0, -0.1]]  ...  0.0  0.0\n",
              "10   [0.0, -0.1]     [[0.0, -0.1], [0.0, -0.1], [0.0, -0.1]]  ...  0.0  0.0\n",
              "11   [0.0, -0.1]     [[0.0, -0.1], [0.0, -0.1], [0.0, -0.1]]  ...  0.0  0.0\n",
              "12    [0.0, 0.0]        [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]  ...  0.0  0.0\n",
              "13    [0.0, 0.0]        [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]  ...  0.0  0.0\n",
              "14    [0.0, 0.0]        [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]  ...  0.0  0.0\n",
              "15    [0.0, 0.1]        [[0.0, 0.1], [0.0, 0.1], [0.0, 0.1]]  ...  0.2  0.1\n",
              "16    [0.0, 0.1]        [[0.0, 0.1], [0.0, 0.1], [0.0, 0.1]]  ...  0.0  0.0\n",
              "17    [0.0, 0.1]        [[0.0, 0.1], [0.0, 0.1], [0.0, 0.1]]  ...  0.0  0.0\n",
              "18   [0.1, -0.1]     [[0.1, -0.1], [0.1, -0.1], [0.1, -0.1]]  ...  0.0  0.0\n",
              "19   [0.1, -0.1]     [[0.1, -0.1], [0.1, -0.1], [0.1, -0.1]]  ...  0.0  0.0\n",
              "20   [0.1, -0.1]     [[0.1, -0.1], [0.1, -0.1], [0.1, -0.1]]  ...  0.0  0.0\n",
              "21    [0.1, 0.0]        [[0.1, 0.0], [0.1, 0.0], [0.1, 0.0]]  ...  0.0  0.0\n",
              "22    [0.1, 0.0]        [[0.1, 0.0], [0.1, 0.0], [0.1, 0.0]]  ...  0.0  0.0\n",
              "23    [0.1, 0.0]        [[0.1, 0.0], [0.1, 0.0], [0.1, 0.0]]  ...  0.0  0.0\n",
              "24    [0.1, 0.1]        [[0.1, 0.1], [0.1, 0.1], [0.1, 0.1]]  ...  0.0  0.0\n",
              "25    [0.1, 0.1]        [[0.1, 0.1], [0.1, 0.1], [0.1, 0.1]]  ...  0.0  0.0\n",
              "26    [0.1, 0.1]        [[0.1, 0.1], [0.1, 0.1], [0.1, 0.1]]  ...  0.0  0.0\n",
              "\n",
              "[27 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m2PyeaJcO7H"
      },
      "source": [
        "df_test.to_csv(\"linear_linear_simultaneous.csv\")"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mipCcN0cdXO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}