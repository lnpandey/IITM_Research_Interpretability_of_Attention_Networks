{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alternate_minimization_demo_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SI3pji3AL4r"
      },
      "source": [
        "# import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R26eodhdAEBF"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import log_loss\n",
        "import pandas as pd\n",
        "\n",
        "from torch.nn import BCELoss\n",
        "#from scipy.optimize import fmin"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE7kNdASAS7m"
      },
      "source": [
        "# utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AuN4wcTH-9Q"
      },
      "source": [
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    m =  torch.max(x,dim=1,keepdims=True) \n",
        "    #print(m)\n",
        "    e_x = torch.exp(torch.sub(x,m.values)) \n",
        "    return e_x / torch.sum(e_x,dim=1,keepdims=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsDZefaEDJoW"
      },
      "source": [
        "def focus_(a,x):\n",
        "  \"\"\"\n",
        "  focus function parametrized by a*x\n",
        "  returns : averaged input for classification function\n",
        "  \"\"\"\n",
        "  #print(a*x)\n",
        "  out = softmax(a*x)\n",
        "  #print(out)\n",
        "  out = torch.sum(out*x,dim=1)\n",
        "  return out\n",
        "\n",
        "def classification_(b,c,x):\n",
        "  \"\"\"\n",
        "  classification function parametrized by b*x + c\n",
        "  returns  : sigmoid(b*x+c)\n",
        "  \"\"\"\n",
        "  out = (b*x) + c\n",
        "  out = 1/(1+torch.exp(-out))\n",
        "  return out"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmvMRalO3rPK"
      },
      "source": [
        "def derv_g(b,c):\n",
        "  \"\"\"\n",
        "   derivate of log-loss with respect to b and c using autograd\n",
        "  \"\"\"\n",
        "  #print(yhat,y,yhat-y)\n",
        "  #print()\n",
        "  db = b.grad\n",
        "  dc = c.grad\n",
        "  # db = np.dot(xhat,yhat-y)/xhat.shape[0]\n",
        "  # dc  = np.sum(yhat-y)/xhat.shape[0]\n",
        "  return db,dc"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQA_swIyPhid"
      },
      "source": [
        "def derv_f(a):\n",
        "  \"\"\"\n",
        "  derivative of log-loss with respect to a using autograd\n",
        "\n",
        "  \"\"\"\n",
        "  da = a.grad\n",
        "  # da = np.sum((yhat-y)*b*(  ( (x[:,0] - x[:,1])* x[:,0] ) +  ( (x[:,1]- x[:,0]) * x[:,1] )   ) * (np.exp((a*x[:,0]+a*x[:,1]))/ (np.exp(a*x[:,0])+ np.exp(a*x[:,1]))**2 )) / xhat.shape[0] \n",
        "  \n",
        "  # #print(  (  ( (x[:,0] - x[:,1])* x[:,0] ) +  ( (x[:,1]- x[:,0]) * x[:,1] )   ) * (np.exp((a*x[:,0]+a*x[:,1]))/ (np.exp(a*x[:,0])+ np.exp(a*x[:,1]))**2 ) )\n",
        "    \n",
        "  return da"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNYay5tP7c-7"
      },
      "source": [
        "\n",
        "def gd(w,dw):\n",
        "  \"\"\"\n",
        "  updates given parameter in negative direction of gradient\n",
        "  \"\"\"\n",
        "  eta = torch.tensor([0.1])\n",
        "  with torch.no_grad():\n",
        "    w = w - torch.dot(eta,dw)\n",
        "  return w"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0AusdtJAYlT"
      },
      "source": [
        "# m = 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDNCAOJYYbjv"
      },
      "source": [
        "X = torch.tensor([[3,-1],[-1,3],[1,3],[3,1]]) # mosaic data m = 2 , d= 1\n",
        "Y = torch.tensor([0,0,1,1])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy7tSJ544mi6"
      },
      "source": [
        "def minimize_b_c(x,y,a,b,c,epochs=1000):\n",
        "  # b = 0 \n",
        "  # c = 0 \n",
        "\n",
        "  #a.requires_grad=False\n",
        "  criterion = BCELoss()\n",
        "  y = y.float()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    x_average = focus_(a,x)\n",
        "    yhat = classification_(b,c,x_average)\n",
        "    initial_loss = criterion(yhat,y)\n",
        "\n",
        "\n",
        "  print(\"x average at 0 epoch\", x_average )\n",
        "  print(\"yhat at 0 epoch\",yhat)\n",
        "  print(\"loss at 0 epoch\",criterion(yhat,y).item())\n",
        "\n",
        "\n",
        "  for i in range(epochs):\n",
        "    a.requires_grad = False\n",
        "    b.requires_grad = True\n",
        "    c.requires_grad = True\n",
        "    x_average = focus_(a,x)\n",
        "    yhat = classification_(b,c,x_average)\n",
        "\n",
        "    loss = criterion(yhat,y)\n",
        "    b.retain_grad()\n",
        "    c.retain_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    #der_b,der_c = derv_g(b,c)\n",
        "    #print(i,der_b,der_c)\n",
        "    grad_b = b.grad\n",
        "    grad_c = c.grad\n",
        "    b = gd(b,grad_b)\n",
        "    c = gd(c,grad_c)\n",
        "    \n",
        "    \n",
        "    x_average = focus_(a,x)\n",
        "    yhat = classification_(b,c,x_average)\n",
        "    current_loss = criterion(yhat,y) \n",
        "    #print(current_loss<=(initial_loss/2) , current_loss,initial_loss)\n",
        "    if current_loss<= (initial_loss)/2:\n",
        "      break\n",
        "  print(\"   \")\n",
        "  with torch.no_grad():\n",
        "    x_average = focus_(a,x)\n",
        "    print(\"x average\",x_average)\n",
        "    yhat = classification_(b,c,x_average) \n",
        "    print(\"Y hat\",yhat)\n",
        "    current_loss  = criterion(yhat,y)\n",
        "\n",
        "  print(\"Loss\",current_loss.item(),i)\n",
        "  \n",
        "  return b,c,current_loss.item()\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yJmNDMxLNsJ"
      },
      "source": [
        "a = torch.tensor([0.],requires_grad=True)\n",
        "b = torch.tensor([0.],requires_grad=True)\n",
        "c = torch.tensor([0.],requires_grad=True)\n",
        "b,c,loss = minimize_b_c(X,Y,a,b,c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVHCR21mboPa"
      },
      "source": [
        "def minimize_a(x,y,a,b,c,epochs=1000):\n",
        "\n",
        "  #b = 0 \n",
        "  #c = 0 \n",
        "  criterion = BCELoss()\n",
        "  y = y.float()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    x_average = focus_(a,x)\n",
        "    yhat = classification_(b,c,x_average)\n",
        "    initial_loss = criterion(yhat,y)\n",
        "  print(\"x average at 0 epoch\", x_average )\n",
        "  print(\"yhat at 0 epoch\",yhat)\n",
        "  print(\"loss at 0 epoch\",criterion(yhat,y).item())\n",
        "\n",
        "  for i in range(epochs):\n",
        "    a.requires_grad =True\n",
        "    b.requires_grad = False\n",
        "    c.requires_grad = False\n",
        "    x_average = focus_(a,x)\n",
        "    yhat = classification_(b,c,x_average)\n",
        "\n",
        "    \n",
        "    loss = criterion(yhat,y)\n",
        "    a.retain_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    der_a = derv_f(a)\n",
        "    #print(i,der_a)\n",
        "    a = gd(a,der_a)\n",
        "\n",
        "    x_average = focus_(a,x)\n",
        "    yhat = classification_(b,c,x_average)\n",
        "    current_loss = criterion(yhat,y)\n",
        "    if current_loss <= initial_loss/2:\n",
        "      break \n",
        "  print(\"*\"*60)\n",
        "  with torch.no_grad():\n",
        "    x_average = focus_(a,x)\n",
        "    print(\"x average\",x_average)\n",
        "    yhat = classification_(b,c,x_average) \n",
        "    print(\"Y hat\",yhat)\n",
        "    current_loss = log_loss(y,yhat)\n",
        "  print(\"Loss\",current_loss.item(),i)\n",
        "  return a,current_loss.item()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8AH9blw0hgU"
      },
      "source": [
        "a = torch.tensor([0.],requires_grad=True)\n",
        "b = torch.tensor([0.],requires_grad=False)\n",
        "c = torch.tensor([0.],requires_grad=False)\n",
        "a,loss = minimize_a(X,Y,a,b,c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kz27pwXRf2K"
      },
      "source": [
        "a = torch.tensor(np.linspace(-1,1,20),requires_grad=True,dtype=torch.float32)\n",
        "b_list = []\n",
        "c_list = []\n",
        "loss_list = []\n",
        "b = torch.tensor([0.],requires_grad=True)\n",
        "c = torch.tensor([0.],requires_grad=True)\n",
        "for a1 in a:\n",
        "  #out =focus_(a1,X)\n",
        "  #print(out)\n",
        "  b,c,loss = minimize_b_c(X,Y,a=a1,b=b,c=c)\n",
        "  b_list.append(b.item())\n",
        "  c_list.append(c.item()) \n",
        "  #out= classification_(0,0,out)\n",
        "  #print(out)\n",
        "  loss_list.append(loss)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7DHzJ6lSpQR"
      },
      "source": [
        "a = np.linspace(-1,1,20)\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(a,loss_list,\"*-\")\n",
        "plt.grid()\n",
        "#plt.xticks(a)\n",
        "plt.xlabel(\"a\")\n",
        "plt.ylabel(\"log-loss\")\n",
        "plt.title(\"loss plot for fix value of a \")\n",
        "plt.savefig(\"loss_fixed_a.png\")\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(a,b_list,\"*-\")\n",
        "plt.grid()\n",
        "#plt.xticks(a)\n",
        "plt.xlabel(\"a\")\n",
        "plt.ylabel(\"b\")\n",
        "plt.title(\"Minimized value of b for fixed a\")\n",
        "plt.savefig(\"minimized_b_fixed_a.png\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(a,c_list,\"*-\")\n",
        "plt.grid()\n",
        "plt.xlabel(\"a\")\n",
        "plt.ylabel(\"c\")\n",
        "plt.title(\"Minimized value of c for fixed a\")\n",
        "plt.savefig(\"minimized_c_fixed_a.png\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KB7PbHbRu8k"
      },
      "source": [
        "loss_ = []\n",
        "bb,cc= np.meshgrid(np.arange(-21,21,0.2),np.arange(-21,21,0.2))\n",
        "b_ = bb.reshape(-1,1)\n",
        "c_ = cc.reshape(-1,1) \n",
        "a_ = 0\n",
        "x_average_ = focus_(a_,X)\n",
        "yhat_  = classification_(b_,c_,x_average_) \n",
        "#print(\"Y hat\",yhat_)\n",
        "#Y_ = np.array([list(Y)]*40000)\n",
        "for i in range(yhat_.shape[0]):\n",
        "  loss_.append(log_loss(Y,yhat_[i]))\n",
        "loss_ = np.array(loss_)#,axis=0)\n",
        "plt.figure(figsize=(6,5))\n",
        "cs = plt.contourf(b_.reshape(bb.shape),c_.reshape(cc.shape),loss_.reshape(bb.shape))\n",
        "plt.xlabel(\"b\")\n",
        "plt.ylabel(\"c\")\n",
        "plt.colorbar(cs)\n",
        "\n",
        "plt.scatter(0, 0,c=\"black\",s=100)\n",
        "plt.scatter(15.625194533788827, -1.5129474107626304,c=\"r\",s=100)\n",
        "\n",
        "plt.title(\"contour plot for fixed a = \"+str(a_) )\n",
        "\n",
        "plt.savefig(\"contour_b_c_a_0.png\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JnlprwVRuy5"
      },
      "source": [
        "minimize_b_c(X,Y,0,0,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QwL0cW6Ag1n"
      },
      "source": [
        "a = np.linspace(-10,10,5000)\n",
        "loss = []\n",
        "for a1 in a:\n",
        "  out =focus_(a1,X)\n",
        "  #print(out)\n",
        "  out = classification_(-10,-10,out)\n",
        "  #print(out)\n",
        "  loss.append(log_loss(Y,out,))\n",
        "\n",
        "plt.plot(a,loss)\n",
        "plt.xlabel(\"a\")\n",
        "plt.ylabel(\"log-loss\")\n",
        "plt.title(\"loss plot for fix value of  b and c\")\n",
        "plt.savefig(\"loss_landscape_b_n10_c_n10.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyMjVkBih9U6"
      },
      "source": [
        "# Alternate minimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZQhfXHNh9CR"
      },
      "source": [
        "a = torch.tensor([0.],requires_grad=True)\n",
        "b = torch.tensor([0.],requires_grad=True)\n",
        "c = torch.tensor([0.],requires_grad=True)\n",
        "\n",
        "criterion = BCELoss()\n",
        "data = pd.DataFrame(columns=[\"sno\",\"b_c_fixed\",\"a_fixed\",\"a_value\",\"b_value\",\"c_value\",\"loss\"]) \n",
        "Y_ = Y.float()\n",
        "X_average = focus_(a,X)\n",
        "Yhat = classification_(b,c,X_average)\n",
        "initial_loss = criterion(Yhat,Y_)\n",
        "\n",
        "#print(initial_loss)\n",
        "\n",
        "k = 0 \n",
        "data.loc[k] = [k,True,True,a.item(),b.item(),c.item(),initial_loss.item()]\n",
        "k = k+1\n",
        "j= 1\n",
        "\n",
        "for i in range(0,40,2):\n",
        "  print(\"Minimize b and c\")\n",
        "  b,c,loss = minimize_b_c(X,Y,a,b,c)\n",
        "  #print(b,c)\n",
        "  data.loc[k] = [j,False,True,a.item(),b.item(),c.item(),loss]\n",
        "  print(\"*\"*60)\n",
        "  print(\"  \")\n",
        "  print(\"minimize a\")\n",
        "  \n",
        "\n",
        "  #print(a,b,c)\n",
        "\n",
        "  a,loss = minimize_a(X,Y,a,b,c)\n",
        "  data.loc[k+1] = [j,True,False,a.item(),b.item(),c.item(),loss]\n",
        "  print(\"  \")\n",
        "  k = k+2\n",
        "  j = j+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvxqLbXVg8nY"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AhJx3e7umgA"
      },
      "source": [
        "data.to_csv(\"data_1_m_2_1.csv\",index=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Wsi6gdul_S"
      },
      "source": [
        "a = torch.tensor([0.],requires_grad=True)\n",
        "b = torch.tensor([0.],requires_grad=True)\n",
        "c = torch.tensor([0.],requires_grad=True)\n",
        "\n",
        "criterion = BCELoss()\n",
        "\n",
        "data_1 = pd.DataFrame(columns=[\"sno\",\"b_c_fixed\",\"a_fixed\",\"a_value\",\"b_value\",\"c_value\",\"loss\"]) \n",
        "\n",
        "X_average = focus_(a,X)\n",
        "Yhat = classification_(b,c,X_average)\n",
        "Y_ = Y.float()\n",
        "initial_loss = criterion(Yhat,Y_)\n",
        "\n",
        "k = 0 \n",
        "data_1.loc[k] = [k,True,True,a.item(),b.item(),c.item(),initial_loss.item()]\n",
        "k = k+1\n",
        "j= 1\n",
        "\n",
        "for i in range(0,40,2):\n",
        "\n",
        "\n",
        "  print(\"minimize a\")\n",
        "  a,loss = minimize_a(X,Y,a,b,c)\n",
        "  data_1.loc[k] = [j,True,False,a.item(),b.item(),c.item(),loss]\n",
        "  print(\"*\"*60)\n",
        "  print(\"  \")\n",
        "  \n",
        "  print(\"Minimize b and c\")\n",
        "  b,c,loss = minimize_b_c(X,Y,a,b,c)\n",
        "  data_1.loc[k+1] = [j,False,True,a.item(),b.item(),c.item(),loss]\n",
        "  print(\"  \")\n",
        "  k = k+2\n",
        "  j = j+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8nivB_YukCJ"
      },
      "source": [
        "data_1.to_csv(\"data_1_m_2_2.csv\",index=False)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSzEUkb677ca"
      },
      "source": [
        "data_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrXGQ0Sy77CS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3OFWH48BTlb"
      },
      "source": [
        "# m = 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Kk44HB-AC1"
      },
      "source": [
        "X1 = torch.tensor([[-1,3,3,3,3,3,3,3,3],[1,3,3,3,3,3,3,3,3],\n",
        "               [3,-1,3,3,3,3,3,3,3],[3,1,3,3,3,3,3,3,3],\n",
        "               [3,3,-1,3,3,3,3,3,3],[3,3,1,3,3,3,3,3,3],\n",
        "               [3,3,3,-1,3,3,3,3,3],[3,3,3,1,3,3,3,3,3],\n",
        "               [3,3,3,3,-1,3,3,3,3],[3,3,3,3,1,3,3,3,3],\n",
        "               [3,3,3,3,3,-1,3,3,3],[3,3,3,3,3,1,3,3,3],\n",
        "               [3,3,3,3,3,3,-1,3,3],[3,3,3,3,3,3,1,3,3],\n",
        "               [3,3,3,3,3,3,3,-1,3],[3,3,3,3,3,3,3,1,3],\n",
        "               [3,3,3,3,3,3,3,3,-1],[3,3,3,3,3,3,3,3,1],]) # mosaic data m = 9 , d= 1\n",
        "Y1 = torch.tensor([0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBvz3BBlE3vY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac8bdbe-aee5-4d87-96c1-be9edc8e1767"
      },
      "source": [
        "a = torch.tensor([0.],requires_grad=True)\n",
        "b = torch.tensor([0.],requires_grad=True)\n",
        "c = torch.tensor([0.],requires_grad=True)\n",
        "\n",
        "criterion = BCELoss()\n",
        "data = pd.DataFrame(columns=[\"sno\",\"b_c_fixed\",\"a_fixed\",\"a_value\",\"b_value\",\"c_value\",\"loss\"]) \n",
        "Y1_ = Y1.float()\n",
        "X1_average = focus_(a,X1)\n",
        "Yhat1 = classification_(b,c,X1_average)\n",
        "initial_loss = criterion(Yhat1,Y1_)\n",
        "\n",
        "#print(initial_loss)\n",
        "\n",
        "k = 0 \n",
        "data.loc[k] = [k,True,True,a.item(),b.item(),c.item(),initial_loss.item()]\n",
        "k = k+1\n",
        "j= 1\n",
        "\n",
        "for i in range(0,40,2):\n",
        "  print(\"Minimize b and c\")\n",
        "  b,c,loss = minimize_b_c(X1,Y1,a,b,c,epochs=20000)\n",
        "  #print(b,c)\n",
        "  data.loc[k] = [j,False,True,a.item(),b.item(),c.item(),loss]\n",
        "  print(\"*\"*60)\n",
        "  print(\"  \")\n",
        "  print(\"minimize a\")\n",
        "  \n",
        "\n",
        "  #print(a,b,c)\n",
        "\n",
        "  a,loss = minimize_a(X1,Y1,a,b,c,epochs=20000)\n",
        "  data.loc[k+1] = [j,True,False,a.item(),b.item(),c.item(),loss]\n",
        "  print(\"  \")\n",
        "  k = k+2\n",
        "  j = j+1"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimize b and c\n",
            "x average at 0 epoch tensor([2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556,\n",
            "        2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778])\n",
            "yhat at 0 epoch tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000])\n",
            "loss at 0 epoch 0.6931471824645996\n",
            "   \n",
            "x average tensor([2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556,\n",
            "        2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778])\n",
            "Y hat tensor([0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035,\n",
            "        0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179])\n",
            "Loss 0.3465682566165924 15077\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556,\n",
            "        2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778])\n",
            "yhat at 0 epoch tensor([0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035,\n",
            "        0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179])\n",
            "loss at 0 epoch 0.3465682566165924\n",
            "************************************************************\n",
            "x average tensor([2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491,\n",
            "        2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303])\n",
            "Y hat tensor([0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780,\n",
            "        0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358])\n",
            "Loss 0.2670542713668611 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491,\n",
            "        2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303])\n",
            "yhat at 0 epoch tensor([0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780,\n",
            "        0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358])\n",
            "loss at 0 epoch 0.2670542597770691\n",
            "   \n",
            "x average tensor([2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491,\n",
            "        2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303])\n",
            "Y hat tensor([0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331,\n",
            "        0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832])\n",
            "Loss 0.13352686166763306 5171\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491,\n",
            "        2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303])\n",
            "yhat at 0 epoch tensor([0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331,\n",
            "        0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832])\n",
            "loss at 0 epoch 0.13352686166763306\n",
            "************************************************************\n",
            "x average tensor([2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950,\n",
            "        2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986])\n",
            "Y hat tensor([0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308,\n",
            "        0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453])\n",
            "Loss 0.09966916818585661 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950,\n",
            "        2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986])\n",
            "yhat at 0 epoch tensor([0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308,\n",
            "        0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453])\n",
            "loss at 0 epoch 0.09966916590929031\n",
            "   \n",
            "x average tensor([2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950,\n",
            "        2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986])\n",
            "Y hat tensor([0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529,\n",
            "        0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557])\n",
            "Loss 0.04983256012201309 6242\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950,\n",
            "        2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986])\n",
            "yhat at 0 epoch tensor([0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529,\n",
            "        0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557])\n",
            "loss at 0 epoch 0.04983256012201309\n",
            "************************************************************\n",
            "x average tensor([2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610,\n",
            "        2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725])\n",
            "Y hat tensor([0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113,\n",
            "        0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406])\n",
            "Loss 0.036292890241990484 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610,\n",
            "        2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725])\n",
            "yhat at 0 epoch tensor([0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113,\n",
            "        0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406])\n",
            "loss at 0 epoch 0.03629289194941521\n",
            "   \n",
            "x average tensor([2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610,\n",
            "        2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725])\n",
            "Y hat tensor([0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200,\n",
            "        0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840])\n",
            "Loss 0.01814611256122589 9725\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610,\n",
            "        2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725])\n",
            "yhat at 0 epoch tensor([0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200,\n",
            "        0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840])\n",
            "loss at 0 epoch 0.01814611256122589\n",
            "************************************************************\n",
            "x average tensor([1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371,\n",
            "        2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492])\n",
            "Y hat tensor([0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040,\n",
            "        0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784])\n",
            "Loss 0.01291769191933175 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371,\n",
            "        2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492])\n",
            "yhat at 0 epoch tensor([0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040,\n",
            "        0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784])\n",
            "loss at 0 epoch 0.01291769091039896\n",
            "   \n",
            "x average tensor([1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371,\n",
            "        2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492])\n",
            "Y hat tensor([0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073,\n",
            "        0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944])\n",
            "Loss 0.006458787247538567 17197\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371,\n",
            "        2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492])\n",
            "yhat at 0 epoch tensor([0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073,\n",
            "        0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944])\n",
            "loss at 0 epoch 0.006458787247538567\n",
            "************************************************************\n",
            "x average tensor([1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195,\n",
            "        2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276])\n",
            "Y hat tensor([0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014,\n",
            "        0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924])\n",
            "Loss 0.0044996076030656695 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195,\n",
            "        2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276])\n",
            "yhat at 0 epoch tensor([0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014,\n",
            "        0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924])\n",
            "loss at 0 epoch 0.004499607719480991\n",
            "   \n",
            "x average tensor([1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195,\n",
            "        2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276])\n",
            "Y hat tensor([0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028,\n",
            "        0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979])\n",
            "Loss 0.0024409375619143248 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195,\n",
            "        2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276])\n",
            "yhat at 0 epoch tensor([0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028,\n",
            "        0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979])\n",
            "loss at 0 epoch 0.0024409375619143248\n",
            "************************************************************\n",
            "x average tensor([1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048,\n",
            "        2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069])\n",
            "Y hat tensor([5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01,\n",
            "        5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01,\n",
            "        5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01])\n",
            "Loss 0.0016659789835102856 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048,\n",
            "        2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069])\n",
            "yhat at 0 epoch tensor([5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01,\n",
            "        5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01,\n",
            "        5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01])\n",
            "loss at 0 epoch 0.0016659791581332684\n",
            "   \n",
            "x average tensor([1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048,\n",
            "        2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069])\n",
            "Y hat tensor([0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011,\n",
            "        0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992])\n",
            "Loss 0.000950712594203651 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048,\n",
            "        2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069])\n",
            "yhat at 0 epoch tensor([0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011,\n",
            "        0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992])\n",
            "loss at 0 epoch 0.000950712594203651\n",
            "************************************************************\n",
            "x average tensor([1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914,\n",
            "        2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865])\n",
            "Y hat tensor([1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01,\n",
            "        1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01,\n",
            "        1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01])\n",
            "Loss 0.0006346709924400784 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914,\n",
            "        2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865])\n",
            "yhat at 0 epoch tensor([1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01,\n",
            "        1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01,\n",
            "        1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01])\n",
            "loss at 0 epoch 0.0006346709560602903\n",
            "   \n",
            "x average tensor([1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914,\n",
            "        2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865])\n",
            "Y hat tensor([4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01,\n",
            "        4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01,\n",
            "        4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01])\n",
            "Loss 0.00036517693661153316 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914,\n",
            "        2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865])\n",
            "yhat at 0 epoch tensor([4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01,\n",
            "        4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01,\n",
            "        4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01])\n",
            "loss at 0 epoch 0.00036517693661153316\n",
            "************************************************************\n",
            "x average tensor([1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816,\n",
            "        2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667])\n",
            "Y hat tensor([7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01,\n",
            "        7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01,\n",
            "        7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01])\n",
            "Loss 0.00024409537218161859 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816,\n",
            "        2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667])\n",
            "yhat at 0 epoch tensor([7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01,\n",
            "        7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01,\n",
            "        7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01])\n",
            "loss at 0 epoch 0.00024409539764747024\n",
            "   \n",
            "x average tensor([1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816,\n",
            "        2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667])\n",
            "Y hat tensor([1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01,\n",
            "        1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01,\n",
            "        1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01])\n",
            "Loss 0.00014303158968687057 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816,\n",
            "        2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667])\n",
            "yhat at 0 epoch tensor([1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01,\n",
            "        1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01,\n",
            "        1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01])\n",
            "loss at 0 epoch 0.00014303158968687057\n",
            "************************************************************\n",
            "x average tensor([1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927,\n",
            "        2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507])\n",
            "Y hat tensor([3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01,\n",
            "        3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01,\n",
            "        3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01])\n",
            "Loss 0.00010953240962408017 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927,\n",
            "        2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507])\n",
            "yhat at 0 epoch tensor([3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01,\n",
            "        3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01,\n",
            "        3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01])\n",
            "loss at 0 epoch 0.00010953241871902719\n",
            "   \n",
            "x average tensor([1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927,\n",
            "        2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507])\n",
            "Y hat tensor([5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01,\n",
            "        5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01,\n",
            "        5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01])\n",
            "Loss 7.063416705932468e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927,\n",
            "        2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507])\n",
            "yhat at 0 epoch tensor([5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01,\n",
            "        5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01,\n",
            "        5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01])\n",
            "loss at 0 epoch 7.063416705932468e-05\n",
            "************************************************************\n",
            "x average tensor([1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330,\n",
            "        2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398])\n",
            "Y hat tensor([1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01,\n",
            "        1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01,\n",
            "        1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01])\n",
            "Loss 6.300504446699051e-05 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330,\n",
            "        2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398])\n",
            "yhat at 0 epoch tensor([1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01,\n",
            "        1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01,\n",
            "        1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01])\n",
            "loss at 0 epoch 6.300504901446402e-05\n",
            "   \n",
            "x average tensor([1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330,\n",
            "        2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398])\n",
            "Y hat tensor([2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01,\n",
            "        2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01,\n",
            "        2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01])\n",
            "Loss 4.500268914853223e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330,\n",
            "        2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398])\n",
            "yhat at 0 epoch tensor([2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01,\n",
            "        2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01,\n",
            "        2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01])\n",
            "loss at 0 epoch 4.500268914853223e-05\n",
            "************************************************************\n",
            "x average tensor([1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918,\n",
            "        2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323])\n",
            "Y hat tensor([1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01,\n",
            "        1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3215e-05, 9.9993e-01,\n",
            "        1.3215e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01])\n",
            "Loss 4.267827171133831e-05 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918,\n",
            "        2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323])\n",
            "yhat at 0 epoch tensor([1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01,\n",
            "        1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3215e-05, 9.9993e-01,\n",
            "        1.3215e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01])\n",
            "loss at 0 epoch 4.2678268073359504e-05\n",
            "   \n",
            "x average tensor([1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918,\n",
            "        2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323])\n",
            "Y hat tensor([1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01,\n",
            "        1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01,\n",
            "        1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01])\n",
            "Loss 3.290244421805255e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918,\n",
            "        2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323])\n",
            "yhat at 0 epoch tensor([1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01,\n",
            "        1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01,\n",
            "        1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01])\n",
            "loss at 0 epoch 3.290244421805255e-05\n",
            "************************************************************\n",
            "x average tensor([1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619,\n",
            "        2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268])\n",
            "Y hat tensor([9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01,\n",
            "        9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01,\n",
            "        9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01])\n",
            "Loss 3.2038252356869634e-05 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619,\n",
            "        2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268])\n",
            "yhat at 0 epoch tensor([9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01,\n",
            "        9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01,\n",
            "        9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01])\n",
            "loss at 0 epoch 3.2038253266364336e-05\n",
            "   \n",
            "x average tensor([1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619,\n",
            "        2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268])\n",
            "Y hat tensor([1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01,\n",
            "        1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01,\n",
            "        1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01])\n",
            "Loss 2.6226496629533358e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619,\n",
            "        2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268])\n",
            "yhat at 0 epoch tensor([1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01,\n",
            "        1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01,\n",
            "        1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01])\n",
            "loss at 0 epoch 2.6226496629533358e-05\n",
            "************************************************************\n",
            "x average tensor([1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406,\n",
            "        2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229])\n",
            "Y hat tensor([8.0521e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01,\n",
            "        8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01,\n",
            "        8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01])\n",
            "Loss 2.5839106456260197e-05 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406,\n",
            "        2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229])\n",
            "yhat at 0 epoch tensor([8.0521e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01,\n",
            "        8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01,\n",
            "        8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01])\n",
            "loss at 0 epoch 2.58391082752496e-05\n",
            "   \n",
            "x average tensor([1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406,\n",
            "        2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229])\n",
            "Y hat tensor([8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01,\n",
            "        8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01,\n",
            "        8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01])\n",
            "Loss 2.2232867195270956e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406,\n",
            "        2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229])\n",
            "yhat at 0 epoch tensor([8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01,\n",
            "        8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01,\n",
            "        8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01])\n",
            "loss at 0 epoch 2.2232867195270956e-05\n",
            "************************************************************\n",
            "x average tensor([1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254,\n",
            "        2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201])\n",
            "Y hat tensor([6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01,\n",
            "        6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01,\n",
            "        6.8843e-06, 9.9996e-01, 6.8843e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01])\n",
            "Loss 2.2047453436850144e-05 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254,\n",
            "        2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201])\n",
            "yhat at 0 epoch tensor([6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01,\n",
            "        6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01,\n",
            "        6.8843e-06, 9.9996e-01, 6.8843e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01])\n",
            "loss at 0 epoch 2.204745396738872e-05\n",
            "   \n",
            "x average tensor([1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254,\n",
            "        2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201])\n",
            "Y hat tensor([7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01, 7.5590e-06, 9.9997e-01,\n",
            "        7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01,\n",
            "        7.5590e-06, 9.9997e-01, 7.5590e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01])\n",
            "Loss 1.9163142496836372e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254,\n",
            "        2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201])\n",
            "yhat at 0 epoch tensor([7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01, 7.5590e-06, 9.9997e-01,\n",
            "        7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01,\n",
            "        7.5590e-06, 9.9997e-01, 7.5590e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01])\n",
            "loss at 0 epoch 1.9163142496836372e-05\n",
            "************************************************************\n",
            "x average tensor([1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114,\n",
            "        2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175])\n",
            "Y hat tensor([5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01,\n",
            "        5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01,\n",
            "        5.9504e-06, 9.9997e-01, 5.9503e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01])\n",
            "Loss 1.9014148847418255e-05 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114,\n",
            "        2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175])\n",
            "yhat at 0 epoch tensor([5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01,\n",
            "        5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01,\n",
            "        5.9504e-06, 9.9997e-01, 5.9503e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01])\n",
            "loss at 0 epoch 1.9014145436813124e-05\n",
            "   \n",
            "x average tensor([1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114,\n",
            "        2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175])\n",
            "Y hat tensor([6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01,\n",
            "        6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01,\n",
            "        6.5266e-06, 9.9997e-01, 6.5265e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01])\n",
            "Loss 1.648086981731467e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114,\n",
            "        2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175])\n",
            "yhat at 0 epoch tensor([6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01,\n",
            "        6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01,\n",
            "        6.5266e-06, 9.9997e-01, 6.5265e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01])\n",
            "loss at 0 epoch 1.648086981731467e-05\n",
            "************************************************************\n",
            "x average tensor([1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976,\n",
            "        2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149])\n",
            "Y hat tensor([5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01,\n",
            "        5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01,\n",
            "        5.1438e-06, 9.9997e-01, 5.1438e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01])\n",
            "Loss 1.6391474900956382e-05 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976,\n",
            "        2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149])\n",
            "yhat at 0 epoch tensor([5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01,\n",
            "        5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01,\n",
            "        5.1438e-06, 9.9997e-01, 5.1438e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01])\n",
            "loss at 0 epoch 1.6391473764088005e-05\n",
            "   \n",
            "x average tensor([1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976,\n",
            "        2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149])\n",
            "Y hat tensor([5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01,\n",
            "        5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01,\n",
            "        5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01])\n",
            "Loss 1.4782103789912071e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976,\n",
            "        2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149])\n",
            "yhat at 0 epoch tensor([5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01,\n",
            "        5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01,\n",
            "        5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.4782103789912071e-05\n",
            "************************************************************\n",
            "x average tensor([1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875,\n",
            "        2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131])\n",
            "Y hat tensor([4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01,\n",
            "        4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01,\n",
            "        4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01])\n",
            "Loss 1.472250619372062e-05 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875,\n",
            "        2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131])\n",
            "yhat at 0 epoch tensor([4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01,\n",
            "        4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01,\n",
            "        4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.4722507330588996e-05\n",
            "   \n",
            "x average tensor([1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875,\n",
            "        2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131])\n",
            "Y hat tensor([4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01,\n",
            "        4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01,\n",
            "        4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01])\n",
            "Loss 1.367940058116801e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875,\n",
            "        2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131])\n",
            "yhat at 0 epoch tensor([4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01,\n",
            "        4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01,\n",
            "        4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.367940058116801e-05\n",
            "************************************************************\n",
            "x average tensor([1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807,\n",
            "        2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118])\n",
            "Y hat tensor([4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01,\n",
            "        4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01,\n",
            "        4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01])\n",
            "Loss 1.3709206541534513e-05 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807,\n",
            "        2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118])\n",
            "yhat at 0 epoch tensor([4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01,\n",
            "        4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01,\n",
            "        4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.3709205632039811e-05\n",
            "   \n",
            "x average tensor([1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807,\n",
            "        2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118])\n",
            "Y hat tensor([4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01,\n",
            "        4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01,\n",
            "        4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01])\n",
            "Loss 1.272570534638362e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807,\n",
            "        2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118])\n",
            "yhat at 0 epoch tensor([4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01,\n",
            "        4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01,\n",
            "        4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.272570534638362e-05\n",
            "************************************************************\n",
            "x average tensor([1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739,\n",
            "        2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105])\n",
            "Y hat tensor([3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01,\n",
            "        3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01,\n",
            "        3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01])\n",
            "Loss 1.2725711258099182e-05 19999\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739,\n",
            "        2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105])\n",
            "yhat at 0 epoch tensor([3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01,\n",
            "        3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01,\n",
            "        3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.2725711712846532e-05\n",
            "   \n",
            "x average tensor([1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739,\n",
            "        2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105])\n",
            "Y hat tensor([4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01,\n",
            "        4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01,\n",
            "        4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01])\n",
            "Loss 1.1801817890955135e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739,\n",
            "        2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105])\n",
            "yhat at 0 epoch tensor([4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01,\n",
            "        4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01,\n",
            "        4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.1801817890955135e-05\n",
            "************************************************************\n",
            "x average tensor([1.1672, 2.5093, 1.1672, 2.5093, 1.1672, 2.5093, 1.1672, 2.5093, 1.1672,\n",
            "        2.5093, 1.1672, 2.5093, 1.1672, 2.5093, 1.1672, 2.5093, 1.1672, 2.5093])\n",
            "Y hat tensor([3.7162e-06, 9.9998e-01, 3.7162e-06, 9.9998e-01, 3.7162e-06, 9.9998e-01,\n",
            "        3.7162e-06, 9.9998e-01, 3.7162e-06, 9.9998e-01, 3.7162e-06, 9.9998e-01,\n",
            "        3.7162e-06, 9.9998e-01, 3.7162e-06, 9.9998e-01, 3.7162e-06, 9.9998e-01])\n",
            "Loss 1.1801822211054969e-05 19999\n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRjs9A8ayCFs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "383d22e0-900d-4ed5-b199-308cd004b6b3"
      },
      "source": [
        "data"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sno</th>\n",
              "      <th>b_c_fixed</th>\n",
              "      <th>a_fixed</th>\n",
              "      <th>a_value</th>\n",
              "      <th>b_value</th>\n",
              "      <th>c_value</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.941030</td>\n",
              "      <td>-21.124401</td>\n",
              "      <td>0.346568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.110344</td>\n",
              "      <td>7.941030</td>\n",
              "      <td>-21.124401</td>\n",
              "      <td>0.267054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.110344</td>\n",
              "      <td>10.221793</td>\n",
              "      <td>-25.885893</td>\n",
              "      <td>0.133527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.175237</td>\n",
              "      <td>10.221793</td>\n",
              "      <td>-25.885893</td>\n",
              "      <td>0.099669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.175237</td>\n",
              "      <td>11.828355</td>\n",
              "      <td>-28.848444</td>\n",
              "      <td>0.049833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.224443</td>\n",
              "      <td>11.828355</td>\n",
              "      <td>-28.848444</td>\n",
              "      <td>0.036293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.224443</td>\n",
              "      <td>13.103411</td>\n",
              "      <td>-30.900333</td>\n",
              "      <td>0.018146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.265743</td>\n",
              "      <td>13.103411</td>\n",
              "      <td>-30.900333</td>\n",
              "      <td>0.012918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.265743</td>\n",
              "      <td>14.176970</td>\n",
              "      <td>-32.378441</td>\n",
              "      <td>0.006459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.302198</td>\n",
              "      <td>14.176970</td>\n",
              "      <td>-32.378441</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.302198</td>\n",
              "      <td>14.912832</td>\n",
              "      <td>-33.007488</td>\n",
              "      <td>0.002441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.335762</td>\n",
              "      <td>14.912832</td>\n",
              "      <td>-33.007488</td>\n",
              "      <td>0.001666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.335762</td>\n",
              "      <td>15.461018</td>\n",
              "      <td>-33.155376</td>\n",
              "      <td>0.000951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.367467</td>\n",
              "      <td>15.461018</td>\n",
              "      <td>-33.155376</td>\n",
              "      <td>0.000635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.367467</td>\n",
              "      <td>15.938407</td>\n",
              "      <td>-33.119297</td>\n",
              "      <td>0.000365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>8</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.397039</td>\n",
              "      <td>15.938407</td>\n",
              "      <td>-33.119297</td>\n",
              "      <td>0.000244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.397039</td>\n",
              "      <td>16.316177</td>\n",
              "      <td>-33.024620</td>\n",
              "      <td>0.000143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>9</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.420388</td>\n",
              "      <td>16.316177</td>\n",
              "      <td>-33.024620</td>\n",
              "      <td>0.000110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.420388</td>\n",
              "      <td>16.569515</td>\n",
              "      <td>-32.937027</td>\n",
              "      <td>0.000071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>10</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.435816</td>\n",
              "      <td>16.569515</td>\n",
              "      <td>-32.937027</td>\n",
              "      <td>0.000063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>11</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.435816</td>\n",
              "      <td>16.743834</td>\n",
              "      <td>-32.863758</td>\n",
              "      <td>0.000045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>11</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.446387</td>\n",
              "      <td>16.743834</td>\n",
              "      <td>-32.863758</td>\n",
              "      <td>0.000043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>12</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.446387</td>\n",
              "      <td>16.873188</td>\n",
              "      <td>-32.810760</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>12</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.454003</td>\n",
              "      <td>16.873188</td>\n",
              "      <td>-32.810760</td>\n",
              "      <td>0.000032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>13</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.454003</td>\n",
              "      <td>16.975836</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>13</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.459430</td>\n",
              "      <td>16.975836</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.459430</td>\n",
              "      <td>17.057751</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>14</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.463268</td>\n",
              "      <td>17.057751</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>15</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.463268</td>\n",
              "      <td>17.134045</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>15</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.466801</td>\n",
              "      <td>17.134045</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>16</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.466801</td>\n",
              "      <td>17.210339</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>16</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.470296</td>\n",
              "      <td>17.210339</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>17</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.470296</td>\n",
              "      <td>17.266453</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>17</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.472843</td>\n",
              "      <td>17.266453</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>18</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.472843</td>\n",
              "      <td>17.304600</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>18</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.474562</td>\n",
              "      <td>17.304600</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>19</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.474562</td>\n",
              "      <td>17.342747</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>19</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.476273</td>\n",
              "      <td>17.342747</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>20</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.476273</td>\n",
              "      <td>17.380894</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.477974</td>\n",
              "      <td>17.380894</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sno b_c_fixed a_fixed   a_value    b_value    c_value      loss\n",
              "0    0      True    True  0.000000   0.000000   0.000000  0.693147\n",
              "1    1     False    True  0.000000   7.941030 -21.124401  0.346568\n",
              "2    1      True   False -0.110344   7.941030 -21.124401  0.267054\n",
              "3    2     False    True -0.110344  10.221793 -25.885893  0.133527\n",
              "4    2      True   False -0.175237  10.221793 -25.885893  0.099669\n",
              "5    3     False    True -0.175237  11.828355 -28.848444  0.049833\n",
              "6    3      True   False -0.224443  11.828355 -28.848444  0.036293\n",
              "7    4     False    True -0.224443  13.103411 -30.900333  0.018146\n",
              "8    4      True   False -0.265743  13.103411 -30.900333  0.012918\n",
              "9    5     False    True -0.265743  14.176970 -32.378441  0.006459\n",
              "10   5      True   False -0.302198  14.176970 -32.378441  0.004500\n",
              "11   6     False    True -0.302198  14.912832 -33.007488  0.002441\n",
              "12   6      True   False -0.335762  14.912832 -33.007488  0.001666\n",
              "13   7     False    True -0.335762  15.461018 -33.155376  0.000951\n",
              "14   7      True   False -0.367467  15.461018 -33.155376  0.000635\n",
              "15   8     False    True -0.367467  15.938407 -33.119297  0.000365\n",
              "16   8      True   False -0.397039  15.938407 -33.119297  0.000244\n",
              "17   9     False    True -0.397039  16.316177 -33.024620  0.000143\n",
              "18   9      True   False -0.420388  16.316177 -33.024620  0.000110\n",
              "19  10     False    True -0.420388  16.569515 -32.937027  0.000071\n",
              "20  10      True   False -0.435816  16.569515 -32.937027  0.000063\n",
              "21  11     False    True -0.435816  16.743834 -32.863758  0.000045\n",
              "22  11      True   False -0.446387  16.743834 -32.863758  0.000043\n",
              "23  12     False    True -0.446387  16.873188 -32.810760  0.000033\n",
              "24  12      True   False -0.454003  16.873188 -32.810760  0.000032\n",
              "25  13     False    True -0.454003  16.975836 -32.788967  0.000026\n",
              "26  13      True   False -0.459430  16.975836 -32.788967  0.000026\n",
              "27  14     False    True -0.459430  17.057751 -32.788967  0.000022\n",
              "28  14      True   False -0.463268  17.057751 -32.788967  0.000022\n",
              "29  15     False    True -0.463268  17.134045 -32.788967  0.000019\n",
              "30  15      True   False -0.466801  17.134045 -32.788967  0.000019\n",
              "31  16     False    True -0.466801  17.210339 -32.788967  0.000016\n",
              "32  16      True   False -0.470296  17.210339 -32.788967  0.000016\n",
              "33  17     False    True -0.470296  17.266453 -32.788967  0.000015\n",
              "34  17      True   False -0.472843  17.266453 -32.788967  0.000015\n",
              "35  18     False    True -0.472843  17.304600 -32.788967  0.000014\n",
              "36  18      True   False -0.474562  17.304600 -32.788967  0.000014\n",
              "37  19     False    True -0.474562  17.342747 -32.788967  0.000013\n",
              "38  19      True   False -0.476273  17.342747 -32.788967  0.000013\n",
              "39  20     False    True -0.476273  17.380894 -32.788967  0.000012\n",
              "40  20      True   False -0.477974  17.380894 -32.788967  0.000012"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbqJkHBvRu2c"
      },
      "source": [
        "data.to_csv(\"data_1_m_9_1.csv\",index=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfDp3_p5RuXH",
        "outputId": "7d43d2e5-17c5-4f3f-c53b-acc89fb80340"
      },
      "source": [
        "a = torch.tensor([0.],requires_grad=True)\n",
        "b = torch.tensor([0.],requires_grad=True)\n",
        "c = torch.tensor([0.],requires_grad=True)\n",
        "\n",
        "criterion = BCELoss()\n",
        "data = pd.DataFrame(columns=[\"sno\",\"b_c_fixed\",\"a_fixed\",\"a_value\",\"b_value\",\"c_value\",\"loss\"]) \n",
        "Y1_ = Y1.float()\n",
        "X1_average = focus_(a,X1)\n",
        "Yhat1 = classification_(b,c,X1_average)\n",
        "initial_loss = criterion(Yhat1,Y1_)\n",
        "\n",
        "#print(initial_loss)\n",
        "\n",
        "k = 0 \n",
        "data.loc[k] = [k,True,True,a.item(),b.item(),c.item(),initial_loss.item()]\n",
        "k = k+1\n",
        "j= 1\n",
        "\n",
        "for i in range(0,40,2):\n",
        "  \n",
        "  \n",
        "  print(\"minimize a\")\n",
        "  a,loss = minimize_a(X1,Y1,a,b,c,epochs=20000)\n",
        "  data.loc[k] = [j,True,False,a.item(),b.item(),c.item(),loss]\n",
        "\n",
        "  print(\"*\"*60)\n",
        "  print(\"  \")\n",
        "\n",
        "  print(\"Minimize b and c\")\n",
        "  b,c,loss = minimize_b_c(X1,Y1,a,b,c,epochs=20000)\n",
        "  #print(b,c)\n",
        "  data.loc[k+1] = [j,False,True,a.item(),b.item(),c.item(),loss]\n",
        "  print(\"  \")\n",
        "  k = k+2\n",
        "  j = j+1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "minimize a\n",
            "x average at 0 epoch tensor([2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556,\n",
            "        2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778])\n",
            "yhat at 0 epoch tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000])\n",
            "loss at 0 epoch 0.6931471824645996\n",
            "************************************************************\n",
            "x average tensor([2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556,\n",
            "        2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778])\n",
            "Y hat tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000])\n",
            "Loss 0.6931471824645996 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556,\n",
            "        2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778])\n",
            "yhat at 0 epoch tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000])\n",
            "loss at 0 epoch 0.6931471824645996\n",
            "   \n",
            "x average tensor([2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556,\n",
            "        2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778])\n",
            "Y hat tensor([0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035,\n",
            "        0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179])\n",
            "Loss 0.3465682566165924 15077\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556,\n",
            "        2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778, 2.5556, 2.7778])\n",
            "yhat at 0 epoch tensor([0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035,\n",
            "        0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179, 0.3035, 0.7179])\n",
            "loss at 0 epoch 0.3465682566165924\n",
            "************************************************************\n",
            "x average tensor([2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491,\n",
            "        2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303])\n",
            "Y hat tensor([0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780,\n",
            "        0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358])\n",
            "Loss 0.2670542713668611 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491,\n",
            "        2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303])\n",
            "yhat at 0 epoch tensor([0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780,\n",
            "        0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358, 0.0780, 0.6358])\n",
            "loss at 0 epoch 0.2670542597770691\n",
            "   \n",
            "x average tensor([2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491,\n",
            "        2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303])\n",
            "Y hat tensor([0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331,\n",
            "        0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832])\n",
            "Loss 0.13352686166763306 5171\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491,\n",
            "        2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303, 2.3491, 2.7303])\n",
            "yhat at 0 epoch tensor([0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331,\n",
            "        0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832, 0.1331, 0.8832])\n",
            "loss at 0 epoch 0.13352686166763306\n",
            "************************************************************\n",
            "x average tensor([2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950,\n",
            "        2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986])\n",
            "Y hat tensor([0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308,\n",
            "        0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453])\n",
            "Loss 0.09966916818585661 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950,\n",
            "        2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986])\n",
            "yhat at 0 epoch tensor([0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308,\n",
            "        0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453, 0.0308, 0.8453])\n",
            "loss at 0 epoch 0.09966916590929031\n",
            "   \n",
            "x average tensor([2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950,\n",
            "        2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986])\n",
            "Y hat tensor([0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529,\n",
            "        0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557])\n",
            "Loss 0.04983256012201309 6242\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950,\n",
            "        2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986, 2.1950, 2.6986])\n",
            "yhat at 0 epoch tensor([0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529,\n",
            "        0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557, 0.0529, 0.9557])\n",
            "loss at 0 epoch 0.04983256012201309\n",
            "************************************************************\n",
            "x average tensor([2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610,\n",
            "        2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725])\n",
            "Y hat tensor([0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113,\n",
            "        0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406])\n",
            "Loss 0.036292890241990484 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610,\n",
            "        2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725])\n",
            "yhat at 0 epoch tensor([0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113,\n",
            "        0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406, 0.0113, 0.9406])\n",
            "loss at 0 epoch 0.03629289194941521\n",
            "   \n",
            "x average tensor([2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610,\n",
            "        2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725])\n",
            "Y hat tensor([0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200,\n",
            "        0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840])\n",
            "Loss 0.01814611256122589 9725\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610,\n",
            "        2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725, 2.0610, 2.6725])\n",
            "yhat at 0 epoch tensor([0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200,\n",
            "        0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840, 0.0200, 0.9840])\n",
            "loss at 0 epoch 0.01814611256122589\n",
            "************************************************************\n",
            "x average tensor([1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371,\n",
            "        2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492])\n",
            "Y hat tensor([0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040,\n",
            "        0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784])\n",
            "Loss 0.01291769191933175 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371,\n",
            "        2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492])\n",
            "yhat at 0 epoch tensor([0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040,\n",
            "        0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784, 0.0040, 0.9784])\n",
            "loss at 0 epoch 0.01291769091039896\n",
            "   \n",
            "x average tensor([1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371,\n",
            "        2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492])\n",
            "Y hat tensor([0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073,\n",
            "        0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944])\n",
            "Loss 0.006458787247538567 17197\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371,\n",
            "        2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492, 1.9371, 2.6492])\n",
            "yhat at 0 epoch tensor([0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073,\n",
            "        0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944, 0.0073, 0.9944])\n",
            "loss at 0 epoch 0.006458787247538567\n",
            "************************************************************\n",
            "x average tensor([1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195,\n",
            "        2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276])\n",
            "Y hat tensor([0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014,\n",
            "        0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924])\n",
            "Loss 0.0044996076030656695 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195,\n",
            "        2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276])\n",
            "yhat at 0 epoch tensor([0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014,\n",
            "        0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924, 0.0014, 0.9924])\n",
            "loss at 0 epoch 0.004499607719480991\n",
            "   \n",
            "x average tensor([1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195,\n",
            "        2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276])\n",
            "Y hat tensor([0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028,\n",
            "        0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979])\n",
            "Loss 0.0024409375619143248 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195,\n",
            "        2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276, 1.8195, 2.6276])\n",
            "yhat at 0 epoch tensor([0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028,\n",
            "        0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979, 0.0028, 0.9979])\n",
            "loss at 0 epoch 0.0024409375619143248\n",
            "************************************************************\n",
            "x average tensor([1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048,\n",
            "        2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069])\n",
            "Y hat tensor([5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01,\n",
            "        5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01,\n",
            "        5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01])\n",
            "Loss 0.0016659789835102856 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048,\n",
            "        2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069])\n",
            "yhat at 0 epoch tensor([5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01,\n",
            "        5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01,\n",
            "        5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01, 5.0841e-04, 9.9718e-01])\n",
            "loss at 0 epoch 0.0016659791581332684\n",
            "   \n",
            "x average tensor([1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048,\n",
            "        2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069])\n",
            "Y hat tensor([0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011,\n",
            "        0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992])\n",
            "Loss 0.000950712594203651 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048,\n",
            "        2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069, 1.7048, 2.6069])\n",
            "yhat at 0 epoch tensor([0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011,\n",
            "        0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992, 0.0011, 0.9992])\n",
            "loss at 0 epoch 0.000950712594203651\n",
            "************************************************************\n",
            "x average tensor([1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914,\n",
            "        2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865])\n",
            "Y hat tensor([1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01,\n",
            "        1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01,\n",
            "        1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01])\n",
            "Loss 0.0006346709924400784 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914,\n",
            "        2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865])\n",
            "yhat at 0 epoch tensor([1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01,\n",
            "        1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01,\n",
            "        1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01, 1.9330e-04, 9.9892e-01])\n",
            "loss at 0 epoch 0.0006346709560602903\n",
            "   \n",
            "x average tensor([1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914,\n",
            "        2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865])\n",
            "Y hat tensor([4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01,\n",
            "        4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01,\n",
            "        4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01])\n",
            "Loss 0.00036517693661153316 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914,\n",
            "        2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865, 1.5914, 2.5865])\n",
            "yhat at 0 epoch tensor([4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01,\n",
            "        4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01,\n",
            "        4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01, 4.2828e-04, 9.9970e-01])\n",
            "loss at 0 epoch 0.00036517693661153316\n",
            "************************************************************\n",
            "x average tensor([1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816,\n",
            "        2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667])\n",
            "Y hat tensor([7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01,\n",
            "        7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01,\n",
            "        7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01])\n",
            "Loss 0.00024409537218161859 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816,\n",
            "        2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667])\n",
            "yhat at 0 epoch tensor([7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01,\n",
            "        7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01,\n",
            "        7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01, 7.4519e-05, 9.9959e-01])\n",
            "loss at 0 epoch 0.00024409539764747024\n",
            "   \n",
            "x average tensor([1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816,\n",
            "        2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667])\n",
            "Y hat tensor([1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01,\n",
            "        1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01,\n",
            "        1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01])\n",
            "Loss 0.00014303158968687057 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816,\n",
            "        2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667, 1.4816, 2.5667])\n",
            "yhat at 0 epoch tensor([1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01,\n",
            "        1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01,\n",
            "        1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01, 1.4336e-04, 9.9986e-01])\n",
            "loss at 0 epoch 0.00014303158968687057\n",
            "************************************************************\n",
            "x average tensor([1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927,\n",
            "        2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507])\n",
            "Y hat tensor([3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01,\n",
            "        3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01,\n",
            "        3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01])\n",
            "Loss 0.00010953240962408017 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927,\n",
            "        2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507])\n",
            "yhat at 0 epoch tensor([3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01,\n",
            "        3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01,\n",
            "        3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01, 3.3607e-05, 9.9981e-01])\n",
            "loss at 0 epoch 0.00010953241871902719\n",
            "   \n",
            "x average tensor([1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927,\n",
            "        2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507])\n",
            "Y hat tensor([5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01,\n",
            "        5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01,\n",
            "        5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01])\n",
            "Loss 7.063416705932468e-05 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927,\n",
            "        2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507, 1.3927, 2.5507])\n",
            "yhat at 0 epoch tensor([5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01,\n",
            "        5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01,\n",
            "        5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01, 5.2203e-05, 9.9991e-01])\n",
            "loss at 0 epoch 7.063416705932468e-05\n",
            "************************************************************\n",
            "x average tensor([1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330,\n",
            "        2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398])\n",
            "Y hat tensor([1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01,\n",
            "        1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01,\n",
            "        1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01])\n",
            "Loss 6.300504446699051e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330,\n",
            "        2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398])\n",
            "yhat at 0 epoch tensor([1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01,\n",
            "        1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01,\n",
            "        1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01, 1.9422e-05, 9.9989e-01])\n",
            "loss at 0 epoch 6.300504901446402e-05\n",
            "   \n",
            "x average tensor([1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330,\n",
            "        2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398])\n",
            "Y hat tensor([2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01,\n",
            "        2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01,\n",
            "        2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01])\n",
            "Loss 4.500268914853223e-05 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330,\n",
            "        2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398, 1.3330, 2.5398])\n",
            "yhat at 0 epoch tensor([2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01,\n",
            "        2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01,\n",
            "        2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01, 2.6365e-05, 9.9994e-01])\n",
            "loss at 0 epoch 4.500268914853223e-05\n",
            "************************************************************\n",
            "x average tensor([1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918,\n",
            "        2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323])\n",
            "Y hat tensor([1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01,\n",
            "        1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3215e-05, 9.9993e-01,\n",
            "        1.3215e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01])\n",
            "Loss 4.267827171133831e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918,\n",
            "        2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323])\n",
            "yhat at 0 epoch tensor([1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01,\n",
            "        1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3215e-05, 9.9993e-01,\n",
            "        1.3215e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01, 1.3216e-05, 9.9993e-01])\n",
            "loss at 0 epoch 4.2678268073359504e-05\n",
            "   \n",
            "x average tensor([1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918,\n",
            "        2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323])\n",
            "Y hat tensor([1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01,\n",
            "        1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01,\n",
            "        1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01])\n",
            "Loss 3.290244421805255e-05 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918,\n",
            "        2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323, 1.2918, 2.5323])\n",
            "yhat at 0 epoch tensor([1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01,\n",
            "        1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01,\n",
            "        1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01, 1.6469e-05, 9.9995e-01])\n",
            "loss at 0 epoch 3.290244421805255e-05\n",
            "************************************************************\n",
            "x average tensor([1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619,\n",
            "        2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268])\n",
            "Y hat tensor([9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01,\n",
            "        9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01,\n",
            "        9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01])\n",
            "Loss 3.2038252356869634e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619,\n",
            "        2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268])\n",
            "yhat at 0 epoch tensor([9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01,\n",
            "        9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01,\n",
            "        9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01, 9.9471e-06, 9.9995e-01])\n",
            "loss at 0 epoch 3.2038253266364336e-05\n",
            "   \n",
            "x average tensor([1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619,\n",
            "        2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268])\n",
            "Y hat tensor([1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01,\n",
            "        1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01,\n",
            "        1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01])\n",
            "Loss 2.6226496629533358e-05 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619,\n",
            "        2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268, 1.2619, 2.5268])\n",
            "yhat at 0 epoch tensor([1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01,\n",
            "        1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01,\n",
            "        1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01, 1.1572e-05, 9.9996e-01])\n",
            "loss at 0 epoch 2.6226496629533358e-05\n",
            "************************************************************\n",
            "x average tensor([1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406,\n",
            "        2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229])\n",
            "Y hat tensor([8.0521e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01,\n",
            "        8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01,\n",
            "        8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01])\n",
            "Loss 2.5839106456260197e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406,\n",
            "        2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229])\n",
            "yhat at 0 epoch tensor([8.0521e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01,\n",
            "        8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01,\n",
            "        8.0522e-06, 9.9996e-01, 8.0522e-06, 9.9996e-01, 8.0521e-06, 9.9996e-01])\n",
            "loss at 0 epoch 2.58391082752496e-05\n",
            "   \n",
            "x average tensor([1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406,\n",
            "        2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229])\n",
            "Y hat tensor([8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01,\n",
            "        8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01,\n",
            "        8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01])\n",
            "Loss 2.2232867195270956e-05 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406,\n",
            "        2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229, 1.2406, 2.5229])\n",
            "yhat at 0 epoch tensor([8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01,\n",
            "        8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01,\n",
            "        8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01, 8.9134e-06, 9.9996e-01])\n",
            "loss at 0 epoch 2.2232867195270956e-05\n",
            "************************************************************\n",
            "x average tensor([1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254,\n",
            "        2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201])\n",
            "Y hat tensor([6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01,\n",
            "        6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01,\n",
            "        6.8843e-06, 9.9996e-01, 6.8843e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01])\n",
            "Loss 2.2047453436850144e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254,\n",
            "        2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201])\n",
            "yhat at 0 epoch tensor([6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01,\n",
            "        6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01,\n",
            "        6.8843e-06, 9.9996e-01, 6.8843e-06, 9.9996e-01, 6.8844e-06, 9.9996e-01])\n",
            "loss at 0 epoch 2.204745396738872e-05\n",
            "   \n",
            "x average tensor([1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254,\n",
            "        2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201])\n",
            "Y hat tensor([7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01, 7.5590e-06, 9.9997e-01,\n",
            "        7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01,\n",
            "        7.5590e-06, 9.9997e-01, 7.5590e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01])\n",
            "Loss 1.9163142496836372e-05 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254,\n",
            "        2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201, 1.2254, 2.5201])\n",
            "yhat at 0 epoch tensor([7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01, 7.5590e-06, 9.9997e-01,\n",
            "        7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01,\n",
            "        7.5590e-06, 9.9997e-01, 7.5590e-06, 9.9997e-01, 7.5591e-06, 9.9997e-01])\n",
            "loss at 0 epoch 1.9163142496836372e-05\n",
            "************************************************************\n",
            "x average tensor([1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114,\n",
            "        2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175])\n",
            "Y hat tensor([5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01,\n",
            "        5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01,\n",
            "        5.9504e-06, 9.9997e-01, 5.9503e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01])\n",
            "Loss 1.9014148847418255e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114,\n",
            "        2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175])\n",
            "yhat at 0 epoch tensor([5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01,\n",
            "        5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01,\n",
            "        5.9504e-06, 9.9997e-01, 5.9503e-06, 9.9997e-01, 5.9504e-06, 9.9997e-01])\n",
            "loss at 0 epoch 1.9014145436813124e-05\n",
            "   \n",
            "x average tensor([1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114,\n",
            "        2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175])\n",
            "Y hat tensor([6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01,\n",
            "        6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01,\n",
            "        6.5266e-06, 9.9997e-01, 6.5265e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01])\n",
            "Loss 1.648086981731467e-05 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114,\n",
            "        2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175, 1.2114, 2.5175])\n",
            "yhat at 0 epoch tensor([6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01,\n",
            "        6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01,\n",
            "        6.5266e-06, 9.9997e-01, 6.5265e-06, 9.9997e-01, 6.5266e-06, 9.9997e-01])\n",
            "loss at 0 epoch 1.648086981731467e-05\n",
            "************************************************************\n",
            "x average tensor([1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976,\n",
            "        2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149])\n",
            "Y hat tensor([5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01,\n",
            "        5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01,\n",
            "        5.1438e-06, 9.9997e-01, 5.1438e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01])\n",
            "Loss 1.6391474900956382e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976,\n",
            "        2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149])\n",
            "yhat at 0 epoch tensor([5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01,\n",
            "        5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01,\n",
            "        5.1438e-06, 9.9997e-01, 5.1438e-06, 9.9997e-01, 5.1439e-06, 9.9997e-01])\n",
            "loss at 0 epoch 1.6391473764088005e-05\n",
            "   \n",
            "x average tensor([1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976,\n",
            "        2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149])\n",
            "Y hat tensor([5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01,\n",
            "        5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01,\n",
            "        5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01])\n",
            "Loss 1.4782103789912071e-05 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976,\n",
            "        2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149, 1.1976, 2.5149])\n",
            "yhat at 0 epoch tensor([5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01,\n",
            "        5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01,\n",
            "        5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01, 5.5014e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.4782103789912071e-05\n",
            "************************************************************\n",
            "x average tensor([1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875,\n",
            "        2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131])\n",
            "Y hat tensor([4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01,\n",
            "        4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01,\n",
            "        4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01])\n",
            "Loss 1.472250619372062e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875,\n",
            "        2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131])\n",
            "yhat at 0 epoch tensor([4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01,\n",
            "        4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01,\n",
            "        4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01, 4.6217e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.4722507330588996e-05\n",
            "   \n",
            "x average tensor([1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875,\n",
            "        2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131])\n",
            "Y hat tensor([4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01,\n",
            "        4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01,\n",
            "        4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01])\n",
            "Loss 1.367940058116801e-05 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875,\n",
            "        2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131, 1.1875, 2.5131])\n",
            "yhat at 0 epoch tensor([4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01,\n",
            "        4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01,\n",
            "        4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01, 4.8359e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.367940058116801e-05\n",
            "************************************************************\n",
            "x average tensor([1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807,\n",
            "        2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118])\n",
            "Y hat tensor([4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01,\n",
            "        4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01,\n",
            "        4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01])\n",
            "Loss 1.3709206541534513e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807,\n",
            "        2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118])\n",
            "yhat at 0 epoch tensor([4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01,\n",
            "        4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01,\n",
            "        4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01, 4.2975e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.3709205632039811e-05\n",
            "   \n",
            "x average tensor([1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807,\n",
            "        2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118])\n",
            "Y hat tensor([4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01,\n",
            "        4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01,\n",
            "        4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01])\n",
            "Loss 1.272570534638362e-05 19999\n",
            "  \n",
            "minimize a\n",
            "x average at 0 epoch tensor([1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807,\n",
            "        2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118, 1.1807, 2.5118])\n",
            "yhat at 0 epoch tensor([4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01,\n",
            "        4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01,\n",
            "        4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01, 4.4955e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.272570534638362e-05\n",
            "************************************************************\n",
            "x average tensor([1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739,\n",
            "        2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105])\n",
            "Y hat tensor([3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01,\n",
            "        3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01,\n",
            "        3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01])\n",
            "Loss 1.2725711258099182e-05 19999\n",
            "************************************************************\n",
            "  \n",
            "Minimize b and c\n",
            "x average at 0 epoch tensor([1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739,\n",
            "        2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105])\n",
            "yhat at 0 epoch tensor([3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01,\n",
            "        3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01,\n",
            "        3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01, 3.9963e-06, 9.9998e-01])\n",
            "loss at 0 epoch 1.2725711712846532e-05\n",
            "   \n",
            "x average tensor([1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739,\n",
            "        2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105, 1.1739, 2.5105])\n",
            "Y hat tensor([4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01,\n",
            "        4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01,\n",
            "        4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01, 4.1793e-06, 9.9998e-01])\n",
            "Loss 1.1801817890955135e-05 19999\n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4QCUN0QfSCmD",
        "outputId": "dde1c28a-a883-4de9-835b-e1682bba4714"
      },
      "source": [
        "data"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sno</th>\n",
              "      <th>b_c_fixed</th>\n",
              "      <th>a_fixed</th>\n",
              "      <th>a_value</th>\n",
              "      <th>b_value</th>\n",
              "      <th>c_value</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.941030</td>\n",
              "      <td>-21.124401</td>\n",
              "      <td>0.346568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.110344</td>\n",
              "      <td>7.941030</td>\n",
              "      <td>-21.124401</td>\n",
              "      <td>0.267054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.110344</td>\n",
              "      <td>10.221793</td>\n",
              "      <td>-25.885893</td>\n",
              "      <td>0.133527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.175237</td>\n",
              "      <td>10.221793</td>\n",
              "      <td>-25.885893</td>\n",
              "      <td>0.099669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.175237</td>\n",
              "      <td>11.828355</td>\n",
              "      <td>-28.848444</td>\n",
              "      <td>0.049833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.224443</td>\n",
              "      <td>11.828355</td>\n",
              "      <td>-28.848444</td>\n",
              "      <td>0.036293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.224443</td>\n",
              "      <td>13.103411</td>\n",
              "      <td>-30.900333</td>\n",
              "      <td>0.018146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.265743</td>\n",
              "      <td>13.103411</td>\n",
              "      <td>-30.900333</td>\n",
              "      <td>0.012918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.265743</td>\n",
              "      <td>14.176970</td>\n",
              "      <td>-32.378441</td>\n",
              "      <td>0.006459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.302198</td>\n",
              "      <td>14.176970</td>\n",
              "      <td>-32.378441</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.302198</td>\n",
              "      <td>14.912832</td>\n",
              "      <td>-33.007488</td>\n",
              "      <td>0.002441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.335762</td>\n",
              "      <td>14.912832</td>\n",
              "      <td>-33.007488</td>\n",
              "      <td>0.001666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.335762</td>\n",
              "      <td>15.461018</td>\n",
              "      <td>-33.155376</td>\n",
              "      <td>0.000951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.367467</td>\n",
              "      <td>15.461018</td>\n",
              "      <td>-33.155376</td>\n",
              "      <td>0.000635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.367467</td>\n",
              "      <td>15.938407</td>\n",
              "      <td>-33.119297</td>\n",
              "      <td>0.000365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>9</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.397039</td>\n",
              "      <td>15.938407</td>\n",
              "      <td>-33.119297</td>\n",
              "      <td>0.000244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.397039</td>\n",
              "      <td>16.316177</td>\n",
              "      <td>-33.024620</td>\n",
              "      <td>0.000143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>10</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.420388</td>\n",
              "      <td>16.316177</td>\n",
              "      <td>-33.024620</td>\n",
              "      <td>0.000110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.420388</td>\n",
              "      <td>16.569515</td>\n",
              "      <td>-32.937027</td>\n",
              "      <td>0.000071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>11</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.435816</td>\n",
              "      <td>16.569515</td>\n",
              "      <td>-32.937027</td>\n",
              "      <td>0.000063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>11</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.435816</td>\n",
              "      <td>16.743834</td>\n",
              "      <td>-32.863758</td>\n",
              "      <td>0.000045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>12</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.446387</td>\n",
              "      <td>16.743834</td>\n",
              "      <td>-32.863758</td>\n",
              "      <td>0.000043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>12</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.446387</td>\n",
              "      <td>16.873188</td>\n",
              "      <td>-32.810760</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>13</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.454003</td>\n",
              "      <td>16.873188</td>\n",
              "      <td>-32.810760</td>\n",
              "      <td>0.000032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>13</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.454003</td>\n",
              "      <td>16.975836</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>14</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.459430</td>\n",
              "      <td>16.975836</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.459430</td>\n",
              "      <td>17.057751</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>15</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.463268</td>\n",
              "      <td>17.057751</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>15</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.463268</td>\n",
              "      <td>17.134045</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>16</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.466801</td>\n",
              "      <td>17.134045</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>16</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.466801</td>\n",
              "      <td>17.210339</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>17</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.470296</td>\n",
              "      <td>17.210339</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>17</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.470296</td>\n",
              "      <td>17.266453</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>18</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.472843</td>\n",
              "      <td>17.266453</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>18</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.472843</td>\n",
              "      <td>17.304600</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>19</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.474562</td>\n",
              "      <td>17.304600</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>19</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.474562</td>\n",
              "      <td>17.342747</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.476273</td>\n",
              "      <td>17.342747</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>20</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.476273</td>\n",
              "      <td>17.380894</td>\n",
              "      <td>-32.788967</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sno b_c_fixed a_fixed   a_value    b_value    c_value      loss\n",
              "0    0      True    True  0.000000   0.000000   0.000000  0.693147\n",
              "1    1      True   False  0.000000   0.000000   0.000000  0.693147\n",
              "2    1     False    True  0.000000   7.941030 -21.124401  0.346568\n",
              "3    2      True   False -0.110344   7.941030 -21.124401  0.267054\n",
              "4    2     False    True -0.110344  10.221793 -25.885893  0.133527\n",
              "5    3      True   False -0.175237  10.221793 -25.885893  0.099669\n",
              "6    3     False    True -0.175237  11.828355 -28.848444  0.049833\n",
              "7    4      True   False -0.224443  11.828355 -28.848444  0.036293\n",
              "8    4     False    True -0.224443  13.103411 -30.900333  0.018146\n",
              "9    5      True   False -0.265743  13.103411 -30.900333  0.012918\n",
              "10   5     False    True -0.265743  14.176970 -32.378441  0.006459\n",
              "11   6      True   False -0.302198  14.176970 -32.378441  0.004500\n",
              "12   6     False    True -0.302198  14.912832 -33.007488  0.002441\n",
              "13   7      True   False -0.335762  14.912832 -33.007488  0.001666\n",
              "14   7     False    True -0.335762  15.461018 -33.155376  0.000951\n",
              "15   8      True   False -0.367467  15.461018 -33.155376  0.000635\n",
              "16   8     False    True -0.367467  15.938407 -33.119297  0.000365\n",
              "17   9      True   False -0.397039  15.938407 -33.119297  0.000244\n",
              "18   9     False    True -0.397039  16.316177 -33.024620  0.000143\n",
              "19  10      True   False -0.420388  16.316177 -33.024620  0.000110\n",
              "20  10     False    True -0.420388  16.569515 -32.937027  0.000071\n",
              "21  11      True   False -0.435816  16.569515 -32.937027  0.000063\n",
              "22  11     False    True -0.435816  16.743834 -32.863758  0.000045\n",
              "23  12      True   False -0.446387  16.743834 -32.863758  0.000043\n",
              "24  12     False    True -0.446387  16.873188 -32.810760  0.000033\n",
              "25  13      True   False -0.454003  16.873188 -32.810760  0.000032\n",
              "26  13     False    True -0.454003  16.975836 -32.788967  0.000026\n",
              "27  14      True   False -0.459430  16.975836 -32.788967  0.000026\n",
              "28  14     False    True -0.459430  17.057751 -32.788967  0.000022\n",
              "29  15      True   False -0.463268  17.057751 -32.788967  0.000022\n",
              "30  15     False    True -0.463268  17.134045 -32.788967  0.000019\n",
              "31  16      True   False -0.466801  17.134045 -32.788967  0.000019\n",
              "32  16     False    True -0.466801  17.210339 -32.788967  0.000016\n",
              "33  17      True   False -0.470296  17.210339 -32.788967  0.000016\n",
              "34  17     False    True -0.470296  17.266453 -32.788967  0.000015\n",
              "35  18      True   False -0.472843  17.266453 -32.788967  0.000015\n",
              "36  18     False    True -0.472843  17.304600 -32.788967  0.000014\n",
              "37  19      True   False -0.474562  17.304600 -32.788967  0.000014\n",
              "38  19     False    True -0.474562  17.342747 -32.788967  0.000013\n",
              "39  20      True   False -0.476273  17.342747 -32.788967  0.000013\n",
              "40  20     False    True -0.476273  17.380894 -32.788967  0.000012"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAJXgrtfSErs"
      },
      "source": [
        "data.to_csv(\"data_1_m_9_2.csv\",index=False)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jiR9bg-SEkW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqR2PqyUSEbk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWb16RbsyDI2"
      },
      "source": [
        "# m = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7hre0rnyHaA",
        "outputId": "97c50be4-eddd-43c8-b4e9-284d7fb2ceca"
      },
      "source": [
        "X2 = np.ones((50,50))*3\n",
        "idx = np.arange(0,50,1)\n",
        "X2[idx,idx] =  -1\n",
        "\n",
        "X3 = np.ones((50,50))*3\n",
        "X3[idx,idx] =  1\n",
        "\n",
        "X3 = np.concatenate((X2,X3),axis=0)\n",
        "print(X3,X3.shape)\n",
        "\n",
        "Y3 = np.zeros((100))\n",
        "Y3[50:] = 1\n",
        "print(Y3,Y3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.  3.  3. ...  3.  3.  3.]\n",
            " [ 3. -1.  3. ...  3.  3.  3.]\n",
            " [ 3.  3. -1. ...  3.  3.  3.]\n",
            " ...\n",
            " [ 3.  3.  3. ...  1.  3.  3.]\n",
            " [ 3.  3.  3. ...  3.  1.  3.]\n",
            " [ 3.  3.  3. ...  3.  3.  1.]] (100, 50)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1.] (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvUNfUId9dNU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X3sdejk9dFJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ECJtD-A05i9"
      },
      "source": [
        "def softmax_(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    m =  torch.max(x,dim=1,keepdims=True) \n",
        "    print(m)\n",
        "    e_x = torch.exp(torch.sub(x,m.values)) \n",
        "    return e_x / torch.sum(e_x,dim=1,keepdims=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImT5JpSPC69Q",
        "outputId": "f563eb81-4651-4257-f6fe-0e6607a57d49"
      },
      "source": [
        "a = torch.tensor([10.],requires_grad=True)\n",
        "x = torch.tensor([[3.,-1.]])\n",
        "out = torch.sum(softmax_(a*x) * x,dim=1)\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.return_types.max(\n",
            "values=tensor([[30.]], grad_fn=<MaxBackward0>),\n",
            "indices=tensor([[0]]))\n",
            "tensor([3.], grad_fn=<SumBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI-epz1AC6d6"
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QptbiRRDywS",
        "outputId": "cb11568e-e78a-4f84-8294-d2006b3beaf8"
      },
      "source": [
        "a.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.7974e-17])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy4tGD4EFrWJ",
        "outputId": "bdc0d643-f61c-46b8-b18d-7eba5650128a"
      },
      "source": [
        "l = ( torch.exp(a*x[0,0],) + torch.exp(a*x[0,1]) ) **2\n",
        "\n",
        "\n",
        "#print(l)\n",
        "\n",
        "\n",
        "f1 = ( ( ( x[0,0] - x[0,1] ) * torch.exp(a*x[0,0] + a*x[0,1]) ) / l  ) * x[0,0]\n",
        "\n",
        "f2 = ( ( ( x[0,1] - x[0,0] ) * torch.exp(a*x[0,0] + a*x[0,1]) ) / l  ) * x[0,1]\n",
        "print(f1.item()+f2.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.797367106130223e-17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwG1kifXHjpc",
        "outputId": "5545cd58-9ad9-4afe-bcb5-83a950d56a6b"
      },
      "source": [
        "x = np.array([[3,-1]])\n",
        "a = 10\n",
        "b = 1\n",
        "c = 0\n",
        "y = np.array([1])\n",
        "xhat = np.sum(softmax(a*x) * x,axis=1)\n",
        "print(xhat)\n",
        "yhat = classification_(b,c,xhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp-Ymq7sSSqs",
        "outputId": "715aedfa-7680-4564-cad8-81aacf0bd9f1"
      },
      "source": [
        "derv_f(x,xhat,y,yhat,a,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.79736681e-17]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-3.223710561997351e-18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpgFYp8QVhXa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}