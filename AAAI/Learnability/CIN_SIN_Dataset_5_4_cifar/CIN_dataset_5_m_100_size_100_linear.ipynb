{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5o64whWetUM",
    "outputId": "3b9eb569-5c2b-4ad9-8d9a-dd2d02f9a636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TeaxLxZIgKwv",
    "outputId": "afbee13f-3466-46bb-af16-76ae23d4215f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 500\n",
      "1 500\n",
      "2 500\n",
      "3 500\n",
      "4 500\n",
      "5 500\n",
      "6 500\n",
      "7 500\n",
      "8 500\n",
      "9 500\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "n_points = 500\n",
    "y = np.concatenate((np.zeros(n_points),np.ones(n_points),np.ones(n_points)*2,np.ones(n_points)*3,np.ones(n_points)*4,\n",
    "                    np.ones(n_points)*5,np.ones(n_points)*6,np.ones(n_points)*7,np.ones(n_points)*8,np.ones(n_points)*9))\n",
    "#y = np.random.randint(0,3,6000)\n",
    "idx= []\n",
    "for i in range(10):\n",
    "    print(i,sum(y==i))\n",
    "    idx.append(y==i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K_pn3BaqgPEh"
   },
   "outputs": [],
   "source": [
    "x = np.zeros((n_points*10,5))\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "cov_mat = [[0.02,0,0,0,0],[0,0.02,0,0,0],[0,0,0.02,0,0],\n",
    "                                                 [0,0,0,0.02,0],[0,0,0,0,0.02]]\n",
    "\n",
    "x[idx[0],:] = np.random.multivariate_normal(mean = [1,0,0,0,0],\n",
    "                                            cov=cov_mat,size=sum(idx[0]))\n",
    "\n",
    "\n",
    "x[idx[1],:] = np.random.multivariate_normal(mean = [0,1,0,0,0],\n",
    "                                            cov=cov_mat,size=sum(idx[1]))\n",
    "\n",
    "\n",
    "x[idx[2],:] = np.random.multivariate_normal(mean = [0,0,1,0,0],\n",
    "                                            cov=cov_mat,size=sum(idx[2]))\n",
    "\n",
    "\n",
    "x[idx[3],:] = np.random.multivariate_normal(mean = [0,0,0,-0.75,0.5],\n",
    "                                            cov=cov_mat,size=sum(idx[3]))\n",
    "\n",
    "\n",
    "\n",
    "x[idx[4],:] = np.random.multivariate_normal(mean = [0,0,0,0.65,-0.65],\n",
    "                                            cov=cov_mat,size=sum(idx[4]))\n",
    "\n",
    "\n",
    "x[idx[5],:] = np.random.multivariate_normal(mean = [0,0,0,-0.9,-0.75],\n",
    "                                            cov=cov_mat,size=sum(idx[5]))\n",
    "\n",
    "\n",
    "x[idx[6],:] = np.random.multivariate_normal(mean = [0,0,0,0.8,-0.8],\n",
    "                                            cov=cov_mat,size=sum(idx[6]))\n",
    "\n",
    "x[idx[7],:] = np.random.multivariate_normal(mean = [0,0,0,-0.5,0.8],\n",
    "                                            cov=cov_mat,size=sum(idx[7]))\n",
    "\n",
    "\n",
    "x[idx[8],:] = np.random.multivariate_normal(mean = [0,0,0,0.9,0.75],\n",
    "                                            cov=cov_mat,size=sum(idx[8]))\n",
    "\n",
    "\n",
    "x[idx[9],:] = np.random.multivariate_normal(mean = [0,0,0,-1,0.65],\n",
    "                                            cov=cov_mat,size=sum(idx[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "xVsQiqI94jnC",
    "outputId": "b9a1a30a-7d86-4e6e-abca-52bd3297331e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x147dcfa90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(x[idx[i],0],x[idx[i],1],label=\"class_\"+str(i))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ckDp9oLEgWZm"
   },
   "outputs": [],
   "source": [
    "mean_x = np.mean(x,axis=0,keepdims=True)\n",
    "std_x = np.std(x,axis=0,keepdims=True) \n",
    "x = ( x - mean_x  )  / std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "JhEjDlch4kJ2",
    "outputId": "cd487a38-8888-4520-9d51-ae0cf86fd415"
   },
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     plt.scatter(x[idx[i],0],x[idx[i],1],label=\"class_\"+str(i))\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bg_idx = [ np.where(idx[3] == True)[0], \n",
    "#           np.where(idx[4] == True)[0], \n",
    "#           np.where(idx[5] == True)[0],\n",
    "#           np.where(idx[6] == True)[0], \n",
    "#           np.where(idx[7] == True)[0], \n",
    "#           np.where(idx[8] == True)[0],\n",
    "#           np.where(idx[9] == True)[0]]\n",
    "\n",
    "# bg_idx = np.concatenate(bg_idx, axis = 0)\n",
    "# bg_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(bg_idx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x - np.mean(x[bg_idx], axis = 0, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(x[bg_idx], axis = 0, keepdims = True), np.mean(x, axis = 0, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x/np.std(x[bg_idx], axis = 0, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.std(x[bg_idx], axis = 0, keepdims = True), np.std(x, axis = 0, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x103b97370>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x[idx[0],0],x[idx[0],1],label=\"class_\"+str(0))\n",
    "plt.scatter(x[idx[1],0],x[idx[1],1],label=\"class_\"+str(1))\n",
    "plt.scatter(x[idx[2],1],x[idx[2],2],label=\"class_\"+str(2))\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9EOCiXVkgcXD"
   },
   "outputs": [],
   "source": [
    "foreground_classes = {'class_0','class_1' }\n",
    "\n",
    "background_classes = {'bg_classes',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6JMEk8-gj4o",
    "outputId": "fd048473-578c-4772-9294-ffdeee9a2621"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1100/1100 [00:02<00:00, 393.63it/s]\n"
     ]
    }
   ],
   "source": [
    "desired_num = 1100  # 2000 + 1000\n",
    "\n",
    "\n",
    "m = 100\n",
    "\n",
    "\n",
    "\n",
    "mosaic_list_of_images =[]\n",
    "mosaic_label = []\n",
    "fore_idx=[]\n",
    "for j in tqdm(range(desired_num)):\n",
    "    np.random.seed(j)\n",
    "    fg_class  = np.random.randint(0,3)\n",
    "    fg_idx = np.random.randint(0,m)\n",
    "    a = []\n",
    "    for i in range(m):\n",
    "        if i == fg_idx:\n",
    "            b = np.random.choice(np.where(idx[fg_class]==True)[0],size=1)\n",
    "            a.append(x[b])\n",
    "#             print(\"foreground \"+str(fg_class)+\" present at \" + str(fg_idx))\n",
    "        else:\n",
    "            bg_class = np.random.randint(3,10)\n",
    "            b = np.random.choice(np.where(idx[bg_class]==True)[0],size=1)\n",
    "            a.append(x[b])\n",
    "#             print(\"background \"+str(bg_class)+\" present at \" + str(i))\n",
    "    a = np.concatenate(a,axis=0)\n",
    "    mosaic_list_of_images.append(np.reshape(a,(m,5)))\n",
    "    mosaic_label.append(fg_class)\n",
    "    fore_idx.append(fg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Tj-yqVxagvWt"
   },
   "outputs": [],
   "source": [
    "def create_avg_image_from_mosaic_dataset(mosaic_dataset,labels,foreground_index,dataset_number,m):\n",
    "  \"\"\"\n",
    "  mosaic_dataset : mosaic_dataset contains 500 patches dimension 2 each as 1 data point\n",
    "  labels : mosaic_dataset labels\n",
    "  foreground_index : contains list of indexes where foreground image is present so that using this we can take weighted average\n",
    "  dataset_number : will help us to tell what ratio of foreground image to be taken. for eg: if it is \"j\" then fg_image_ratio = j/500 , bg_image_ratio = (500-j)/499*500\n",
    "  \"\"\"\n",
    "  avg_image_dataset = []\n",
    "  for i in tqdm(range(len(mosaic_dataset))):\n",
    "    img = torch.zeros([5], dtype=torch.float64)\n",
    "    for j in range(m):\n",
    "      if j == foreground_index[i]:\n",
    "        img = img + mosaic_dataset[i][j]*dataset_number/(m)\n",
    "      else :\n",
    "        img = img + mosaic_dataset[i][j]*(m-dataset_number)/((m-1)*(m))\n",
    "    \n",
    "    avg_image_dataset.append(img)\n",
    "    \n",
    "  return avg_image_dataset , labels , foreground_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_GNrABGh7MC",
    "outputId": "9f58886b-b098-4fd2-c7d7-249e4fc27613"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:00<00:00, 292.07it/s]\n",
      "100%|| 100/100 [00:00<00:00, 291.49it/s]\n",
      "100%|| 100/100 [00:00<00:00, 295.10it/s]\n",
      "100%|| 100/100 [00:00<00:00, 288.27it/s]\n",
      "100%|| 100/100 [00:00<00:00, 295.87it/s]\n",
      "100%|| 100/100 [00:00<00:00, 292.12it/s]\n",
      "100%|| 100/100 [00:00<00:00, 296.31it/s]\n",
      "100%|| 100/100 [00:00<00:00, 296.91it/s]\n",
      "100%|| 100/100 [00:00<00:00, 294.51it/s]\n",
      "100%|| 100/100 [00:00<00:00, 296.73it/s]\n",
      "100%|| 100/100 [00:00<00:00, 285.26it/s]\n",
      "100%|| 1000/1000 [00:03<00:00, 295.01it/s]\n"
     ]
    }
   ],
   "source": [
    "tr = 100\n",
    "\n",
    "\n",
    "\n",
    "avg_image_dataset_1 , labels_1,  fg_index_1 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images[0:tr], mosaic_label[0:tr], fore_idx[0:tr] , 1,m)\n",
    "avg_image_dataset_2 , labels_2,  fg_index_2 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images[0:tr], mosaic_label[0:tr], fore_idx[0:tr] , 10,m)\n",
    "avg_image_dataset_3 , labels_3,  fg_index_3 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images[0:tr], mosaic_label[0:tr], fore_idx[0:tr] , 20,m)\n",
    "avg_image_dataset_4 , labels_4,  fg_index_4 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images[0:tr], mosaic_label[0:tr], fore_idx[0:tr] , 30,m )\n",
    "avg_image_dataset_5 , labels_5,  fg_index_5 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images[0:tr], mosaic_label[0:tr], fore_idx[0:tr] , 40,m)\n",
    "avg_image_dataset_6 , labels_6,  fg_index_6 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images[0:tr], mosaic_label[0:tr], fore_idx[0:tr] , 50,m)\n",
    "avg_image_dataset_7 , labels_7,  fg_index_7 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images[0:tr], mosaic_label[0:tr], fore_idx[0:tr] ,60,m)\n",
    "avg_image_dataset_8 , labels_8,  fg_index_8 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images[0:tr], mosaic_label[0:tr], fore_idx[0:tr] , 70,m)\n",
    "avg_image_dataset_9 , labels_9,  fg_index_9 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images[0:tr], mosaic_label[0:tr], fore_idx[0:tr] , 80,m)\n",
    "avg_image_dataset_10 , labels_10,  fg_index_10 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images[0:tr], mosaic_label[0:tr], fore_idx[0:tr] , 80,m)\n",
    "avg_image_dataset_11 , labels_11,  fg_index_11 = create_avg_image_from_mosaic_dataset(mosaic_list_of_images[0:tr], mosaic_label[0:tr], fore_idx[0:tr] , 100,m)\n",
    "avg_image_dataset_12 , labels_12,  fg_index_12= create_avg_image_from_mosaic_dataset(mosaic_list_of_images[tr:], mosaic_label[tr:], fore_idx[tr:] , 100,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mMonbxLTmryY"
   },
   "outputs": [],
   "source": [
    "avg_image_dataset_1 = torch.stack(avg_image_dataset_1,dim=0)\n",
    "avg_image_dataset_2 = torch.stack(avg_image_dataset_2,dim=0)\n",
    "avg_image_dataset_3 = torch.stack(avg_image_dataset_3,dim=0)\n",
    "avg_image_dataset_4 = torch.stack(avg_image_dataset_4,dim=0)\n",
    "avg_image_dataset_5 = torch.stack(avg_image_dataset_5,dim=0)\n",
    "avg_image_dataset_6 = torch.stack(avg_image_dataset_6,dim=0)\n",
    "avg_image_dataset_7 = torch.stack(avg_image_dataset_7,dim=0)\n",
    "avg_image_dataset_8 = torch.stack(avg_image_dataset_8,dim=0)\n",
    "avg_image_dataset_9 = torch.stack(avg_image_dataset_9,dim=0)\n",
    "avg_image_dataset_10 = torch.stack(avg_image_dataset_10,dim=0)\n",
    "avg_image_dataset_11 = torch.stack(avg_image_dataset_11,dim=0)\n",
    "avg_image_dataset_12 = torch.stack(avg_image_dataset_12,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_image_dataset_12 = avg_image_dataset_12/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q5NOxkrOjfmk",
    "outputId": "ebab8cca-faf5-4df4-814e-6d38b76f998e"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_1[:,0],avg_image_dataset_1[:,1],c=labels_1)\n",
    "# plt.title(\"Dataset 1\")\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_2[:,0],avg_image_dataset_2[:,1],c=labels_2)\n",
    "# plt.title(\"Dataset 2\")\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_3[:,0],avg_image_dataset_3[:,1],c=labels_3)\n",
    "# plt.title(\"Dataset 3\")\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_4[:,0],avg_image_dataset_4[:,1],c=labels_4)\n",
    "# plt.title(\"Dataset 4\")\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_5[:,0],avg_image_dataset_5[:,1],c=labels_5)\n",
    "# plt.title(\"Dataset 5\")\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_6[:,0],avg_image_dataset_6[:,1],c=labels_6)\n",
    "# plt.title(\"Dataset 6\")\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_7[:,0],avg_image_dataset_7[:,1],c=labels_7)\n",
    "# plt.title(\"Dataset 7\")\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_8[:,0],avg_image_dataset_8[:,1],c=labels_8)\n",
    "# plt.title(\"Dataset 8\")\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_9[:,0],avg_image_dataset_9[:,1],c=labels_9)\n",
    "# plt.title(\"Dataset 9\")\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_10[:,0],avg_image_dataset_10[:,1],c=labels_10)\n",
    "# plt.title(\"Dataset 10\")\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_11[:,0],avg_image_dataset_11[:,1],c=labels_11)\n",
    "# plt.title(\"Dataset 11\")\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_12[:,0],avg_image_dataset_12[:,1],c=labels_12)\n",
    "# plt.title(\"Dataset 12\")\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_13[:,0],avg_image_dataset_13[:,1],c=labels_13)\n",
    "# plt.title(\"Dataset 13\")\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(6,8))\n",
    "# plt.scatter(avg_image_dataset_14[:,0],avg_image_dataset_14[:,1],c=labels_14)\n",
    "# plt.title(\"Dataset 14\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "IdP5nh0tpsdo"
   },
   "outputs": [],
   "source": [
    "class MosaicDataset(Dataset):\n",
    "  \"\"\"MosaicDataset dataset.\"\"\"\n",
    "\n",
    "  def __init__(self, mosaic_list_of_images, mosaic_label):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "        csv_file (string): Path to the csv file with annotations.\n",
    "        root_dir (string): Directory with all the images.\n",
    "        transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "    \"\"\"\n",
    "    self.mosaic = mosaic_list_of_images\n",
    "    self.label = mosaic_label\n",
    "    #self.fore_idx = fore_idx\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.label)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.mosaic[idx] , self.label[idx] #, self.fore_idx[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "n9p6F1jrpzbV"
   },
   "outputs": [],
   "source": [
    "batch = 256\n",
    "\n",
    "\n",
    "# training_data = avg_image_dataset_5    #just change this and training_label to desired dataset for training\n",
    "# training_label = labels_5\n",
    "\n",
    "traindata_1 = MosaicDataset(avg_image_dataset_1, labels_1 )\n",
    "trainloader_1 = DataLoader( traindata_1 , batch_size= batch ,shuffle=True)\n",
    "\n",
    "traindata_2 = MosaicDataset(avg_image_dataset_2, labels_2 )\n",
    "trainloader_2 = DataLoader( traindata_2 , batch_size= batch ,shuffle=True)\n",
    "\n",
    "traindata_3 = MosaicDataset(avg_image_dataset_3, labels_3 )\n",
    "trainloader_3 = DataLoader( traindata_3 , batch_size= batch ,shuffle=True)\n",
    "\n",
    "traindata_4 = MosaicDataset(avg_image_dataset_4, labels_4 )\n",
    "trainloader_4 = DataLoader( traindata_4 , batch_size= batch ,shuffle=True)\n",
    "\n",
    "traindata_5 = MosaicDataset(avg_image_dataset_5, labels_5 )\n",
    "trainloader_5 = DataLoader( traindata_5 , batch_size= batch ,shuffle=True)\n",
    "\n",
    "traindata_6 = MosaicDataset(avg_image_dataset_6, labels_6 )\n",
    "trainloader_6 = DataLoader( traindata_6 , batch_size= batch ,shuffle=True)\n",
    "\n",
    "traindata_7 = MosaicDataset(avg_image_dataset_7, labels_7 )\n",
    "trainloader_7 = DataLoader( traindata_7 , batch_size= batch ,shuffle=True)\n",
    "\n",
    "traindata_8 = MosaicDataset(avg_image_dataset_8, labels_8 )\n",
    "trainloader_8 = DataLoader( traindata_8 , batch_size= batch ,shuffle=True)\n",
    "\n",
    "traindata_9 = MosaicDataset(avg_image_dataset_9, labels_9 )\n",
    "trainloader_9 = DataLoader( traindata_9 , batch_size= batch ,shuffle=True)\n",
    "\n",
    "\n",
    "traindata_10 = MosaicDataset(avg_image_dataset_10, labels_10 )\n",
    "trainloader_10 = DataLoader( traindata_10 , batch_size= batch ,shuffle=True)\n",
    "\n",
    "traindata_11 = MosaicDataset(avg_image_dataset_11, labels_11 )\n",
    "trainloader_11 = DataLoader( traindata_11, batch_size= batch ,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "testdata_1 = MosaicDataset(avg_image_dataset_1, labels_1 )\n",
    "testloader_1 = DataLoader( testdata_1 , batch_size= batch ,shuffle=False)\n",
    "\n",
    "testdata_2 = MosaicDataset(avg_image_dataset_2, labels_2 )\n",
    "testloader_2 = DataLoader( testdata_2 , batch_size= batch ,shuffle=False)\n",
    "\n",
    "testdata_3 = MosaicDataset(avg_image_dataset_3, labels_3 )\n",
    "testloader_3 = DataLoader( testdata_3 , batch_size= batch ,shuffle=False)\n",
    "\n",
    "testdata_4 = MosaicDataset(avg_image_dataset_4, labels_4 )\n",
    "testloader_4 = DataLoader( testdata_4 , batch_size= batch ,shuffle=False)\n",
    "\n",
    "testdata_5 = MosaicDataset(avg_image_dataset_5, labels_5 )\n",
    "testloader_5 = DataLoader( testdata_5 , batch_size= batch ,shuffle=False)\n",
    "\n",
    "testdata_6 = MosaicDataset(avg_image_dataset_6, labels_6 )\n",
    "testloader_6 = DataLoader( testdata_6 , batch_size= batch ,shuffle=False)\n",
    "\n",
    "testdata_7 = MosaicDataset(avg_image_dataset_7, labels_7 )\n",
    "testloader_7 = DataLoader( testdata_7 , batch_size= batch ,shuffle=False)\n",
    "\n",
    "testdata_8 = MosaicDataset(avg_image_dataset_8, labels_8 )\n",
    "testloader_8 = DataLoader( testdata_8 , batch_size= batch ,shuffle=False)\n",
    "\n",
    "testdata_9 = MosaicDataset(avg_image_dataset_9, labels_9 )\n",
    "testloader_9 = DataLoader( testdata_9 , batch_size= batch ,shuffle=False)\n",
    "\n",
    "testdata_10 = MosaicDataset(avg_image_dataset_10, labels_10 )\n",
    "testloader_10 = DataLoader( testdata_10 , batch_size= batch ,shuffle=False)\n",
    "\n",
    "\n",
    "testdata_11 = MosaicDataset(avg_image_dataset_11, labels_11)\n",
    "testloader_11 = DataLoader( testdata_11 , batch_size= batch ,shuffle=False)\n",
    "\n",
    "\n",
    "testdata_12 = MosaicDataset(avg_image_dataset_12, labels_12)\n",
    "testloader_12 = DataLoader( testdata_12 , batch_size= batch ,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "25ep84nHb_4z"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = nn.Linear(5, 3)\n",
    "    torch.nn.init.xavier_normal_(self.fc1.weight)\n",
    "    torch.nn.init.zeros_(self.fc1.bias)\n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    # print(x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4055,  0.0120, -0.0452,  0.8600, -0.5742],\n",
      "        [ 0.4041, -0.6415,  0.1186,  0.2583,  0.0892],\n",
      "        [ 0.5539,  0.7417, -0.8079, -0.7441,  0.5195]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for params in net.parameters():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "P1gKqHb2cdCt"
   },
   "outputs": [],
   "source": [
    "def test_all(number, testloader,net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    out = []\n",
    "    pred = []\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device),labels.to(device)\n",
    "            out.append(labels.cpu().numpy())\n",
    "            outputs= net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            pred.append(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the test dataset %d: %d %%' % (number , 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tLCcSRQOcy0M"
   },
   "outputs": [],
   "source": [
    "def train_all(trainloader, ds_number, testloader_list):\n",
    "    \n",
    "    print(\"--\"*40)\n",
    "    print(\"training on data set  \", ds_number)\n",
    "    torch.manual_seed(12)\n",
    "    net = Net().double()\n",
    "    net = net.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)#, momentum=0.9)\n",
    "    \n",
    "    acti = []\n",
    "    loss_curi = []\n",
    "    epochs = 300\n",
    "    \n",
    "    for epoch in range(epochs): # loop over the dataset multiple times\n",
    "        ep_lossi = []\n",
    "\n",
    "        running_loss = 0.0\n",
    "        if epoch ==0:\n",
    "            with torch.no_grad():\n",
    "                for k, data in enumerate(trainloader, 0):\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = inputs.to(device),labels.to(device)\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    running_loss += loss.item()\n",
    "                    if k+1 ==8:\n",
    "                        ep_lossi.append(running_loss/(k+1))\n",
    "                        print('[%d, %5d] loss: %.3f' %(epoch, k+ 1, running_loss/(k+1) ))\n",
    "                        running_loss = 0.0  \n",
    "                loss_curi.append(np.mean(ep_lossi))\n",
    "                ep_lossi = [] \n",
    "        \n",
    "        \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device),labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            mini = 1\n",
    "            if i % mini == (mini-1):    \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / ( mini ) ))\n",
    "                ep_lossi.append(running_loss/ (mini) ) # loss per minibatch\n",
    "                running_loss = 0.0\n",
    "                \n",
    "        loss_curi.append(np.mean(ep_lossi))   #loss per epoch\n",
    "    print('Finished Training')\n",
    "    torch.save(net.state_dict(),\"train_dataset_\"+str(ds_number)+\"_\"+str(epochs)+\".pt\")\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the train images: %d %%' % (  100 * correct / total))\n",
    "    \n",
    "    for i, j in enumerate(testloader_list):\n",
    "        test_all(i+1, j,net)\n",
    "    \n",
    "    print(\"--\"*40)\n",
    "    \n",
    "    return loss_curi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8w9MEZ2dwt-",
    "outputId": "6bf1a48d-0866-4503-8dc8-6d0d5eee963c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "training on data set   1\n",
      "[1,     1] loss: 2.223\n",
      "[2,     1] loss: 1.109\n",
      "[3,     1] loss: 1.107\n",
      "[4,     1] loss: 1.105\n",
      "[5,     1] loss: 1.103\n",
      "[6,     1] loss: 1.102\n",
      "[7,     1] loss: 1.101\n",
      "[8,     1] loss: 1.100\n",
      "[9,     1] loss: 1.099\n",
      "[10,     1] loss: 1.099\n",
      "[11,     1] loss: 1.098\n",
      "[12,     1] loss: 1.098\n",
      "[13,     1] loss: 1.097\n",
      "[14,     1] loss: 1.097\n",
      "[15,     1] loss: 1.097\n",
      "[16,     1] loss: 1.096\n",
      "[17,     1] loss: 1.096\n",
      "[18,     1] loss: 1.095\n",
      "[19,     1] loss: 1.095\n",
      "[20,     1] loss: 1.095\n",
      "[21,     1] loss: 1.094\n",
      "[22,     1] loss: 1.094\n",
      "[23,     1] loss: 1.093\n",
      "[24,     1] loss: 1.093\n",
      "[25,     1] loss: 1.092\n",
      "[26,     1] loss: 1.092\n",
      "[27,     1] loss: 1.091\n",
      "[28,     1] loss: 1.091\n",
      "[29,     1] loss: 1.090\n",
      "[30,     1] loss: 1.090\n",
      "[31,     1] loss: 1.089\n",
      "[32,     1] loss: 1.089\n",
      "[33,     1] loss: 1.088\n",
      "[34,     1] loss: 1.088\n",
      "[35,     1] loss: 1.087\n",
      "[36,     1] loss: 1.087\n",
      "[37,     1] loss: 1.087\n",
      "[38,     1] loss: 1.086\n",
      "[39,     1] loss: 1.086\n",
      "[40,     1] loss: 1.085\n",
      "[41,     1] loss: 1.085\n",
      "[42,     1] loss: 1.084\n",
      "[43,     1] loss: 1.084\n",
      "[44,     1] loss: 1.084\n",
      "[45,     1] loss: 1.083\n",
      "[46,     1] loss: 1.083\n",
      "[47,     1] loss: 1.082\n",
      "[48,     1] loss: 1.082\n",
      "[49,     1] loss: 1.081\n",
      "[50,     1] loss: 1.081\n",
      "[51,     1] loss: 1.081\n",
      "[52,     1] loss: 1.080\n",
      "[53,     1] loss: 1.080\n",
      "[54,     1] loss: 1.079\n",
      "[55,     1] loss: 1.079\n",
      "[56,     1] loss: 1.078\n",
      "[57,     1] loss: 1.078\n",
      "[58,     1] loss: 1.078\n",
      "[59,     1] loss: 1.077\n",
      "[60,     1] loss: 1.077\n",
      "[61,     1] loss: 1.076\n",
      "[62,     1] loss: 1.076\n",
      "[63,     1] loss: 1.076\n",
      "[64,     1] loss: 1.075\n",
      "[65,     1] loss: 1.075\n",
      "[66,     1] loss: 1.075\n",
      "[67,     1] loss: 1.074\n",
      "[68,     1] loss: 1.074\n",
      "[69,     1] loss: 1.073\n",
      "[70,     1] loss: 1.073\n",
      "[71,     1] loss: 1.073\n",
      "[72,     1] loss: 1.072\n",
      "[73,     1] loss: 1.072\n",
      "[74,     1] loss: 1.071\n",
      "[75,     1] loss: 1.071\n",
      "[76,     1] loss: 1.071\n",
      "[77,     1] loss: 1.070\n",
      "[78,     1] loss: 1.070\n",
      "[79,     1] loss: 1.070\n",
      "[80,     1] loss: 1.069\n",
      "[81,     1] loss: 1.069\n",
      "[82,     1] loss: 1.068\n",
      "[83,     1] loss: 1.068\n",
      "[84,     1] loss: 1.068\n",
      "[85,     1] loss: 1.067\n",
      "[86,     1] loss: 1.067\n",
      "[87,     1] loss: 1.067\n",
      "[88,     1] loss: 1.066\n",
      "[89,     1] loss: 1.066\n",
      "[90,     1] loss: 1.066\n",
      "[91,     1] loss: 1.065\n",
      "[92,     1] loss: 1.065\n",
      "[93,     1] loss: 1.064\n",
      "[94,     1] loss: 1.064\n",
      "[95,     1] loss: 1.064\n",
      "[96,     1] loss: 1.063\n",
      "[97,     1] loss: 1.063\n",
      "[98,     1] loss: 1.063\n",
      "[99,     1] loss: 1.062\n",
      "[100,     1] loss: 1.062\n",
      "[101,     1] loss: 1.062\n",
      "[102,     1] loss: 1.061\n",
      "[103,     1] loss: 1.061\n",
      "[104,     1] loss: 1.061\n",
      "[105,     1] loss: 1.060\n",
      "[106,     1] loss: 1.060\n",
      "[107,     1] loss: 1.060\n",
      "[108,     1] loss: 1.059\n",
      "[109,     1] loss: 1.059\n",
      "[110,     1] loss: 1.059\n",
      "[111,     1] loss: 1.058\n",
      "[112,     1] loss: 1.058\n",
      "[113,     1] loss: 1.058\n",
      "[114,     1] loss: 1.057\n",
      "[115,     1] loss: 1.057\n",
      "[116,     1] loss: 1.057\n",
      "[117,     1] loss: 1.056\n",
      "[118,     1] loss: 1.056\n",
      "[119,     1] loss: 1.056\n",
      "[120,     1] loss: 1.055\n",
      "[121,     1] loss: 1.055\n",
      "[122,     1] loss: 1.055\n",
      "[123,     1] loss: 1.054\n",
      "[124,     1] loss: 1.054\n",
      "[125,     1] loss: 1.054\n",
      "[126,     1] loss: 1.053\n",
      "[127,     1] loss: 1.053\n",
      "[128,     1] loss: 1.053\n",
      "[129,     1] loss: 1.052\n",
      "[130,     1] loss: 1.052\n",
      "[131,     1] loss: 1.052\n",
      "[132,     1] loss: 1.051\n",
      "[133,     1] loss: 1.051\n",
      "[134,     1] loss: 1.051\n",
      "[135,     1] loss: 1.050\n",
      "[136,     1] loss: 1.050\n",
      "[137,     1] loss: 1.050\n",
      "[138,     1] loss: 1.050\n",
      "[139,     1] loss: 1.049\n",
      "[140,     1] loss: 1.049\n",
      "[141,     1] loss: 1.049\n",
      "[142,     1] loss: 1.048\n",
      "[143,     1] loss: 1.048\n",
      "[144,     1] loss: 1.048\n",
      "[145,     1] loss: 1.047\n",
      "[146,     1] loss: 1.047\n",
      "[147,     1] loss: 1.047\n",
      "[148,     1] loss: 1.046\n",
      "[149,     1] loss: 1.046\n",
      "[150,     1] loss: 1.046\n",
      "[151,     1] loss: 1.045\n",
      "[152,     1] loss: 1.045\n",
      "[153,     1] loss: 1.045\n",
      "[154,     1] loss: 1.045\n",
      "[155,     1] loss: 1.044\n",
      "[156,     1] loss: 1.044\n",
      "[157,     1] loss: 1.044\n",
      "[158,     1] loss: 1.043\n",
      "[159,     1] loss: 1.043\n",
      "[160,     1] loss: 1.043\n",
      "[161,     1] loss: 1.042\n",
      "[162,     1] loss: 1.042\n",
      "[163,     1] loss: 1.042\n",
      "[164,     1] loss: 1.042\n",
      "[165,     1] loss: 1.041\n",
      "[166,     1] loss: 1.041\n",
      "[167,     1] loss: 1.041\n",
      "[168,     1] loss: 1.040\n",
      "[169,     1] loss: 1.040\n",
      "[170,     1] loss: 1.040\n",
      "[171,     1] loss: 1.040\n",
      "[172,     1] loss: 1.039\n",
      "[173,     1] loss: 1.039\n",
      "[174,     1] loss: 1.039\n",
      "[175,     1] loss: 1.038\n",
      "[176,     1] loss: 1.038\n",
      "[177,     1] loss: 1.038\n",
      "[178,     1] loss: 1.037\n",
      "[179,     1] loss: 1.037\n",
      "[180,     1] loss: 1.037\n",
      "[181,     1] loss: 1.037\n",
      "[182,     1] loss: 1.036\n",
      "[183,     1] loss: 1.036\n",
      "[184,     1] loss: 1.036\n",
      "[185,     1] loss: 1.035\n",
      "[186,     1] loss: 1.035\n",
      "[187,     1] loss: 1.035\n",
      "[188,     1] loss: 1.035\n",
      "[189,     1] loss: 1.034\n",
      "[190,     1] loss: 1.034\n",
      "[191,     1] loss: 1.034\n",
      "[192,     1] loss: 1.033\n",
      "[193,     1] loss: 1.033\n",
      "[194,     1] loss: 1.033\n",
      "[195,     1] loss: 1.033\n",
      "[196,     1] loss: 1.032\n",
      "[197,     1] loss: 1.032\n",
      "[198,     1] loss: 1.032\n",
      "[199,     1] loss: 1.031\n",
      "[200,     1] loss: 1.031\n",
      "[201,     1] loss: 1.031\n",
      "[202,     1] loss: 1.031\n",
      "[203,     1] loss: 1.030\n",
      "[204,     1] loss: 1.030\n",
      "[205,     1] loss: 1.030\n",
      "[206,     1] loss: 1.030\n",
      "[207,     1] loss: 1.029\n",
      "[208,     1] loss: 1.029\n",
      "[209,     1] loss: 1.029\n",
      "[210,     1] loss: 1.028\n",
      "[211,     1] loss: 1.028\n",
      "[212,     1] loss: 1.028\n",
      "[213,     1] loss: 1.028\n",
      "[214,     1] loss: 1.027\n",
      "[215,     1] loss: 1.027\n",
      "[216,     1] loss: 1.027\n",
      "[217,     1] loss: 1.027\n",
      "[218,     1] loss: 1.026\n",
      "[219,     1] loss: 1.026\n",
      "[220,     1] loss: 1.026\n",
      "[221,     1] loss: 1.025\n",
      "[222,     1] loss: 1.025\n",
      "[223,     1] loss: 1.025\n",
      "[224,     1] loss: 1.025\n",
      "[225,     1] loss: 1.024\n",
      "[226,     1] loss: 1.024\n",
      "[227,     1] loss: 1.024\n",
      "[228,     1] loss: 1.024\n",
      "[229,     1] loss: 1.023\n",
      "[230,     1] loss: 1.023\n",
      "[231,     1] loss: 1.023\n",
      "[232,     1] loss: 1.022\n",
      "[233,     1] loss: 1.022\n",
      "[234,     1] loss: 1.022\n",
      "[235,     1] loss: 1.022\n",
      "[236,     1] loss: 1.021\n",
      "[237,     1] loss: 1.021\n",
      "[238,     1] loss: 1.021\n",
      "[239,     1] loss: 1.021\n",
      "[240,     1] loss: 1.020\n",
      "[241,     1] loss: 1.020\n",
      "[242,     1] loss: 1.020\n",
      "[243,     1] loss: 1.020\n",
      "[244,     1] loss: 1.019\n",
      "[245,     1] loss: 1.019\n",
      "[246,     1] loss: 1.019\n",
      "[247,     1] loss: 1.019\n",
      "[248,     1] loss: 1.018\n",
      "[249,     1] loss: 1.018\n",
      "[250,     1] loss: 1.018\n",
      "[251,     1] loss: 1.018\n",
      "[252,     1] loss: 1.017\n",
      "[253,     1] loss: 1.017\n",
      "[254,     1] loss: 1.017\n",
      "[255,     1] loss: 1.016\n",
      "[256,     1] loss: 1.016\n",
      "[257,     1] loss: 1.016\n",
      "[258,     1] loss: 1.016\n",
      "[259,     1] loss: 1.015\n",
      "[260,     1] loss: 1.015\n",
      "[261,     1] loss: 1.015\n",
      "[262,     1] loss: 1.015\n",
      "[263,     1] loss: 1.014\n",
      "[264,     1] loss: 1.014\n",
      "[265,     1] loss: 1.014\n",
      "[266,     1] loss: 1.014\n",
      "[267,     1] loss: 1.013\n",
      "[268,     1] loss: 1.013\n",
      "[269,     1] loss: 1.013\n",
      "[270,     1] loss: 1.013\n",
      "[271,     1] loss: 1.012\n",
      "[272,     1] loss: 1.012\n",
      "[273,     1] loss: 1.012\n",
      "[274,     1] loss: 1.012\n",
      "[275,     1] loss: 1.011\n",
      "[276,     1] loss: 1.011\n",
      "[277,     1] loss: 1.011\n",
      "[278,     1] loss: 1.011\n",
      "[279,     1] loss: 1.010\n",
      "[280,     1] loss: 1.010\n",
      "[281,     1] loss: 1.010\n",
      "[282,     1] loss: 1.010\n",
      "[283,     1] loss: 1.010\n",
      "[284,     1] loss: 1.009\n",
      "[285,     1] loss: 1.009\n",
      "[286,     1] loss: 1.009\n",
      "[287,     1] loss: 1.009\n",
      "[288,     1] loss: 1.008\n",
      "[289,     1] loss: 1.008\n",
      "[290,     1] loss: 1.008\n",
      "[291,     1] loss: 1.008\n",
      "[292,     1] loss: 1.007\n",
      "[293,     1] loss: 1.007\n",
      "[294,     1] loss: 1.007\n",
      "[295,     1] loss: 1.007\n",
      "[296,     1] loss: 1.006\n",
      "[297,     1] loss: 1.006\n",
      "[298,     1] loss: 1.006\n",
      "[299,     1] loss: 1.006\n",
      "[300,     1] loss: 1.005\n",
      "Finished Training\n",
      "Accuracy of the network on the train images: 46 %\n",
      "Accuracy of the network on the test dataset 1: 46 %\n",
      "Accuracy of the network on the test dataset 2: 100 %\n",
      "Accuracy of the network on the test dataset 3: 100 %\n",
      "Accuracy of the network on the test dataset 4: 100 %\n",
      "Accuracy of the network on the test dataset 5: 100 %\n",
      "Accuracy of the network on the test dataset 6: 100 %\n",
      "Accuracy of the network on the test dataset 7: 100 %\n",
      "Accuracy of the network on the test dataset 8: 100 %\n",
      "Accuracy of the network on the test dataset 9: 100 %\n",
      "Accuracy of the network on the test dataset 10: 100 %\n",
      "Accuracy of the network on the test dataset 11: 100 %\n",
      "Accuracy of the network on the test dataset 12: 67 %\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "training on data set   2\n",
      "[1,     1] loss: 2.500\n",
      "[2,     1] loss: 1.244\n",
      "[3,     1] loss: 1.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,     1] loss: 1.233\n",
      "[5,     1] loss: 1.227\n",
      "[6,     1] loss: 1.222\n",
      "[7,     1] loss: 1.217\n",
      "[8,     1] loss: 1.212\n",
      "[9,     1] loss: 1.206\n",
      "[10,     1] loss: 1.201\n",
      "[11,     1] loss: 1.196\n",
      "[12,     1] loss: 1.191\n",
      "[13,     1] loss: 1.187\n",
      "[14,     1] loss: 1.182\n",
      "[15,     1] loss: 1.177\n",
      "[16,     1] loss: 1.172\n",
      "[17,     1] loss: 1.168\n",
      "[18,     1] loss: 1.163\n",
      "[19,     1] loss: 1.159\n",
      "[20,     1] loss: 1.154\n",
      "[21,     1] loss: 1.150\n",
      "[22,     1] loss: 1.146\n",
      "[23,     1] loss: 1.141\n",
      "[24,     1] loss: 1.137\n",
      "[25,     1] loss: 1.133\n",
      "[26,     1] loss: 1.129\n",
      "[27,     1] loss: 1.125\n",
      "[28,     1] loss: 1.120\n",
      "[29,     1] loss: 1.116\n",
      "[30,     1] loss: 1.112\n",
      "[31,     1] loss: 1.108\n",
      "[32,     1] loss: 1.104\n",
      "[33,     1] loss: 1.100\n",
      "[34,     1] loss: 1.096\n",
      "[35,     1] loss: 1.091\n",
      "[36,     1] loss: 1.087\n",
      "[37,     1] loss: 1.083\n",
      "[38,     1] loss: 1.079\n",
      "[39,     1] loss: 1.075\n",
      "[40,     1] loss: 1.071\n",
      "[41,     1] loss: 1.067\n",
      "[42,     1] loss: 1.063\n",
      "[43,     1] loss: 1.059\n",
      "[44,     1] loss: 1.055\n",
      "[45,     1] loss: 1.051\n",
      "[46,     1] loss: 1.047\n",
      "[47,     1] loss: 1.043\n",
      "[48,     1] loss: 1.040\n",
      "[49,     1] loss: 1.036\n",
      "[50,     1] loss: 1.032\n",
      "[51,     1] loss: 1.028\n",
      "[52,     1] loss: 1.024\n",
      "[53,     1] loss: 1.020\n",
      "[54,     1] loss: 1.016\n",
      "[55,     1] loss: 1.013\n",
      "[56,     1] loss: 1.009\n",
      "[57,     1] loss: 1.005\n",
      "[58,     1] loss: 1.001\n",
      "[59,     1] loss: 0.998\n",
      "[60,     1] loss: 0.994\n",
      "[61,     1] loss: 0.990\n",
      "[62,     1] loss: 0.987\n",
      "[63,     1] loss: 0.983\n",
      "[64,     1] loss: 0.979\n",
      "[65,     1] loss: 0.976\n",
      "[66,     1] loss: 0.972\n",
      "[67,     1] loss: 0.968\n",
      "[68,     1] loss: 0.965\n",
      "[69,     1] loss: 0.961\n",
      "[70,     1] loss: 0.958\n",
      "[71,     1] loss: 0.954\n",
      "[72,     1] loss: 0.951\n",
      "[73,     1] loss: 0.947\n",
      "[74,     1] loss: 0.944\n",
      "[75,     1] loss: 0.940\n",
      "[76,     1] loss: 0.937\n",
      "[77,     1] loss: 0.933\n",
      "[78,     1] loss: 0.930\n",
      "[79,     1] loss: 0.926\n",
      "[80,     1] loss: 0.923\n",
      "[81,     1] loss: 0.920\n",
      "[82,     1] loss: 0.916\n",
      "[83,     1] loss: 0.913\n",
      "[84,     1] loss: 0.909\n",
      "[85,     1] loss: 0.906\n",
      "[86,     1] loss: 0.903\n",
      "[87,     1] loss: 0.899\n",
      "[88,     1] loss: 0.896\n",
      "[89,     1] loss: 0.893\n",
      "[90,     1] loss: 0.890\n",
      "[91,     1] loss: 0.886\n",
      "[92,     1] loss: 0.883\n",
      "[93,     1] loss: 0.880\n",
      "[94,     1] loss: 0.877\n",
      "[95,     1] loss: 0.873\n",
      "[96,     1] loss: 0.870\n",
      "[97,     1] loss: 0.867\n",
      "[98,     1] loss: 0.864\n",
      "[99,     1] loss: 0.861\n",
      "[100,     1] loss: 0.858\n",
      "[101,     1] loss: 0.854\n",
      "[102,     1] loss: 0.851\n",
      "[103,     1] loss: 0.848\n",
      "[104,     1] loss: 0.845\n",
      "[105,     1] loss: 0.842\n",
      "[106,     1] loss: 0.839\n",
      "[107,     1] loss: 0.836\n",
      "[108,     1] loss: 0.833\n",
      "[109,     1] loss: 0.830\n",
      "[110,     1] loss: 0.827\n",
      "[111,     1] loss: 0.824\n",
      "[112,     1] loss: 0.821\n",
      "[113,     1] loss: 0.818\n",
      "[114,     1] loss: 0.815\n",
      "[115,     1] loss: 0.812\n",
      "[116,     1] loss: 0.809\n",
      "[117,     1] loss: 0.806\n",
      "[118,     1] loss: 0.803\n",
      "[119,     1] loss: 0.800\n",
      "[120,     1] loss: 0.798\n",
      "[121,     1] loss: 0.795\n",
      "[122,     1] loss: 0.792\n",
      "[123,     1] loss: 0.789\n",
      "[124,     1] loss: 0.786\n",
      "[125,     1] loss: 0.783\n",
      "[126,     1] loss: 0.781\n",
      "[127,     1] loss: 0.778\n",
      "[128,     1] loss: 0.775\n",
      "[129,     1] loss: 0.772\n",
      "[130,     1] loss: 0.769\n",
      "[131,     1] loss: 0.767\n",
      "[132,     1] loss: 0.764\n",
      "[133,     1] loss: 0.761\n",
      "[134,     1] loss: 0.758\n",
      "[135,     1] loss: 0.756\n",
      "[136,     1] loss: 0.753\n",
      "[137,     1] loss: 0.750\n",
      "[138,     1] loss: 0.748\n",
      "[139,     1] loss: 0.745\n",
      "[140,     1] loss: 0.742\n",
      "[141,     1] loss: 0.740\n",
      "[142,     1] loss: 0.737\n",
      "[143,     1] loss: 0.735\n",
      "[144,     1] loss: 0.732\n",
      "[145,     1] loss: 0.729\n",
      "[146,     1] loss: 0.727\n",
      "[147,     1] loss: 0.724\n",
      "[148,     1] loss: 0.722\n",
      "[149,     1] loss: 0.719\n",
      "[150,     1] loss: 0.717\n",
      "[151,     1] loss: 0.714\n",
      "[152,     1] loss: 0.712\n",
      "[153,     1] loss: 0.709\n",
      "[154,     1] loss: 0.707\n",
      "[155,     1] loss: 0.704\n",
      "[156,     1] loss: 0.702\n",
      "[157,     1] loss: 0.699\n",
      "[158,     1] loss: 0.697\n",
      "[159,     1] loss: 0.694\n",
      "[160,     1] loss: 0.692\n",
      "[161,     1] loss: 0.690\n",
      "[162,     1] loss: 0.687\n",
      "[163,     1] loss: 0.685\n",
      "[164,     1] loss: 0.682\n",
      "[165,     1] loss: 0.680\n",
      "[166,     1] loss: 0.678\n",
      "[167,     1] loss: 0.675\n",
      "[168,     1] loss: 0.673\n",
      "[169,     1] loss: 0.671\n",
      "[170,     1] loss: 0.668\n",
      "[171,     1] loss: 0.666\n",
      "[172,     1] loss: 0.664\n",
      "[173,     1] loss: 0.661\n",
      "[174,     1] loss: 0.659\n",
      "[175,     1] loss: 0.657\n",
      "[176,     1] loss: 0.655\n",
      "[177,     1] loss: 0.652\n",
      "[178,     1] loss: 0.650\n",
      "[179,     1] loss: 0.648\n",
      "[180,     1] loss: 0.646\n",
      "[181,     1] loss: 0.643\n",
      "[182,     1] loss: 0.641\n",
      "[183,     1] loss: 0.639\n",
      "[184,     1] loss: 0.637\n",
      "[185,     1] loss: 0.635\n",
      "[186,     1] loss: 0.633\n",
      "[187,     1] loss: 0.630\n",
      "[188,     1] loss: 0.628\n",
      "[189,     1] loss: 0.626\n",
      "[190,     1] loss: 0.624\n",
      "[191,     1] loss: 0.622\n",
      "[192,     1] loss: 0.620\n",
      "[193,     1] loss: 0.618\n",
      "[194,     1] loss: 0.616\n",
      "[195,     1] loss: 0.613\n",
      "[196,     1] loss: 0.611\n",
      "[197,     1] loss: 0.609\n",
      "[198,     1] loss: 0.607\n",
      "[199,     1] loss: 0.605\n",
      "[200,     1] loss: 0.603\n",
      "[201,     1] loss: 0.601\n",
      "[202,     1] loss: 0.599\n",
      "[203,     1] loss: 0.597\n",
      "[204,     1] loss: 0.595\n",
      "[205,     1] loss: 0.593\n",
      "[206,     1] loss: 0.591\n",
      "[207,     1] loss: 0.589\n",
      "[208,     1] loss: 0.587\n",
      "[209,     1] loss: 0.585\n",
      "[210,     1] loss: 0.583\n",
      "[211,     1] loss: 0.581\n",
      "[212,     1] loss: 0.580\n",
      "[213,     1] loss: 0.578\n",
      "[214,     1] loss: 0.576\n",
      "[215,     1] loss: 0.574\n",
      "[216,     1] loss: 0.572\n",
      "[217,     1] loss: 0.570\n",
      "[218,     1] loss: 0.568\n",
      "[219,     1] loss: 0.566\n",
      "[220,     1] loss: 0.564\n",
      "[221,     1] loss: 0.563\n",
      "[222,     1] loss: 0.561\n",
      "[223,     1] loss: 0.559\n",
      "[224,     1] loss: 0.557\n",
      "[225,     1] loss: 0.555\n",
      "[226,     1] loss: 0.553\n",
      "[227,     1] loss: 0.552\n",
      "[228,     1] loss: 0.550\n",
      "[229,     1] loss: 0.548\n",
      "[230,     1] loss: 0.546\n",
      "[231,     1] loss: 0.544\n",
      "[232,     1] loss: 0.543\n",
      "[233,     1] loss: 0.541\n",
      "[234,     1] loss: 0.539\n",
      "[235,     1] loss: 0.537\n",
      "[236,     1] loss: 0.536\n",
      "[237,     1] loss: 0.534\n",
      "[238,     1] loss: 0.532\n",
      "[239,     1] loss: 0.531\n",
      "[240,     1] loss: 0.529\n",
      "[241,     1] loss: 0.527\n",
      "[242,     1] loss: 0.526\n",
      "[243,     1] loss: 0.524\n",
      "[244,     1] loss: 0.522\n",
      "[245,     1] loss: 0.520\n",
      "[246,     1] loss: 0.519\n",
      "[247,     1] loss: 0.517\n",
      "[248,     1] loss: 0.516\n",
      "[249,     1] loss: 0.514\n",
      "[250,     1] loss: 0.512\n",
      "[251,     1] loss: 0.511\n",
      "[252,     1] loss: 0.509\n",
      "[253,     1] loss: 0.507\n",
      "[254,     1] loss: 0.506\n",
      "[255,     1] loss: 0.504\n",
      "[256,     1] loss: 0.503\n",
      "[257,     1] loss: 0.501\n",
      "[258,     1] loss: 0.499\n",
      "[259,     1] loss: 0.498\n",
      "[260,     1] loss: 0.496\n",
      "[261,     1] loss: 0.495\n",
      "[262,     1] loss: 0.493\n",
      "[263,     1] loss: 0.492\n",
      "[264,     1] loss: 0.490\n",
      "[265,     1] loss: 0.489\n",
      "[266,     1] loss: 0.487\n",
      "[267,     1] loss: 0.486\n",
      "[268,     1] loss: 0.484\n",
      "[269,     1] loss: 0.483\n",
      "[270,     1] loss: 0.481\n",
      "[271,     1] loss: 0.480\n",
      "[272,     1] loss: 0.478\n",
      "[273,     1] loss: 0.477\n",
      "[274,     1] loss: 0.475\n",
      "[275,     1] loss: 0.474\n",
      "[276,     1] loss: 0.472\n",
      "[277,     1] loss: 0.471\n",
      "[278,     1] loss: 0.469\n",
      "[279,     1] loss: 0.468\n",
      "[280,     1] loss: 0.467\n",
      "[281,     1] loss: 0.465\n",
      "[282,     1] loss: 0.464\n",
      "[283,     1] loss: 0.462\n",
      "[284,     1] loss: 0.461\n",
      "[285,     1] loss: 0.460\n",
      "[286,     1] loss: 0.458\n",
      "[287,     1] loss: 0.457\n",
      "[288,     1] loss: 0.455\n",
      "[289,     1] loss: 0.454\n",
      "[290,     1] loss: 0.453\n",
      "[291,     1] loss: 0.451\n",
      "[292,     1] loss: 0.450\n",
      "[293,     1] loss: 0.449\n",
      "[294,     1] loss: 0.447\n",
      "[295,     1] loss: 0.446\n",
      "[296,     1] loss: 0.445\n",
      "[297,     1] loss: 0.443\n",
      "[298,     1] loss: 0.442\n",
      "[299,     1] loss: 0.441\n",
      "[300,     1] loss: 0.439\n",
      "Finished Training\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Accuracy of the network on the test dataset 1: 53 %\n",
      "Accuracy of the network on the test dataset 2: 100 %\n",
      "Accuracy of the network on the test dataset 3: 100 %\n",
      "Accuracy of the network on the test dataset 4: 100 %\n",
      "Accuracy of the network on the test dataset 5: 100 %\n",
      "Accuracy of the network on the test dataset 6: 100 %\n",
      "Accuracy of the network on the test dataset 7: 100 %\n",
      "Accuracy of the network on the test dataset 8: 100 %\n",
      "Accuracy of the network on the test dataset 9: 100 %\n",
      "Accuracy of the network on the test dataset 10: 100 %\n",
      "Accuracy of the network on the test dataset 11: 100 %\n",
      "Accuracy of the network on the test dataset 12: 32 %\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "training on data set   3\n",
      "[1,     1] loss: 2.841\n",
      "[2,     1] loss: 1.410\n",
      "[3,     1] loss: 1.399\n",
      "[4,     1] loss: 1.389\n",
      "[5,     1] loss: 1.379\n",
      "[6,     1] loss: 1.368\n",
      "[7,     1] loss: 1.358\n",
      "[8,     1] loss: 1.348\n",
      "[9,     1] loss: 1.338\n",
      "[10,     1] loss: 1.329\n",
      "[11,     1] loss: 1.319\n",
      "[12,     1] loss: 1.309\n",
      "[13,     1] loss: 1.300\n",
      "[14,     1] loss: 1.290\n",
      "[15,     1] loss: 1.281\n",
      "[16,     1] loss: 1.272\n",
      "[17,     1] loss: 1.263\n",
      "[18,     1] loss: 1.254\n",
      "[19,     1] loss: 1.245\n",
      "[20,     1] loss: 1.236\n",
      "[21,     1] loss: 1.227\n",
      "[22,     1] loss: 1.218\n",
      "[23,     1] loss: 1.210\n",
      "[24,     1] loss: 1.201\n",
      "[25,     1] loss: 1.193\n",
      "[26,     1] loss: 1.184\n",
      "[27,     1] loss: 1.176\n",
      "[28,     1] loss: 1.167\n",
      "[29,     1] loss: 1.159\n",
      "[30,     1] loss: 1.151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31,     1] loss: 1.143\n",
      "[32,     1] loss: 1.134\n",
      "[33,     1] loss: 1.126\n",
      "[34,     1] loss: 1.118\n",
      "[35,     1] loss: 1.110\n",
      "[36,     1] loss: 1.102\n",
      "[37,     1] loss: 1.094\n",
      "[38,     1] loss: 1.086\n",
      "[39,     1] loss: 1.078\n",
      "[40,     1] loss: 1.071\n",
      "[41,     1] loss: 1.063\n",
      "[42,     1] loss: 1.055\n",
      "[43,     1] loss: 1.048\n",
      "[44,     1] loss: 1.040\n",
      "[45,     1] loss: 1.032\n",
      "[46,     1] loss: 1.025\n",
      "[47,     1] loss: 1.017\n",
      "[48,     1] loss: 1.010\n",
      "[49,     1] loss: 1.003\n",
      "[50,     1] loss: 0.995\n",
      "[51,     1] loss: 0.988\n",
      "[52,     1] loss: 0.981\n",
      "[53,     1] loss: 0.974\n",
      "[54,     1] loss: 0.967\n",
      "[55,     1] loss: 0.960\n",
      "[56,     1] loss: 0.953\n",
      "[57,     1] loss: 0.946\n",
      "[58,     1] loss: 0.939\n",
      "[59,     1] loss: 0.932\n",
      "[60,     1] loss: 0.925\n",
      "[61,     1] loss: 0.919\n",
      "[62,     1] loss: 0.912\n",
      "[63,     1] loss: 0.905\n",
      "[64,     1] loss: 0.899\n",
      "[65,     1] loss: 0.892\n",
      "[66,     1] loss: 0.886\n",
      "[67,     1] loss: 0.879\n",
      "[68,     1] loss: 0.873\n",
      "[69,     1] loss: 0.867\n",
      "[70,     1] loss: 0.860\n",
      "[71,     1] loss: 0.854\n",
      "[72,     1] loss: 0.848\n",
      "[73,     1] loss: 0.842\n",
      "[74,     1] loss: 0.836\n",
      "[75,     1] loss: 0.830\n",
      "[76,     1] loss: 0.824\n",
      "[77,     1] loss: 0.818\n",
      "[78,     1] loss: 0.812\n",
      "[79,     1] loss: 0.806\n",
      "[80,     1] loss: 0.800\n",
      "[81,     1] loss: 0.794\n",
      "[82,     1] loss: 0.789\n",
      "[83,     1] loss: 0.783\n",
      "[84,     1] loss: 0.778\n",
      "[85,     1] loss: 0.772\n",
      "[86,     1] loss: 0.766\n",
      "[87,     1] loss: 0.761\n",
      "[88,     1] loss: 0.756\n",
      "[89,     1] loss: 0.750\n",
      "[90,     1] loss: 0.745\n",
      "[91,     1] loss: 0.740\n",
      "[92,     1] loss: 0.734\n",
      "[93,     1] loss: 0.729\n",
      "[94,     1] loss: 0.724\n",
      "[95,     1] loss: 0.719\n",
      "[96,     1] loss: 0.714\n",
      "[97,     1] loss: 0.709\n",
      "[98,     1] loss: 0.704\n",
      "[99,     1] loss: 0.699\n",
      "[100,     1] loss: 0.694\n",
      "[101,     1] loss: 0.689\n",
      "[102,     1] loss: 0.684\n",
      "[103,     1] loss: 0.679\n",
      "[104,     1] loss: 0.675\n",
      "[105,     1] loss: 0.670\n",
      "[106,     1] loss: 0.665\n",
      "[107,     1] loss: 0.661\n",
      "[108,     1] loss: 0.656\n",
      "[109,     1] loss: 0.652\n",
      "[110,     1] loss: 0.647\n",
      "[111,     1] loss: 0.643\n",
      "[112,     1] loss: 0.638\n",
      "[113,     1] loss: 0.634\n",
      "[114,     1] loss: 0.630\n",
      "[115,     1] loss: 0.625\n",
      "[116,     1] loss: 0.621\n",
      "[117,     1] loss: 0.617\n",
      "[118,     1] loss: 0.613\n",
      "[119,     1] loss: 0.608\n",
      "[120,     1] loss: 0.604\n",
      "[121,     1] loss: 0.600\n",
      "[122,     1] loss: 0.596\n",
      "[123,     1] loss: 0.592\n",
      "[124,     1] loss: 0.588\n",
      "[125,     1] loss: 0.584\n",
      "[126,     1] loss: 0.580\n",
      "[127,     1] loss: 0.576\n",
      "[128,     1] loss: 0.573\n",
      "[129,     1] loss: 0.569\n",
      "[130,     1] loss: 0.565\n",
      "[131,     1] loss: 0.561\n",
      "[132,     1] loss: 0.558\n",
      "[133,     1] loss: 0.554\n",
      "[134,     1] loss: 0.550\n",
      "[135,     1] loss: 0.547\n",
      "[136,     1] loss: 0.543\n",
      "[137,     1] loss: 0.539\n",
      "[138,     1] loss: 0.536\n",
      "[139,     1] loss: 0.532\n",
      "[140,     1] loss: 0.529\n",
      "[141,     1] loss: 0.526\n",
      "[142,     1] loss: 0.522\n",
      "[143,     1] loss: 0.519\n",
      "[144,     1] loss: 0.515\n",
      "[145,     1] loss: 0.512\n",
      "[146,     1] loss: 0.509\n",
      "[147,     1] loss: 0.506\n",
      "[148,     1] loss: 0.502\n",
      "[149,     1] loss: 0.499\n",
      "[150,     1] loss: 0.496\n",
      "[151,     1] loss: 0.493\n",
      "[152,     1] loss: 0.490\n",
      "[153,     1] loss: 0.487\n",
      "[154,     1] loss: 0.484\n",
      "[155,     1] loss: 0.481\n",
      "[156,     1] loss: 0.478\n",
      "[157,     1] loss: 0.475\n",
      "[158,     1] loss: 0.472\n",
      "[159,     1] loss: 0.469\n",
      "[160,     1] loss: 0.466\n",
      "[161,     1] loss: 0.463\n",
      "[162,     1] loss: 0.460\n",
      "[163,     1] loss: 0.457\n",
      "[164,     1] loss: 0.454\n",
      "[165,     1] loss: 0.452\n",
      "[166,     1] loss: 0.449\n",
      "[167,     1] loss: 0.446\n",
      "[168,     1] loss: 0.444\n",
      "[169,     1] loss: 0.441\n",
      "[170,     1] loss: 0.438\n",
      "[171,     1] loss: 0.436\n",
      "[172,     1] loss: 0.433\n",
      "[173,     1] loss: 0.430\n",
      "[174,     1] loss: 0.428\n",
      "[175,     1] loss: 0.425\n",
      "[176,     1] loss: 0.423\n",
      "[177,     1] loss: 0.420\n",
      "[178,     1] loss: 0.418\n",
      "[179,     1] loss: 0.415\n",
      "[180,     1] loss: 0.413\n",
      "[181,     1] loss: 0.410\n",
      "[182,     1] loss: 0.408\n",
      "[183,     1] loss: 0.406\n",
      "[184,     1] loss: 0.403\n",
      "[185,     1] loss: 0.401\n",
      "[186,     1] loss: 0.398\n",
      "[187,     1] loss: 0.396\n",
      "[188,     1] loss: 0.394\n",
      "[189,     1] loss: 0.392\n",
      "[190,     1] loss: 0.389\n",
      "[191,     1] loss: 0.387\n",
      "[192,     1] loss: 0.385\n",
      "[193,     1] loss: 0.383\n",
      "[194,     1] loss: 0.381\n",
      "[195,     1] loss: 0.378\n",
      "[196,     1] loss: 0.376\n",
      "[197,     1] loss: 0.374\n",
      "[198,     1] loss: 0.372\n",
      "[199,     1] loss: 0.370\n",
      "[200,     1] loss: 0.368\n",
      "[201,     1] loss: 0.366\n",
      "[202,     1] loss: 0.364\n",
      "[203,     1] loss: 0.362\n",
      "[204,     1] loss: 0.360\n",
      "[205,     1] loss: 0.358\n",
      "[206,     1] loss: 0.356\n",
      "[207,     1] loss: 0.354\n",
      "[208,     1] loss: 0.352\n",
      "[209,     1] loss: 0.350\n",
      "[210,     1] loss: 0.348\n",
      "[211,     1] loss: 0.346\n",
      "[212,     1] loss: 0.344\n",
      "[213,     1] loss: 0.343\n",
      "[214,     1] loss: 0.341\n",
      "[215,     1] loss: 0.339\n",
      "[216,     1] loss: 0.337\n",
      "[217,     1] loss: 0.335\n",
      "[218,     1] loss: 0.333\n",
      "[219,     1] loss: 0.332\n",
      "[220,     1] loss: 0.330\n",
      "[221,     1] loss: 0.328\n",
      "[222,     1] loss: 0.326\n",
      "[223,     1] loss: 0.325\n",
      "[224,     1] loss: 0.323\n",
      "[225,     1] loss: 0.321\n",
      "[226,     1] loss: 0.320\n",
      "[227,     1] loss: 0.318\n",
      "[228,     1] loss: 0.316\n",
      "[229,     1] loss: 0.315\n",
      "[230,     1] loss: 0.313\n",
      "[231,     1] loss: 0.312\n",
      "[232,     1] loss: 0.310\n",
      "[233,     1] loss: 0.308\n",
      "[234,     1] loss: 0.307\n",
      "[235,     1] loss: 0.305\n",
      "[236,     1] loss: 0.304\n",
      "[237,     1] loss: 0.302\n",
      "[238,     1] loss: 0.301\n",
      "[239,     1] loss: 0.299\n",
      "[240,     1] loss: 0.298\n",
      "[241,     1] loss: 0.296\n",
      "[242,     1] loss: 0.295\n",
      "[243,     1] loss: 0.293\n",
      "[244,     1] loss: 0.292\n",
      "[245,     1] loss: 0.290\n",
      "[246,     1] loss: 0.289\n",
      "[247,     1] loss: 0.287\n",
      "[248,     1] loss: 0.286\n",
      "[249,     1] loss: 0.285\n",
      "[250,     1] loss: 0.283\n",
      "[251,     1] loss: 0.282\n",
      "[252,     1] loss: 0.280\n",
      "[253,     1] loss: 0.279\n",
      "[254,     1] loss: 0.278\n",
      "[255,     1] loss: 0.276\n",
      "[256,     1] loss: 0.275\n",
      "[257,     1] loss: 0.274\n",
      "[258,     1] loss: 0.272\n",
      "[259,     1] loss: 0.271\n",
      "[260,     1] loss: 0.270\n",
      "[261,     1] loss: 0.269\n",
      "[262,     1] loss: 0.267\n",
      "[263,     1] loss: 0.266\n",
      "[264,     1] loss: 0.265\n",
      "[265,     1] loss: 0.264\n",
      "[266,     1] loss: 0.262\n",
      "[267,     1] loss: 0.261\n",
      "[268,     1] loss: 0.260\n",
      "[269,     1] loss: 0.259\n",
      "[270,     1] loss: 0.257\n",
      "[271,     1] loss: 0.256\n",
      "[272,     1] loss: 0.255\n",
      "[273,     1] loss: 0.254\n",
      "[274,     1] loss: 0.253\n",
      "[275,     1] loss: 0.252\n",
      "[276,     1] loss: 0.250\n",
      "[277,     1] loss: 0.249\n",
      "[278,     1] loss: 0.248\n",
      "[279,     1] loss: 0.247\n",
      "[280,     1] loss: 0.246\n",
      "[281,     1] loss: 0.245\n",
      "[282,     1] loss: 0.244\n",
      "[283,     1] loss: 0.243\n",
      "[284,     1] loss: 0.242\n",
      "[285,     1] loss: 0.240\n",
      "[286,     1] loss: 0.239\n",
      "[287,     1] loss: 0.238\n",
      "[288,     1] loss: 0.237\n",
      "[289,     1] loss: 0.236\n",
      "[290,     1] loss: 0.235\n",
      "[291,     1] loss: 0.234\n",
      "[292,     1] loss: 0.233\n",
      "[293,     1] loss: 0.232\n",
      "[294,     1] loss: 0.231\n",
      "[295,     1] loss: 0.230\n",
      "[296,     1] loss: 0.229\n",
      "[297,     1] loss: 0.228\n",
      "[298,     1] loss: 0.227\n",
      "[299,     1] loss: 0.226\n",
      "[300,     1] loss: 0.225\n",
      "Finished Training\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Accuracy of the network on the test dataset 1: 48 %\n",
      "Accuracy of the network on the test dataset 2: 98 %\n",
      "Accuracy of the network on the test dataset 3: 100 %\n",
      "Accuracy of the network on the test dataset 4: 100 %\n",
      "Accuracy of the network on the test dataset 5: 100 %\n",
      "Accuracy of the network on the test dataset 6: 100 %\n",
      "Accuracy of the network on the test dataset 7: 100 %\n",
      "Accuracy of the network on the test dataset 8: 100 %\n",
      "Accuracy of the network on the test dataset 9: 100 %\n",
      "Accuracy of the network on the test dataset 10: 100 %\n",
      "Accuracy of the network on the test dataset 11: 100 %\n",
      "Accuracy of the network on the test dataset 12: 32 %\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "training on data set   4\n",
      "[1,     1] loss: 3.213\n",
      "[2,     1] loss: 1.591\n",
      "[3,     1] loss: 1.575\n",
      "[4,     1] loss: 1.559\n",
      "[5,     1] loss: 1.544\n",
      "[6,     1] loss: 1.529\n",
      "[7,     1] loss: 1.513\n",
      "[8,     1] loss: 1.498\n",
      "[9,     1] loss: 1.483\n",
      "[10,     1] loss: 1.468\n",
      "[11,     1] loss: 1.454\n",
      "[12,     1] loss: 1.439\n",
      "[13,     1] loss: 1.425\n",
      "[14,     1] loss: 1.410\n",
      "[15,     1] loss: 1.396\n",
      "[16,     1] loss: 1.382\n",
      "[17,     1] loss: 1.368\n",
      "[18,     1] loss: 1.354\n",
      "[19,     1] loss: 1.341\n",
      "[20,     1] loss: 1.327\n",
      "[21,     1] loss: 1.314\n",
      "[22,     1] loss: 1.300\n",
      "[23,     1] loss: 1.287\n",
      "[24,     1] loss: 1.274\n",
      "[25,     1] loss: 1.261\n",
      "[26,     1] loss: 1.248\n",
      "[27,     1] loss: 1.235\n",
      "[28,     1] loss: 1.222\n",
      "[29,     1] loss: 1.210\n",
      "[30,     1] loss: 1.197\n",
      "[31,     1] loss: 1.185\n",
      "[32,     1] loss: 1.173\n",
      "[33,     1] loss: 1.160\n",
      "[34,     1] loss: 1.148\n",
      "[35,     1] loss: 1.136\n",
      "[36,     1] loss: 1.124\n",
      "[37,     1] loss: 1.112\n",
      "[38,     1] loss: 1.101\n",
      "[39,     1] loss: 1.089\n",
      "[40,     1] loss: 1.078\n",
      "[41,     1] loss: 1.066\n",
      "[42,     1] loss: 1.055\n",
      "[43,     1] loss: 1.044\n",
      "[44,     1] loss: 1.033\n",
      "[45,     1] loss: 1.022\n",
      "[46,     1] loss: 1.011\n",
      "[47,     1] loss: 1.000\n",
      "[48,     1] loss: 0.989\n",
      "[49,     1] loss: 0.979\n",
      "[50,     1] loss: 0.968\n",
      "[51,     1] loss: 0.958\n",
      "[52,     1] loss: 0.948\n",
      "[53,     1] loss: 0.938\n",
      "[54,     1] loss: 0.928\n",
      "[55,     1] loss: 0.918\n",
      "[56,     1] loss: 0.908\n",
      "[57,     1] loss: 0.898\n",
      "[58,     1] loss: 0.889\n",
      "[59,     1] loss: 0.879\n",
      "[60,     1] loss: 0.870\n",
      "[61,     1] loss: 0.861\n",
      "[62,     1] loss: 0.852\n",
      "[63,     1] loss: 0.842\n",
      "[64,     1] loss: 0.834\n",
      "[65,     1] loss: 0.825\n",
      "[66,     1] loss: 0.816\n",
      "[67,     1] loss: 0.807\n",
      "[68,     1] loss: 0.799\n",
      "[69,     1] loss: 0.790\n",
      "[70,     1] loss: 0.782\n",
      "[71,     1] loss: 0.774\n",
      "[72,     1] loss: 0.766\n",
      "[73,     1] loss: 0.758\n",
      "[74,     1] loss: 0.750\n",
      "[75,     1] loss: 0.742\n",
      "[76,     1] loss: 0.734\n",
      "[77,     1] loss: 0.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78,     1] loss: 0.719\n",
      "[79,     1] loss: 0.711\n",
      "[80,     1] loss: 0.704\n",
      "[81,     1] loss: 0.697\n",
      "[82,     1] loss: 0.689\n",
      "[83,     1] loss: 0.682\n",
      "[84,     1] loss: 0.675\n",
      "[85,     1] loss: 0.668\n",
      "[86,     1] loss: 0.661\n",
      "[87,     1] loss: 0.655\n",
      "[88,     1] loss: 0.648\n",
      "[89,     1] loss: 0.641\n",
      "[90,     1] loss: 0.635\n",
      "[91,     1] loss: 0.628\n",
      "[92,     1] loss: 0.622\n",
      "[93,     1] loss: 0.616\n",
      "[94,     1] loss: 0.610\n",
      "[95,     1] loss: 0.604\n",
      "[96,     1] loss: 0.598\n",
      "[97,     1] loss: 0.592\n",
      "[98,     1] loss: 0.586\n",
      "[99,     1] loss: 0.580\n",
      "[100,     1] loss: 0.574\n",
      "[101,     1] loss: 0.569\n",
      "[102,     1] loss: 0.563\n",
      "[103,     1] loss: 0.557\n",
      "[104,     1] loss: 0.552\n",
      "[105,     1] loss: 0.547\n",
      "[106,     1] loss: 0.541\n",
      "[107,     1] loss: 0.536\n",
      "[108,     1] loss: 0.531\n",
      "[109,     1] loss: 0.526\n",
      "[110,     1] loss: 0.521\n",
      "[111,     1] loss: 0.516\n",
      "[112,     1] loss: 0.511\n",
      "[113,     1] loss: 0.506\n",
      "[114,     1] loss: 0.501\n",
      "[115,     1] loss: 0.497\n",
      "[116,     1] loss: 0.492\n",
      "[117,     1] loss: 0.488\n",
      "[118,     1] loss: 0.483\n",
      "[119,     1] loss: 0.479\n",
      "[120,     1] loss: 0.474\n",
      "[121,     1] loss: 0.470\n",
      "[122,     1] loss: 0.465\n",
      "[123,     1] loss: 0.461\n",
      "[124,     1] loss: 0.457\n",
      "[125,     1] loss: 0.453\n",
      "[126,     1] loss: 0.449\n",
      "[127,     1] loss: 0.445\n",
      "[128,     1] loss: 0.441\n",
      "[129,     1] loss: 0.437\n",
      "[130,     1] loss: 0.433\n",
      "[131,     1] loss: 0.429\n",
      "[132,     1] loss: 0.425\n",
      "[133,     1] loss: 0.422\n",
      "[134,     1] loss: 0.418\n",
      "[135,     1] loss: 0.414\n",
      "[136,     1] loss: 0.411\n",
      "[137,     1] loss: 0.407\n",
      "[138,     1] loss: 0.404\n",
      "[139,     1] loss: 0.400\n",
      "[140,     1] loss: 0.397\n",
      "[141,     1] loss: 0.393\n",
      "[142,     1] loss: 0.390\n",
      "[143,     1] loss: 0.387\n",
      "[144,     1] loss: 0.384\n",
      "[145,     1] loss: 0.380\n",
      "[146,     1] loss: 0.377\n",
      "[147,     1] loss: 0.374\n",
      "[148,     1] loss: 0.371\n",
      "[149,     1] loss: 0.368\n",
      "[150,     1] loss: 0.365\n",
      "[151,     1] loss: 0.362\n",
      "[152,     1] loss: 0.359\n",
      "[153,     1] loss: 0.356\n",
      "[154,     1] loss: 0.353\n",
      "[155,     1] loss: 0.350\n",
      "[156,     1] loss: 0.347\n",
      "[157,     1] loss: 0.345\n",
      "[158,     1] loss: 0.342\n",
      "[159,     1] loss: 0.339\n",
      "[160,     1] loss: 0.337\n",
      "[161,     1] loss: 0.334\n",
      "[162,     1] loss: 0.331\n",
      "[163,     1] loss: 0.329\n",
      "[164,     1] loss: 0.326\n",
      "[165,     1] loss: 0.324\n",
      "[166,     1] loss: 0.321\n",
      "[167,     1] loss: 0.319\n",
      "[168,     1] loss: 0.316\n",
      "[169,     1] loss: 0.314\n",
      "[170,     1] loss: 0.312\n",
      "[171,     1] loss: 0.309\n",
      "[172,     1] loss: 0.307\n",
      "[173,     1] loss: 0.305\n",
      "[174,     1] loss: 0.302\n",
      "[175,     1] loss: 0.300\n",
      "[176,     1] loss: 0.298\n",
      "[177,     1] loss: 0.296\n",
      "[178,     1] loss: 0.293\n",
      "[179,     1] loss: 0.291\n",
      "[180,     1] loss: 0.289\n",
      "[181,     1] loss: 0.287\n",
      "[182,     1] loss: 0.285\n",
      "[183,     1] loss: 0.283\n",
      "[184,     1] loss: 0.281\n",
      "[185,     1] loss: 0.279\n",
      "[186,     1] loss: 0.277\n",
      "[187,     1] loss: 0.275\n",
      "[188,     1] loss: 0.273\n",
      "[189,     1] loss: 0.271\n",
      "[190,     1] loss: 0.269\n",
      "[191,     1] loss: 0.267\n",
      "[192,     1] loss: 0.266\n",
      "[193,     1] loss: 0.264\n",
      "[194,     1] loss: 0.262\n",
      "[195,     1] loss: 0.260\n",
      "[196,     1] loss: 0.258\n",
      "[197,     1] loss: 0.257\n",
      "[198,     1] loss: 0.255\n",
      "[199,     1] loss: 0.253\n",
      "[200,     1] loss: 0.251\n",
      "[201,     1] loss: 0.250\n",
      "[202,     1] loss: 0.248\n",
      "[203,     1] loss: 0.246\n",
      "[204,     1] loss: 0.245\n",
      "[205,     1] loss: 0.243\n",
      "[206,     1] loss: 0.242\n",
      "[207,     1] loss: 0.240\n",
      "[208,     1] loss: 0.238\n",
      "[209,     1] loss: 0.237\n",
      "[210,     1] loss: 0.235\n",
      "[211,     1] loss: 0.234\n",
      "[212,     1] loss: 0.232\n",
      "[213,     1] loss: 0.231\n",
      "[214,     1] loss: 0.229\n",
      "[215,     1] loss: 0.228\n",
      "[216,     1] loss: 0.227\n",
      "[217,     1] loss: 0.225\n",
      "[218,     1] loss: 0.224\n",
      "[219,     1] loss: 0.222\n",
      "[220,     1] loss: 0.221\n",
      "[221,     1] loss: 0.220\n",
      "[222,     1] loss: 0.218\n",
      "[223,     1] loss: 0.217\n",
      "[224,     1] loss: 0.216\n",
      "[225,     1] loss: 0.214\n",
      "[226,     1] loss: 0.213\n",
      "[227,     1] loss: 0.212\n",
      "[228,     1] loss: 0.210\n",
      "[229,     1] loss: 0.209\n",
      "[230,     1] loss: 0.208\n",
      "[231,     1] loss: 0.207\n",
      "[232,     1] loss: 0.205\n",
      "[233,     1] loss: 0.204\n",
      "[234,     1] loss: 0.203\n",
      "[235,     1] loss: 0.202\n",
      "[236,     1] loss: 0.201\n",
      "[237,     1] loss: 0.199\n",
      "[238,     1] loss: 0.198\n",
      "[239,     1] loss: 0.197\n",
      "[240,     1] loss: 0.196\n",
      "[241,     1] loss: 0.195\n",
      "[242,     1] loss: 0.194\n",
      "[243,     1] loss: 0.193\n",
      "[244,     1] loss: 0.191\n",
      "[245,     1] loss: 0.190\n",
      "[246,     1] loss: 0.189\n",
      "[247,     1] loss: 0.188\n",
      "[248,     1] loss: 0.187\n",
      "[249,     1] loss: 0.186\n",
      "[250,     1] loss: 0.185\n",
      "[251,     1] loss: 0.184\n",
      "[252,     1] loss: 0.183\n",
      "[253,     1] loss: 0.182\n",
      "[254,     1] loss: 0.181\n",
      "[255,     1] loss: 0.180\n",
      "[256,     1] loss: 0.179\n",
      "[257,     1] loss: 0.178\n",
      "[258,     1] loss: 0.177\n",
      "[259,     1] loss: 0.176\n",
      "[260,     1] loss: 0.175\n",
      "[261,     1] loss: 0.174\n",
      "[262,     1] loss: 0.173\n",
      "[263,     1] loss: 0.172\n",
      "[264,     1] loss: 0.171\n",
      "[265,     1] loss: 0.171\n",
      "[266,     1] loss: 0.170\n",
      "[267,     1] loss: 0.169\n",
      "[268,     1] loss: 0.168\n",
      "[269,     1] loss: 0.167\n",
      "[270,     1] loss: 0.166\n",
      "[271,     1] loss: 0.165\n",
      "[272,     1] loss: 0.164\n",
      "[273,     1] loss: 0.164\n",
      "[274,     1] loss: 0.163\n",
      "[275,     1] loss: 0.162\n",
      "[276,     1] loss: 0.161\n",
      "[277,     1] loss: 0.160\n",
      "[278,     1] loss: 0.159\n",
      "[279,     1] loss: 0.159\n",
      "[280,     1] loss: 0.158\n",
      "[281,     1] loss: 0.157\n",
      "[282,     1] loss: 0.156\n",
      "[283,     1] loss: 0.155\n",
      "[284,     1] loss: 0.155\n",
      "[285,     1] loss: 0.154\n",
      "[286,     1] loss: 0.153\n",
      "[287,     1] loss: 0.152\n",
      "[288,     1] loss: 0.152\n",
      "[289,     1] loss: 0.151\n",
      "[290,     1] loss: 0.150\n",
      "[291,     1] loss: 0.149\n",
      "[292,     1] loss: 0.149\n",
      "[293,     1] loss: 0.148\n",
      "[294,     1] loss: 0.147\n",
      "[295,     1] loss: 0.147\n",
      "[296,     1] loss: 0.146\n",
      "[297,     1] loss: 0.145\n",
      "[298,     1] loss: 0.144\n",
      "[299,     1] loss: 0.144\n",
      "[300,     1] loss: 0.143\n",
      "Finished Training\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Accuracy of the network on the test dataset 1: 48 %\n",
      "Accuracy of the network on the test dataset 2: 98 %\n",
      "Accuracy of the network on the test dataset 3: 100 %\n",
      "Accuracy of the network on the test dataset 4: 100 %\n",
      "Accuracy of the network on the test dataset 5: 100 %\n",
      "Accuracy of the network on the test dataset 6: 100 %\n",
      "Accuracy of the network on the test dataset 7: 100 %\n",
      "Accuracy of the network on the test dataset 8: 100 %\n",
      "Accuracy of the network on the test dataset 9: 100 %\n",
      "Accuracy of the network on the test dataset 10: 100 %\n",
      "Accuracy of the network on the test dataset 11: 100 %\n",
      "Accuracy of the network on the test dataset 12: 43 %\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "training on data set   5\n",
      "[1,     1] loss: 3.614\n",
      "[2,     1] loss: 1.785\n",
      "[3,     1] loss: 1.764\n",
      "[4,     1] loss: 1.743\n",
      "[5,     1] loss: 1.722\n",
      "[6,     1] loss: 1.701\n",
      "[7,     1] loss: 1.680\n",
      "[8,     1] loss: 1.660\n",
      "[9,     1] loss: 1.640\n",
      "[10,     1] loss: 1.620\n",
      "[11,     1] loss: 1.600\n",
      "[12,     1] loss: 1.580\n",
      "[13,     1] loss: 1.560\n",
      "[14,     1] loss: 1.541\n",
      "[15,     1] loss: 1.521\n",
      "[16,     1] loss: 1.502\n",
      "[17,     1] loss: 1.483\n",
      "[18,     1] loss: 1.464\n",
      "[19,     1] loss: 1.446\n",
      "[20,     1] loss: 1.427\n",
      "[21,     1] loss: 1.409\n",
      "[22,     1] loss: 1.391\n",
      "[23,     1] loss: 1.373\n",
      "[24,     1] loss: 1.355\n",
      "[25,     1] loss: 1.337\n",
      "[26,     1] loss: 1.320\n",
      "[27,     1] loss: 1.302\n",
      "[28,     1] loss: 1.285\n",
      "[29,     1] loss: 1.268\n",
      "[30,     1] loss: 1.251\n",
      "[31,     1] loss: 1.234\n",
      "[32,     1] loss: 1.218\n",
      "[33,     1] loss: 1.202\n",
      "[34,     1] loss: 1.185\n",
      "[35,     1] loss: 1.169\n",
      "[36,     1] loss: 1.153\n",
      "[37,     1] loss: 1.138\n",
      "[38,     1] loss: 1.122\n",
      "[39,     1] loss: 1.107\n",
      "[40,     1] loss: 1.092\n",
      "[41,     1] loss: 1.077\n",
      "[42,     1] loss: 1.062\n",
      "[43,     1] loss: 1.047\n",
      "[44,     1] loss: 1.033\n",
      "[45,     1] loss: 1.018\n",
      "[46,     1] loss: 1.004\n",
      "[47,     1] loss: 0.990\n",
      "[48,     1] loss: 0.977\n",
      "[49,     1] loss: 0.963\n",
      "[50,     1] loss: 0.950\n",
      "[51,     1] loss: 0.937\n",
      "[52,     1] loss: 0.923\n",
      "[53,     1] loss: 0.911\n",
      "[54,     1] loss: 0.898\n",
      "[55,     1] loss: 0.886\n",
      "[56,     1] loss: 0.873\n",
      "[57,     1] loss: 0.861\n",
      "[58,     1] loss: 0.849\n",
      "[59,     1] loss: 0.837\n",
      "[60,     1] loss: 0.826\n",
      "[61,     1] loss: 0.814\n",
      "[62,     1] loss: 0.803\n",
      "[63,     1] loss: 0.792\n",
      "[64,     1] loss: 0.781\n",
      "[65,     1] loss: 0.770\n",
      "[66,     1] loss: 0.760\n",
      "[67,     1] loss: 0.749\n",
      "[68,     1] loss: 0.739\n",
      "[69,     1] loss: 0.729\n",
      "[70,     1] loss: 0.719\n",
      "[71,     1] loss: 0.709\n",
      "[72,     1] loss: 0.699\n",
      "[73,     1] loss: 0.690\n",
      "[74,     1] loss: 0.681\n",
      "[75,     1] loss: 0.671\n",
      "[76,     1] loss: 0.662\n",
      "[77,     1] loss: 0.654\n",
      "[78,     1] loss: 0.645\n",
      "[79,     1] loss: 0.636\n",
      "[80,     1] loss: 0.628\n",
      "[81,     1] loss: 0.619\n",
      "[82,     1] loss: 0.611\n",
      "[83,     1] loss: 0.603\n",
      "[84,     1] loss: 0.595\n",
      "[85,     1] loss: 0.588\n",
      "[86,     1] loss: 0.580\n",
      "[87,     1] loss: 0.572\n",
      "[88,     1] loss: 0.565\n",
      "[89,     1] loss: 0.558\n",
      "[90,     1] loss: 0.551\n",
      "[91,     1] loss: 0.544\n",
      "[92,     1] loss: 0.537\n",
      "[93,     1] loss: 0.530\n",
      "[94,     1] loss: 0.523\n",
      "[95,     1] loss: 0.517\n",
      "[96,     1] loss: 0.510\n",
      "[97,     1] loss: 0.504\n",
      "[98,     1] loss: 0.498\n",
      "[99,     1] loss: 0.492\n",
      "[100,     1] loss: 0.486\n",
      "[101,     1] loss: 0.480\n",
      "[102,     1] loss: 0.474\n",
      "[103,     1] loss: 0.468\n",
      "[104,     1] loss: 0.463\n",
      "[105,     1] loss: 0.457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106,     1] loss: 0.452\n",
      "[107,     1] loss: 0.446\n",
      "[108,     1] loss: 0.441\n",
      "[109,     1] loss: 0.436\n",
      "[110,     1] loss: 0.431\n",
      "[111,     1] loss: 0.426\n",
      "[112,     1] loss: 0.421\n",
      "[113,     1] loss: 0.416\n",
      "[114,     1] loss: 0.411\n",
      "[115,     1] loss: 0.407\n",
      "[116,     1] loss: 0.402\n",
      "[117,     1] loss: 0.398\n",
      "[118,     1] loss: 0.393\n",
      "[119,     1] loss: 0.389\n",
      "[120,     1] loss: 0.385\n",
      "[121,     1] loss: 0.380\n",
      "[122,     1] loss: 0.376\n",
      "[123,     1] loss: 0.372\n",
      "[124,     1] loss: 0.368\n",
      "[125,     1] loss: 0.364\n",
      "[126,     1] loss: 0.360\n",
      "[127,     1] loss: 0.356\n",
      "[128,     1] loss: 0.353\n",
      "[129,     1] loss: 0.349\n",
      "[130,     1] loss: 0.345\n",
      "[131,     1] loss: 0.342\n",
      "[132,     1] loss: 0.338\n",
      "[133,     1] loss: 0.335\n",
      "[134,     1] loss: 0.331\n",
      "[135,     1] loss: 0.328\n",
      "[136,     1] loss: 0.325\n",
      "[137,     1] loss: 0.321\n",
      "[138,     1] loss: 0.318\n",
      "[139,     1] loss: 0.315\n",
      "[140,     1] loss: 0.312\n",
      "[141,     1] loss: 0.309\n",
      "[142,     1] loss: 0.306\n",
      "[143,     1] loss: 0.303\n",
      "[144,     1] loss: 0.300\n",
      "[145,     1] loss: 0.297\n",
      "[146,     1] loss: 0.294\n",
      "[147,     1] loss: 0.291\n",
      "[148,     1] loss: 0.289\n",
      "[149,     1] loss: 0.286\n",
      "[150,     1] loss: 0.283\n",
      "[151,     1] loss: 0.281\n",
      "[152,     1] loss: 0.278\n",
      "[153,     1] loss: 0.275\n",
      "[154,     1] loss: 0.273\n",
      "[155,     1] loss: 0.270\n",
      "[156,     1] loss: 0.268\n",
      "[157,     1] loss: 0.265\n",
      "[158,     1] loss: 0.263\n",
      "[159,     1] loss: 0.261\n",
      "[160,     1] loss: 0.258\n",
      "[161,     1] loss: 0.256\n",
      "[162,     1] loss: 0.254\n",
      "[163,     1] loss: 0.252\n",
      "[164,     1] loss: 0.249\n",
      "[165,     1] loss: 0.247\n",
      "[166,     1] loss: 0.245\n",
      "[167,     1] loss: 0.243\n",
      "[168,     1] loss: 0.241\n",
      "[169,     1] loss: 0.239\n",
      "[170,     1] loss: 0.237\n",
      "[171,     1] loss: 0.235\n",
      "[172,     1] loss: 0.233\n",
      "[173,     1] loss: 0.231\n",
      "[174,     1] loss: 0.229\n",
      "[175,     1] loss: 0.227\n",
      "[176,     1] loss: 0.225\n",
      "[177,     1] loss: 0.224\n",
      "[178,     1] loss: 0.222\n",
      "[179,     1] loss: 0.220\n",
      "[180,     1] loss: 0.218\n",
      "[181,     1] loss: 0.216\n",
      "[182,     1] loss: 0.215\n",
      "[183,     1] loss: 0.213\n",
      "[184,     1] loss: 0.211\n",
      "[185,     1] loss: 0.210\n",
      "[186,     1] loss: 0.208\n",
      "[187,     1] loss: 0.206\n",
      "[188,     1] loss: 0.205\n",
      "[189,     1] loss: 0.203\n",
      "[190,     1] loss: 0.202\n",
      "[191,     1] loss: 0.200\n",
      "[192,     1] loss: 0.199\n",
      "[193,     1] loss: 0.197\n",
      "[194,     1] loss: 0.196\n",
      "[195,     1] loss: 0.194\n",
      "[196,     1] loss: 0.193\n",
      "[197,     1] loss: 0.191\n",
      "[198,     1] loss: 0.190\n",
      "[199,     1] loss: 0.189\n",
      "[200,     1] loss: 0.187\n",
      "[201,     1] loss: 0.186\n",
      "[202,     1] loss: 0.185\n",
      "[203,     1] loss: 0.183\n",
      "[204,     1] loss: 0.182\n",
      "[205,     1] loss: 0.181\n",
      "[206,     1] loss: 0.179\n",
      "[207,     1] loss: 0.178\n",
      "[208,     1] loss: 0.177\n",
      "[209,     1] loss: 0.176\n",
      "[210,     1] loss: 0.174\n",
      "[211,     1] loss: 0.173\n",
      "[212,     1] loss: 0.172\n",
      "[213,     1] loss: 0.171\n",
      "[214,     1] loss: 0.170\n",
      "[215,     1] loss: 0.168\n",
      "[216,     1] loss: 0.167\n",
      "[217,     1] loss: 0.166\n",
      "[218,     1] loss: 0.165\n",
      "[219,     1] loss: 0.164\n",
      "[220,     1] loss: 0.163\n",
      "[221,     1] loss: 0.162\n",
      "[222,     1] loss: 0.161\n",
      "[223,     1] loss: 0.160\n",
      "[224,     1] loss: 0.159\n",
      "[225,     1] loss: 0.158\n",
      "[226,     1] loss: 0.157\n",
      "[227,     1] loss: 0.156\n",
      "[228,     1] loss: 0.155\n",
      "[229,     1] loss: 0.154\n",
      "[230,     1] loss: 0.153\n",
      "[231,     1] loss: 0.152\n",
      "[232,     1] loss: 0.151\n",
      "[233,     1] loss: 0.150\n",
      "[234,     1] loss: 0.149\n",
      "[235,     1] loss: 0.148\n",
      "[236,     1] loss: 0.147\n",
      "[237,     1] loss: 0.146\n",
      "[238,     1] loss: 0.145\n",
      "[239,     1] loss: 0.144\n",
      "[240,     1] loss: 0.143\n",
      "[241,     1] loss: 0.142\n",
      "[242,     1] loss: 0.142\n",
      "[243,     1] loss: 0.141\n",
      "[244,     1] loss: 0.140\n",
      "[245,     1] loss: 0.139\n",
      "[246,     1] loss: 0.138\n",
      "[247,     1] loss: 0.137\n",
      "[248,     1] loss: 0.137\n",
      "[249,     1] loss: 0.136\n",
      "[250,     1] loss: 0.135\n",
      "[251,     1] loss: 0.134\n",
      "[252,     1] loss: 0.133\n",
      "[253,     1] loss: 0.133\n",
      "[254,     1] loss: 0.132\n",
      "[255,     1] loss: 0.131\n",
      "[256,     1] loss: 0.130\n",
      "[257,     1] loss: 0.130\n",
      "[258,     1] loss: 0.129\n",
      "[259,     1] loss: 0.128\n",
      "[260,     1] loss: 0.127\n",
      "[261,     1] loss: 0.127\n",
      "[262,     1] loss: 0.126\n",
      "[263,     1] loss: 0.125\n",
      "[264,     1] loss: 0.125\n",
      "[265,     1] loss: 0.124\n",
      "[266,     1] loss: 0.123\n",
      "[267,     1] loss: 0.122\n",
      "[268,     1] loss: 0.122\n",
      "[269,     1] loss: 0.121\n",
      "[270,     1] loss: 0.120\n",
      "[271,     1] loss: 0.120\n",
      "[272,     1] loss: 0.119\n",
      "[273,     1] loss: 0.118\n",
      "[274,     1] loss: 0.118\n",
      "[275,     1] loss: 0.117\n",
      "[276,     1] loss: 0.117\n",
      "[277,     1] loss: 0.116\n",
      "[278,     1] loss: 0.115\n",
      "[279,     1] loss: 0.115\n",
      "[280,     1] loss: 0.114\n",
      "[281,     1] loss: 0.114\n",
      "[282,     1] loss: 0.113\n",
      "[283,     1] loss: 0.112\n",
      "[284,     1] loss: 0.112\n",
      "[285,     1] loss: 0.111\n",
      "[286,     1] loss: 0.111\n",
      "[287,     1] loss: 0.110\n",
      "[288,     1] loss: 0.109\n",
      "[289,     1] loss: 0.109\n",
      "[290,     1] loss: 0.108\n",
      "[291,     1] loss: 0.108\n",
      "[292,     1] loss: 0.107\n",
      "[293,     1] loss: 0.107\n",
      "[294,     1] loss: 0.106\n",
      "[295,     1] loss: 0.106\n",
      "[296,     1] loss: 0.105\n",
      "[297,     1] loss: 0.105\n",
      "[298,     1] loss: 0.104\n",
      "[299,     1] loss: 0.104\n",
      "[300,     1] loss: 0.103\n",
      "Finished Training\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Accuracy of the network on the test dataset 1: 37 %\n",
      "Accuracy of the network on the test dataset 2: 96 %\n",
      "Accuracy of the network on the test dataset 3: 100 %\n",
      "Accuracy of the network on the test dataset 4: 100 %\n",
      "Accuracy of the network on the test dataset 5: 100 %\n",
      "Accuracy of the network on the test dataset 6: 100 %\n",
      "Accuracy of the network on the test dataset 7: 100 %\n",
      "Accuracy of the network on the test dataset 8: 100 %\n",
      "Accuracy of the network on the test dataset 9: 100 %\n",
      "Accuracy of the network on the test dataset 10: 100 %\n",
      "Accuracy of the network on the test dataset 11: 100 %\n",
      "Accuracy of the network on the test dataset 12: 67 %\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "training on data set   6\n",
      "[1,     1] loss: 4.038\n",
      "[2,     1] loss: 1.992\n",
      "[3,     1] loss: 1.965\n",
      "[4,     1] loss: 1.938\n",
      "[5,     1] loss: 1.911\n",
      "[6,     1] loss: 1.885\n",
      "[7,     1] loss: 1.859\n",
      "[8,     1] loss: 1.833\n",
      "[9,     1] loss: 1.807\n",
      "[10,     1] loss: 1.781\n",
      "[11,     1] loss: 1.756\n",
      "[12,     1] loss: 1.730\n",
      "[13,     1] loss: 1.705\n",
      "[14,     1] loss: 1.681\n",
      "[15,     1] loss: 1.656\n",
      "[16,     1] loss: 1.632\n",
      "[17,     1] loss: 1.607\n",
      "[18,     1] loss: 1.583\n",
      "[19,     1] loss: 1.560\n",
      "[20,     1] loss: 1.536\n",
      "[21,     1] loss: 1.513\n",
      "[22,     1] loss: 1.489\n",
      "[23,     1] loss: 1.466\n",
      "[24,     1] loss: 1.444\n",
      "[25,     1] loss: 1.421\n",
      "[26,     1] loss: 1.399\n",
      "[27,     1] loss: 1.377\n",
      "[28,     1] loss: 1.355\n",
      "[29,     1] loss: 1.334\n",
      "[30,     1] loss: 1.312\n",
      "[31,     1] loss: 1.291\n",
      "[32,     1] loss: 1.270\n",
      "[33,     1] loss: 1.250\n",
      "[34,     1] loss: 1.229\n",
      "[35,     1] loss: 1.209\n",
      "[36,     1] loss: 1.189\n",
      "[37,     1] loss: 1.170\n",
      "[38,     1] loss: 1.150\n",
      "[39,     1] loss: 1.131\n",
      "[40,     1] loss: 1.112\n",
      "[41,     1] loss: 1.094\n",
      "[42,     1] loss: 1.075\n",
      "[43,     1] loss: 1.057\n",
      "[44,     1] loss: 1.039\n",
      "[45,     1] loss: 1.022\n",
      "[46,     1] loss: 1.005\n",
      "[47,     1] loss: 0.988\n",
      "[48,     1] loss: 0.971\n",
      "[49,     1] loss: 0.954\n",
      "[50,     1] loss: 0.938\n",
      "[51,     1] loss: 0.922\n",
      "[52,     1] loss: 0.906\n",
      "[53,     1] loss: 0.891\n",
      "[54,     1] loss: 0.876\n",
      "[55,     1] loss: 0.861\n",
      "[56,     1] loss: 0.846\n",
      "[57,     1] loss: 0.832\n",
      "[58,     1] loss: 0.818\n",
      "[59,     1] loss: 0.804\n",
      "[60,     1] loss: 0.790\n",
      "[61,     1] loss: 0.777\n",
      "[62,     1] loss: 0.764\n",
      "[63,     1] loss: 0.751\n",
      "[64,     1] loss: 0.738\n",
      "[65,     1] loss: 0.726\n",
      "[66,     1] loss: 0.714\n",
      "[67,     1] loss: 0.702\n",
      "[68,     1] loss: 0.690\n",
      "[69,     1] loss: 0.678\n",
      "[70,     1] loss: 0.667\n",
      "[71,     1] loss: 0.656\n",
      "[72,     1] loss: 0.645\n",
      "[73,     1] loss: 0.635\n",
      "[74,     1] loss: 0.624\n",
      "[75,     1] loss: 0.614\n",
      "[76,     1] loss: 0.604\n",
      "[77,     1] loss: 0.595\n",
      "[78,     1] loss: 0.585\n",
      "[79,     1] loss: 0.576\n",
      "[80,     1] loss: 0.566\n",
      "[81,     1] loss: 0.557\n",
      "[82,     1] loss: 0.549\n",
      "[83,     1] loss: 0.540\n",
      "[84,     1] loss: 0.532\n",
      "[85,     1] loss: 0.523\n",
      "[86,     1] loss: 0.515\n",
      "[87,     1] loss: 0.507\n",
      "[88,     1] loss: 0.500\n",
      "[89,     1] loss: 0.492\n",
      "[90,     1] loss: 0.485\n",
      "[91,     1] loss: 0.477\n",
      "[92,     1] loss: 0.470\n",
      "[93,     1] loss: 0.463\n",
      "[94,     1] loss: 0.456\n",
      "[95,     1] loss: 0.450\n",
      "[96,     1] loss: 0.443\n",
      "[97,     1] loss: 0.437\n",
      "[98,     1] loss: 0.431\n",
      "[99,     1] loss: 0.424\n",
      "[100,     1] loss: 0.418\n",
      "[101,     1] loss: 0.412\n",
      "[102,     1] loss: 0.407\n",
      "[103,     1] loss: 0.401\n",
      "[104,     1] loss: 0.395\n",
      "[105,     1] loss: 0.390\n",
      "[106,     1] loss: 0.385\n",
      "[107,     1] loss: 0.380\n",
      "[108,     1] loss: 0.374\n",
      "[109,     1] loss: 0.369\n",
      "[110,     1] loss: 0.365\n",
      "[111,     1] loss: 0.360\n",
      "[112,     1] loss: 0.355\n",
      "[113,     1] loss: 0.350\n",
      "[114,     1] loss: 0.346\n",
      "[115,     1] loss: 0.341\n",
      "[116,     1] loss: 0.337\n",
      "[117,     1] loss: 0.333\n",
      "[118,     1] loss: 0.329\n",
      "[119,     1] loss: 0.325\n",
      "[120,     1] loss: 0.321\n",
      "[121,     1] loss: 0.317\n",
      "[122,     1] loss: 0.313\n",
      "[123,     1] loss: 0.309\n",
      "[124,     1] loss: 0.305\n",
      "[125,     1] loss: 0.302\n",
      "[126,     1] loss: 0.298\n",
      "[127,     1] loss: 0.295\n",
      "[128,     1] loss: 0.291\n",
      "[129,     1] loss: 0.288\n",
      "[130,     1] loss: 0.284\n",
      "[131,     1] loss: 0.281\n",
      "[132,     1] loss: 0.278\n",
      "[133,     1] loss: 0.275\n",
      "[134,     1] loss: 0.272\n",
      "[135,     1] loss: 0.269\n",
      "[136,     1] loss: 0.266\n",
      "[137,     1] loss: 0.263\n",
      "[138,     1] loss: 0.260\n",
      "[139,     1] loss: 0.257\n",
      "[140,     1] loss: 0.254\n",
      "[141,     1] loss: 0.252\n",
      "[142,     1] loss: 0.249\n",
      "[143,     1] loss: 0.246\n",
      "[144,     1] loss: 0.244\n",
      "[145,     1] loss: 0.241\n",
      "[146,     1] loss: 0.239\n",
      "[147,     1] loss: 0.236\n",
      "[148,     1] loss: 0.234\n",
      "[149,     1] loss: 0.231\n",
      "[150,     1] loss: 0.229\n",
      "[151,     1] loss: 0.227\n",
      "[152,     1] loss: 0.224\n",
      "[153,     1] loss: 0.222\n",
      "[154,     1] loss: 0.220\n",
      "[155,     1] loss: 0.218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156,     1] loss: 0.216\n",
      "[157,     1] loss: 0.214\n",
      "[158,     1] loss: 0.212\n",
      "[159,     1] loss: 0.210\n",
      "[160,     1] loss: 0.208\n",
      "[161,     1] loss: 0.206\n",
      "[162,     1] loss: 0.204\n",
      "[163,     1] loss: 0.202\n",
      "[164,     1] loss: 0.200\n",
      "[165,     1] loss: 0.198\n",
      "[166,     1] loss: 0.196\n",
      "[167,     1] loss: 0.194\n",
      "[168,     1] loss: 0.193\n",
      "[169,     1] loss: 0.191\n",
      "[170,     1] loss: 0.189\n",
      "[171,     1] loss: 0.188\n",
      "[172,     1] loss: 0.186\n",
      "[173,     1] loss: 0.184\n",
      "[174,     1] loss: 0.183\n",
      "[175,     1] loss: 0.181\n",
      "[176,     1] loss: 0.180\n",
      "[177,     1] loss: 0.178\n",
      "[178,     1] loss: 0.176\n",
      "[179,     1] loss: 0.175\n",
      "[180,     1] loss: 0.173\n",
      "[181,     1] loss: 0.172\n",
      "[182,     1] loss: 0.171\n",
      "[183,     1] loss: 0.169\n",
      "[184,     1] loss: 0.168\n",
      "[185,     1] loss: 0.166\n",
      "[186,     1] loss: 0.165\n",
      "[187,     1] loss: 0.164\n",
      "[188,     1] loss: 0.162\n",
      "[189,     1] loss: 0.161\n",
      "[190,     1] loss: 0.160\n",
      "[191,     1] loss: 0.158\n",
      "[192,     1] loss: 0.157\n",
      "[193,     1] loss: 0.156\n",
      "[194,     1] loss: 0.155\n",
      "[195,     1] loss: 0.154\n",
      "[196,     1] loss: 0.152\n",
      "[197,     1] loss: 0.151\n",
      "[198,     1] loss: 0.150\n",
      "[199,     1] loss: 0.149\n",
      "[200,     1] loss: 0.148\n",
      "[201,     1] loss: 0.147\n",
      "[202,     1] loss: 0.146\n",
      "[203,     1] loss: 0.144\n",
      "[204,     1] loss: 0.143\n",
      "[205,     1] loss: 0.142\n",
      "[206,     1] loss: 0.141\n",
      "[207,     1] loss: 0.140\n",
      "[208,     1] loss: 0.139\n",
      "[209,     1] loss: 0.138\n",
      "[210,     1] loss: 0.137\n",
      "[211,     1] loss: 0.136\n",
      "[212,     1] loss: 0.135\n",
      "[213,     1] loss: 0.134\n",
      "[214,     1] loss: 0.133\n",
      "[215,     1] loss: 0.132\n",
      "[216,     1] loss: 0.131\n",
      "[217,     1] loss: 0.131\n",
      "[218,     1] loss: 0.130\n",
      "[219,     1] loss: 0.129\n",
      "[220,     1] loss: 0.128\n",
      "[221,     1] loss: 0.127\n",
      "[222,     1] loss: 0.126\n",
      "[223,     1] loss: 0.125\n",
      "[224,     1] loss: 0.124\n",
      "[225,     1] loss: 0.124\n",
      "[226,     1] loss: 0.123\n",
      "[227,     1] loss: 0.122\n",
      "[228,     1] loss: 0.121\n",
      "[229,     1] loss: 0.120\n",
      "[230,     1] loss: 0.120\n",
      "[231,     1] loss: 0.119\n",
      "[232,     1] loss: 0.118\n",
      "[233,     1] loss: 0.117\n",
      "[234,     1] loss: 0.116\n",
      "[235,     1] loss: 0.116\n",
      "[236,     1] loss: 0.115\n",
      "[237,     1] loss: 0.114\n",
      "[238,     1] loss: 0.113\n",
      "[239,     1] loss: 0.113\n",
      "[240,     1] loss: 0.112\n",
      "[241,     1] loss: 0.111\n",
      "[242,     1] loss: 0.111\n",
      "[243,     1] loss: 0.110\n",
      "[244,     1] loss: 0.109\n",
      "[245,     1] loss: 0.109\n",
      "[246,     1] loss: 0.108\n",
      "[247,     1] loss: 0.107\n",
      "[248,     1] loss: 0.107\n",
      "[249,     1] loss: 0.106\n",
      "[250,     1] loss: 0.105\n",
      "[251,     1] loss: 0.105\n",
      "[252,     1] loss: 0.104\n",
      "[253,     1] loss: 0.103\n",
      "[254,     1] loss: 0.103\n",
      "[255,     1] loss: 0.102\n",
      "[256,     1] loss: 0.102\n",
      "[257,     1] loss: 0.101\n",
      "[258,     1] loss: 0.100\n",
      "[259,     1] loss: 0.100\n",
      "[260,     1] loss: 0.099\n",
      "[261,     1] loss: 0.099\n",
      "[262,     1] loss: 0.098\n",
      "[263,     1] loss: 0.098\n",
      "[264,     1] loss: 0.097\n",
      "[265,     1] loss: 0.096\n",
      "[266,     1] loss: 0.096\n",
      "[267,     1] loss: 0.095\n",
      "[268,     1] loss: 0.095\n",
      "[269,     1] loss: 0.094\n",
      "[270,     1] loss: 0.094\n",
      "[271,     1] loss: 0.093\n",
      "[272,     1] loss: 0.093\n",
      "[273,     1] loss: 0.092\n",
      "[274,     1] loss: 0.092\n",
      "[275,     1] loss: 0.091\n",
      "[276,     1] loss: 0.091\n",
      "[277,     1] loss: 0.090\n",
      "[278,     1] loss: 0.090\n",
      "[279,     1] loss: 0.089\n",
      "[280,     1] loss: 0.089\n",
      "[281,     1] loss: 0.088\n",
      "[282,     1] loss: 0.088\n",
      "[283,     1] loss: 0.087\n",
      "[284,     1] loss: 0.087\n",
      "[285,     1] loss: 0.086\n",
      "[286,     1] loss: 0.086\n",
      "[287,     1] loss: 0.086\n",
      "[288,     1] loss: 0.085\n",
      "[289,     1] loss: 0.085\n",
      "[290,     1] loss: 0.084\n",
      "[291,     1] loss: 0.084\n",
      "[292,     1] loss: 0.083\n",
      "[293,     1] loss: 0.083\n",
      "[294,     1] loss: 0.082\n",
      "[295,     1] loss: 0.082\n",
      "[296,     1] loss: 0.082\n",
      "[297,     1] loss: 0.081\n",
      "[298,     1] loss: 0.081\n",
      "[299,     1] loss: 0.080\n",
      "[300,     1] loss: 0.080\n",
      "Finished Training\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Accuracy of the network on the test dataset 1: 37 %\n",
      "Accuracy of the network on the test dataset 2: 91 %\n",
      "Accuracy of the network on the test dataset 3: 100 %\n",
      "Accuracy of the network on the test dataset 4: 100 %\n",
      "Accuracy of the network on the test dataset 5: 100 %\n",
      "Accuracy of the network on the test dataset 6: 100 %\n",
      "Accuracy of the network on the test dataset 7: 100 %\n",
      "Accuracy of the network on the test dataset 8: 100 %\n",
      "Accuracy of the network on the test dataset 9: 100 %\n",
      "Accuracy of the network on the test dataset 10: 100 %\n",
      "Accuracy of the network on the test dataset 11: 100 %\n",
      "Accuracy of the network on the test dataset 12: 57 %\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "training on data set   7\n",
      "[1,     1] loss: 4.482\n",
      "[2,     1] loss: 2.208\n",
      "[3,     1] loss: 2.175\n",
      "[4,     1] loss: 2.143\n",
      "[5,     1] loss: 2.110\n",
      "[6,     1] loss: 2.078\n",
      "[7,     1] loss: 2.046\n",
      "[8,     1] loss: 2.014\n",
      "[9,     1] loss: 1.983\n",
      "[10,     1] loss: 1.952\n",
      "[11,     1] loss: 1.921\n",
      "[12,     1] loss: 1.890\n",
      "[13,     1] loss: 1.859\n",
      "[14,     1] loss: 1.829\n",
      "[15,     1] loss: 1.799\n",
      "[16,     1] loss: 1.769\n",
      "[17,     1] loss: 1.740\n",
      "[18,     1] loss: 1.710\n",
      "[19,     1] loss: 1.681\n",
      "[20,     1] loss: 1.652\n",
      "[21,     1] loss: 1.624\n",
      "[22,     1] loss: 1.596\n",
      "[23,     1] loss: 1.568\n",
      "[24,     1] loss: 1.540\n",
      "[25,     1] loss: 1.513\n",
      "[26,     1] loss: 1.485\n",
      "[27,     1] loss: 1.459\n",
      "[28,     1] loss: 1.432\n",
      "[29,     1] loss: 1.406\n",
      "[30,     1] loss: 1.380\n",
      "[31,     1] loss: 1.354\n",
      "[32,     1] loss: 1.329\n",
      "[33,     1] loss: 1.304\n",
      "[34,     1] loss: 1.279\n",
      "[35,     1] loss: 1.255\n",
      "[36,     1] loss: 1.231\n",
      "[37,     1] loss: 1.207\n",
      "[38,     1] loss: 1.184\n",
      "[39,     1] loss: 1.161\n",
      "[40,     1] loss: 1.139\n",
      "[41,     1] loss: 1.116\n",
      "[42,     1] loss: 1.094\n",
      "[43,     1] loss: 1.073\n",
      "[44,     1] loss: 1.052\n",
      "[45,     1] loss: 1.031\n",
      "[46,     1] loss: 1.010\n",
      "[47,     1] loss: 0.990\n",
      "[48,     1] loss: 0.970\n",
      "[49,     1] loss: 0.951\n",
      "[50,     1] loss: 0.932\n",
      "[51,     1] loss: 0.913\n",
      "[52,     1] loss: 0.895\n",
      "[53,     1] loss: 0.877\n",
      "[54,     1] loss: 0.859\n",
      "[55,     1] loss: 0.842\n",
      "[56,     1] loss: 0.825\n",
      "[57,     1] loss: 0.809\n",
      "[58,     1] loss: 0.792\n",
      "[59,     1] loss: 0.777\n",
      "[60,     1] loss: 0.761\n",
      "[61,     1] loss: 0.746\n",
      "[62,     1] loss: 0.731\n",
      "[63,     1] loss: 0.716\n",
      "[64,     1] loss: 0.702\n",
      "[65,     1] loss: 0.688\n",
      "[66,     1] loss: 0.675\n",
      "[67,     1] loss: 0.662\n",
      "[68,     1] loss: 0.649\n",
      "[69,     1] loss: 0.636\n",
      "[70,     1] loss: 0.624\n",
      "[71,     1] loss: 0.612\n",
      "[72,     1] loss: 0.600\n",
      "[73,     1] loss: 0.588\n",
      "[74,     1] loss: 0.577\n",
      "[75,     1] loss: 0.566\n",
      "[76,     1] loss: 0.556\n",
      "[77,     1] loss: 0.545\n",
      "[78,     1] loss: 0.535\n",
      "[79,     1] loss: 0.525\n",
      "[80,     1] loss: 0.515\n",
      "[81,     1] loss: 0.506\n",
      "[82,     1] loss: 0.497\n",
      "[83,     1] loss: 0.488\n",
      "[84,     1] loss: 0.479\n",
      "[85,     1] loss: 0.471\n",
      "[86,     1] loss: 0.462\n",
      "[87,     1] loss: 0.454\n",
      "[88,     1] loss: 0.446\n",
      "[89,     1] loss: 0.439\n",
      "[90,     1] loss: 0.431\n",
      "[91,     1] loss: 0.424\n",
      "[92,     1] loss: 0.417\n",
      "[93,     1] loss: 0.410\n",
      "[94,     1] loss: 0.403\n",
      "[95,     1] loss: 0.396\n",
      "[96,     1] loss: 0.390\n",
      "[97,     1] loss: 0.383\n",
      "[98,     1] loss: 0.377\n",
      "[99,     1] loss: 0.371\n",
      "[100,     1] loss: 0.365\n",
      "[101,     1] loss: 0.360\n",
      "[102,     1] loss: 0.354\n",
      "[103,     1] loss: 0.349\n",
      "[104,     1] loss: 0.343\n",
      "[105,     1] loss: 0.338\n",
      "[106,     1] loss: 0.333\n",
      "[107,     1] loss: 0.328\n",
      "[108,     1] loss: 0.323\n",
      "[109,     1] loss: 0.318\n",
      "[110,     1] loss: 0.314\n",
      "[111,     1] loss: 0.309\n",
      "[112,     1] loss: 0.305\n",
      "[113,     1] loss: 0.301\n",
      "[114,     1] loss: 0.296\n",
      "[115,     1] loss: 0.292\n",
      "[116,     1] loss: 0.288\n",
      "[117,     1] loss: 0.284\n",
      "[118,     1] loss: 0.280\n",
      "[119,     1] loss: 0.277\n",
      "[120,     1] loss: 0.273\n",
      "[121,     1] loss: 0.269\n",
      "[122,     1] loss: 0.266\n",
      "[123,     1] loss: 0.262\n",
      "[124,     1] loss: 0.259\n",
      "[125,     1] loss: 0.256\n",
      "[126,     1] loss: 0.252\n",
      "[127,     1] loss: 0.249\n",
      "[128,     1] loss: 0.246\n",
      "[129,     1] loss: 0.243\n",
      "[130,     1] loss: 0.240\n",
      "[131,     1] loss: 0.237\n",
      "[132,     1] loss: 0.234\n",
      "[133,     1] loss: 0.231\n",
      "[134,     1] loss: 0.229\n",
      "[135,     1] loss: 0.226\n",
      "[136,     1] loss: 0.223\n",
      "[137,     1] loss: 0.221\n",
      "[138,     1] loss: 0.218\n",
      "[139,     1] loss: 0.216\n",
      "[140,     1] loss: 0.213\n",
      "[141,     1] loss: 0.211\n",
      "[142,     1] loss: 0.208\n",
      "[143,     1] loss: 0.206\n",
      "[144,     1] loss: 0.204\n",
      "[145,     1] loss: 0.201\n",
      "[146,     1] loss: 0.199\n",
      "[147,     1] loss: 0.197\n",
      "[148,     1] loss: 0.195\n",
      "[149,     1] loss: 0.193\n",
      "[150,     1] loss: 0.191\n",
      "[151,     1] loss: 0.189\n",
      "[152,     1] loss: 0.187\n",
      "[153,     1] loss: 0.185\n",
      "[154,     1] loss: 0.183\n",
      "[155,     1] loss: 0.181\n",
      "[156,     1] loss: 0.179\n",
      "[157,     1] loss: 0.178\n",
      "[158,     1] loss: 0.176\n",
      "[159,     1] loss: 0.174\n",
      "[160,     1] loss: 0.172\n",
      "[161,     1] loss: 0.171\n",
      "[162,     1] loss: 0.169\n",
      "[163,     1] loss: 0.167\n",
      "[164,     1] loss: 0.166\n",
      "[165,     1] loss: 0.164\n",
      "[166,     1] loss: 0.163\n",
      "[167,     1] loss: 0.161\n",
      "[168,     1] loss: 0.160\n",
      "[169,     1] loss: 0.158\n",
      "[170,     1] loss: 0.157\n",
      "[171,     1] loss: 0.155\n",
      "[172,     1] loss: 0.154\n",
      "[173,     1] loss: 0.152\n",
      "[174,     1] loss: 0.151\n",
      "[175,     1] loss: 0.150\n",
      "[176,     1] loss: 0.148\n",
      "[177,     1] loss: 0.147\n",
      "[178,     1] loss: 0.146\n",
      "[179,     1] loss: 0.144\n",
      "[180,     1] loss: 0.143\n",
      "[181,     1] loss: 0.142\n",
      "[182,     1] loss: 0.141\n",
      "[183,     1] loss: 0.139\n",
      "[184,     1] loss: 0.138\n",
      "[185,     1] loss: 0.137\n",
      "[186,     1] loss: 0.136\n",
      "[187,     1] loss: 0.135\n",
      "[188,     1] loss: 0.134\n",
      "[189,     1] loss: 0.133\n",
      "[190,     1] loss: 0.132\n",
      "[191,     1] loss: 0.130\n",
      "[192,     1] loss: 0.129\n",
      "[193,     1] loss: 0.128\n",
      "[194,     1] loss: 0.127\n",
      "[195,     1] loss: 0.126\n",
      "[196,     1] loss: 0.125\n",
      "[197,     1] loss: 0.124\n",
      "[198,     1] loss: 0.123\n",
      "[199,     1] loss: 0.122\n",
      "[200,     1] loss: 0.121\n",
      "[201,     1] loss: 0.120\n",
      "[202,     1] loss: 0.120\n",
      "[203,     1] loss: 0.119\n",
      "[204,     1] loss: 0.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205,     1] loss: 0.117\n",
      "[206,     1] loss: 0.116\n",
      "[207,     1] loss: 0.115\n",
      "[208,     1] loss: 0.114\n",
      "[209,     1] loss: 0.113\n",
      "[210,     1] loss: 0.113\n",
      "[211,     1] loss: 0.112\n",
      "[212,     1] loss: 0.111\n",
      "[213,     1] loss: 0.110\n",
      "[214,     1] loss: 0.109\n",
      "[215,     1] loss: 0.109\n",
      "[216,     1] loss: 0.108\n",
      "[217,     1] loss: 0.107\n",
      "[218,     1] loss: 0.106\n",
      "[219,     1] loss: 0.106\n",
      "[220,     1] loss: 0.105\n",
      "[221,     1] loss: 0.104\n",
      "[222,     1] loss: 0.103\n",
      "[223,     1] loss: 0.103\n",
      "[224,     1] loss: 0.102\n",
      "[225,     1] loss: 0.101\n",
      "[226,     1] loss: 0.101\n",
      "[227,     1] loss: 0.100\n",
      "[228,     1] loss: 0.099\n",
      "[229,     1] loss: 0.099\n",
      "[230,     1] loss: 0.098\n",
      "[231,     1] loss: 0.097\n",
      "[232,     1] loss: 0.097\n",
      "[233,     1] loss: 0.096\n",
      "[234,     1] loss: 0.095\n",
      "[235,     1] loss: 0.095\n",
      "[236,     1] loss: 0.094\n",
      "[237,     1] loss: 0.093\n",
      "[238,     1] loss: 0.093\n",
      "[239,     1] loss: 0.092\n",
      "[240,     1] loss: 0.092\n",
      "[241,     1] loss: 0.091\n",
      "[242,     1] loss: 0.090\n",
      "[243,     1] loss: 0.090\n",
      "[244,     1] loss: 0.089\n",
      "[245,     1] loss: 0.089\n",
      "[246,     1] loss: 0.088\n",
      "[247,     1] loss: 0.088\n",
      "[248,     1] loss: 0.087\n",
      "[249,     1] loss: 0.087\n",
      "[250,     1] loss: 0.086\n",
      "[251,     1] loss: 0.086\n",
      "[252,     1] loss: 0.085\n",
      "[253,     1] loss: 0.085\n",
      "[254,     1] loss: 0.084\n",
      "[255,     1] loss: 0.084\n",
      "[256,     1] loss: 0.083\n",
      "[257,     1] loss: 0.083\n",
      "[258,     1] loss: 0.082\n",
      "[259,     1] loss: 0.082\n",
      "[260,     1] loss: 0.081\n",
      "[261,     1] loss: 0.081\n",
      "[262,     1] loss: 0.080\n",
      "[263,     1] loss: 0.080\n",
      "[264,     1] loss: 0.079\n",
      "[265,     1] loss: 0.079\n",
      "[266,     1] loss: 0.078\n",
      "[267,     1] loss: 0.078\n",
      "[268,     1] loss: 0.077\n",
      "[269,     1] loss: 0.077\n",
      "[270,     1] loss: 0.077\n",
      "[271,     1] loss: 0.076\n",
      "[272,     1] loss: 0.076\n",
      "[273,     1] loss: 0.075\n",
      "[274,     1] loss: 0.075\n",
      "[275,     1] loss: 0.074\n",
      "[276,     1] loss: 0.074\n",
      "[277,     1] loss: 0.074\n",
      "[278,     1] loss: 0.073\n",
      "[279,     1] loss: 0.073\n",
      "[280,     1] loss: 0.072\n",
      "[281,     1] loss: 0.072\n",
      "[282,     1] loss: 0.072\n",
      "[283,     1] loss: 0.071\n",
      "[284,     1] loss: 0.071\n",
      "[285,     1] loss: 0.071\n",
      "[286,     1] loss: 0.070\n",
      "[287,     1] loss: 0.070\n",
      "[288,     1] loss: 0.069\n",
      "[289,     1] loss: 0.069\n",
      "[290,     1] loss: 0.069\n",
      "[291,     1] loss: 0.068\n",
      "[292,     1] loss: 0.068\n",
      "[293,     1] loss: 0.068\n",
      "[294,     1] loss: 0.067\n",
      "[295,     1] loss: 0.067\n",
      "[296,     1] loss: 0.067\n",
      "[297,     1] loss: 0.066\n",
      "[298,     1] loss: 0.066\n",
      "[299,     1] loss: 0.066\n",
      "[300,     1] loss: 0.065\n",
      "Finished Training\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Accuracy of the network on the test dataset 1: 35 %\n",
      "Accuracy of the network on the test dataset 2: 83 %\n",
      "Accuracy of the network on the test dataset 3: 100 %\n",
      "Accuracy of the network on the test dataset 4: 100 %\n",
      "Accuracy of the network on the test dataset 5: 100 %\n",
      "Accuracy of the network on the test dataset 6: 100 %\n",
      "Accuracy of the network on the test dataset 7: 100 %\n",
      "Accuracy of the network on the test dataset 8: 100 %\n",
      "Accuracy of the network on the test dataset 9: 100 %\n",
      "Accuracy of the network on the test dataset 10: 100 %\n",
      "Accuracy of the network on the test dataset 11: 100 %\n",
      "Accuracy of the network on the test dataset 12: 35 %\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "training on data set   8\n",
      "[1,     1] loss: 4.942\n",
      "[2,     1] loss: 2.432\n",
      "[3,     1] loss: 2.394\n",
      "[4,     1] loss: 2.355\n",
      "[5,     1] loss: 2.317\n",
      "[6,     1] loss: 2.279\n",
      "[7,     1] loss: 2.242\n",
      "[8,     1] loss: 2.204\n",
      "[9,     1] loss: 2.167\n",
      "[10,     1] loss: 2.130\n",
      "[11,     1] loss: 2.094\n",
      "[12,     1] loss: 2.057\n",
      "[13,     1] loss: 2.021\n",
      "[14,     1] loss: 1.985\n",
      "[15,     1] loss: 1.950\n",
      "[16,     1] loss: 1.914\n",
      "[17,     1] loss: 1.879\n",
      "[18,     1] loss: 1.845\n",
      "[19,     1] loss: 1.810\n",
      "[20,     1] loss: 1.776\n",
      "[21,     1] loss: 1.742\n",
      "[22,     1] loss: 1.709\n",
      "[23,     1] loss: 1.676\n",
      "[24,     1] loss: 1.643\n",
      "[25,     1] loss: 1.610\n",
      "[26,     1] loss: 1.578\n",
      "[27,     1] loss: 1.547\n",
      "[28,     1] loss: 1.515\n",
      "[29,     1] loss: 1.484\n",
      "[30,     1] loss: 1.454\n",
      "[31,     1] loss: 1.423\n",
      "[32,     1] loss: 1.394\n",
      "[33,     1] loss: 1.364\n",
      "[34,     1] loss: 1.335\n",
      "[35,     1] loss: 1.306\n",
      "[36,     1] loss: 1.278\n",
      "[37,     1] loss: 1.251\n",
      "[38,     1] loss: 1.223\n",
      "[39,     1] loss: 1.196\n",
      "[40,     1] loss: 1.170\n",
      "[41,     1] loss: 1.144\n",
      "[42,     1] loss: 1.118\n",
      "[43,     1] loss: 1.093\n",
      "[44,     1] loss: 1.068\n",
      "[45,     1] loss: 1.044\n",
      "[46,     1] loss: 1.021\n",
      "[47,     1] loss: 0.997\n",
      "[48,     1] loss: 0.974\n",
      "[49,     1] loss: 0.952\n",
      "[50,     1] loss: 0.930\n",
      "[51,     1] loss: 0.909\n",
      "[52,     1] loss: 0.888\n",
      "[53,     1] loss: 0.867\n",
      "[54,     1] loss: 0.847\n",
      "[55,     1] loss: 0.828\n",
      "[56,     1] loss: 0.809\n",
      "[57,     1] loss: 0.790\n",
      "[58,     1] loss: 0.772\n",
      "[59,     1] loss: 0.754\n",
      "[60,     1] loss: 0.737\n",
      "[61,     1] loss: 0.720\n",
      "[62,     1] loss: 0.703\n",
      "[63,     1] loss: 0.687\n",
      "[64,     1] loss: 0.672\n",
      "[65,     1] loss: 0.656\n",
      "[66,     1] loss: 0.642\n",
      "[67,     1] loss: 0.627\n",
      "[68,     1] loss: 0.613\n",
      "[69,     1] loss: 0.599\n",
      "[70,     1] loss: 0.586\n",
      "[71,     1] loss: 0.573\n",
      "[72,     1] loss: 0.561\n",
      "[73,     1] loss: 0.549\n",
      "[74,     1] loss: 0.537\n",
      "[75,     1] loss: 0.525\n",
      "[76,     1] loss: 0.514\n",
      "[77,     1] loss: 0.503\n",
      "[78,     1] loss: 0.493\n",
      "[79,     1] loss: 0.482\n",
      "[80,     1] loss: 0.472\n",
      "[81,     1] loss: 0.463\n",
      "[82,     1] loss: 0.453\n",
      "[83,     1] loss: 0.444\n",
      "[84,     1] loss: 0.435\n",
      "[85,     1] loss: 0.427\n",
      "[86,     1] loss: 0.418\n",
      "[87,     1] loss: 0.410\n",
      "[88,     1] loss: 0.402\n",
      "[89,     1] loss: 0.395\n",
      "[90,     1] loss: 0.387\n",
      "[91,     1] loss: 0.380\n",
      "[92,     1] loss: 0.373\n",
      "[93,     1] loss: 0.366\n",
      "[94,     1] loss: 0.359\n",
      "[95,     1] loss: 0.353\n",
      "[96,     1] loss: 0.346\n",
      "[97,     1] loss: 0.340\n",
      "[98,     1] loss: 0.334\n",
      "[99,     1] loss: 0.329\n",
      "[100,     1] loss: 0.323\n",
      "[101,     1] loss: 0.317\n",
      "[102,     1] loss: 0.312\n",
      "[103,     1] loss: 0.307\n",
      "[104,     1] loss: 0.302\n",
      "[105,     1] loss: 0.297\n",
      "[106,     1] loss: 0.292\n",
      "[107,     1] loss: 0.287\n",
      "[108,     1] loss: 0.283\n",
      "[109,     1] loss: 0.278\n",
      "[110,     1] loss: 0.274\n",
      "[111,     1] loss: 0.270\n",
      "[112,     1] loss: 0.266\n",
      "[113,     1] loss: 0.262\n",
      "[114,     1] loss: 0.258\n",
      "[115,     1] loss: 0.254\n",
      "[116,     1] loss: 0.250\n",
      "[117,     1] loss: 0.247\n",
      "[118,     1] loss: 0.243\n",
      "[119,     1] loss: 0.240\n",
      "[120,     1] loss: 0.236\n",
      "[121,     1] loss: 0.233\n",
      "[122,     1] loss: 0.230\n",
      "[123,     1] loss: 0.227\n",
      "[124,     1] loss: 0.224\n",
      "[125,     1] loss: 0.221\n",
      "[126,     1] loss: 0.218\n",
      "[127,     1] loss: 0.215\n",
      "[128,     1] loss: 0.212\n",
      "[129,     1] loss: 0.209\n",
      "[130,     1] loss: 0.206\n",
      "[131,     1] loss: 0.204\n",
      "[132,     1] loss: 0.201\n",
      "[133,     1] loss: 0.199\n",
      "[134,     1] loss: 0.196\n",
      "[135,     1] loss: 0.194\n",
      "[136,     1] loss: 0.191\n",
      "[137,     1] loss: 0.189\n",
      "[138,     1] loss: 0.187\n",
      "[139,     1] loss: 0.185\n",
      "[140,     1] loss: 0.183\n",
      "[141,     1] loss: 0.180\n",
      "[142,     1] loss: 0.178\n",
      "[143,     1] loss: 0.176\n",
      "[144,     1] loss: 0.174\n",
      "[145,     1] loss: 0.172\n",
      "[146,     1] loss: 0.170\n",
      "[147,     1] loss: 0.168\n",
      "[148,     1] loss: 0.167\n",
      "[149,     1] loss: 0.165\n",
      "[150,     1] loss: 0.163\n",
      "[151,     1] loss: 0.161\n",
      "[152,     1] loss: 0.159\n",
      "[153,     1] loss: 0.158\n",
      "[154,     1] loss: 0.156\n",
      "[155,     1] loss: 0.154\n",
      "[156,     1] loss: 0.153\n",
      "[157,     1] loss: 0.151\n",
      "[158,     1] loss: 0.150\n",
      "[159,     1] loss: 0.148\n",
      "[160,     1] loss: 0.147\n",
      "[161,     1] loss: 0.145\n",
      "[162,     1] loss: 0.144\n",
      "[163,     1] loss: 0.142\n",
      "[164,     1] loss: 0.141\n",
      "[165,     1] loss: 0.140\n",
      "[166,     1] loss: 0.138\n",
      "[167,     1] loss: 0.137\n",
      "[168,     1] loss: 0.136\n",
      "[169,     1] loss: 0.134\n",
      "[170,     1] loss: 0.133\n",
      "[171,     1] loss: 0.132\n",
      "[172,     1] loss: 0.131\n",
      "[173,     1] loss: 0.129\n",
      "[174,     1] loss: 0.128\n",
      "[175,     1] loss: 0.127\n",
      "[176,     1] loss: 0.126\n",
      "[177,     1] loss: 0.125\n",
      "[178,     1] loss: 0.124\n",
      "[179,     1] loss: 0.122\n",
      "[180,     1] loss: 0.121\n",
      "[181,     1] loss: 0.120\n",
      "[182,     1] loss: 0.119\n",
      "[183,     1] loss: 0.118\n",
      "[184,     1] loss: 0.117\n",
      "[185,     1] loss: 0.116\n",
      "[186,     1] loss: 0.115\n",
      "[187,     1] loss: 0.114\n",
      "[188,     1] loss: 0.113\n",
      "[189,     1] loss: 0.112\n",
      "[190,     1] loss: 0.111\n",
      "[191,     1] loss: 0.111\n",
      "[192,     1] loss: 0.110\n",
      "[193,     1] loss: 0.109\n",
      "[194,     1] loss: 0.108\n",
      "[195,     1] loss: 0.107\n",
      "[196,     1] loss: 0.106\n",
      "[197,     1] loss: 0.105\n",
      "[198,     1] loss: 0.104\n",
      "[199,     1] loss: 0.104\n",
      "[200,     1] loss: 0.103\n",
      "[201,     1] loss: 0.102\n",
      "[202,     1] loss: 0.101\n",
      "[203,     1] loss: 0.100\n",
      "[204,     1] loss: 0.100\n",
      "[205,     1] loss: 0.099\n",
      "[206,     1] loss: 0.098\n",
      "[207,     1] loss: 0.097\n",
      "[208,     1] loss: 0.097\n",
      "[209,     1] loss: 0.096\n",
      "[210,     1] loss: 0.095\n",
      "[211,     1] loss: 0.095\n",
      "[212,     1] loss: 0.094\n",
      "[213,     1] loss: 0.093\n",
      "[214,     1] loss: 0.092\n",
      "[215,     1] loss: 0.092\n",
      "[216,     1] loss: 0.091\n",
      "[217,     1] loss: 0.090\n",
      "[218,     1] loss: 0.090\n",
      "[219,     1] loss: 0.089\n",
      "[220,     1] loss: 0.089\n",
      "[221,     1] loss: 0.088\n",
      "[222,     1] loss: 0.087\n",
      "[223,     1] loss: 0.087\n",
      "[224,     1] loss: 0.086\n",
      "[225,     1] loss: 0.086\n",
      "[226,     1] loss: 0.085\n",
      "[227,     1] loss: 0.084\n",
      "[228,     1] loss: 0.084\n",
      "[229,     1] loss: 0.083\n",
      "[230,     1] loss: 0.083\n",
      "[231,     1] loss: 0.082\n",
      "[232,     1] loss: 0.082\n",
      "[233,     1] loss: 0.081\n",
      "[234,     1] loss: 0.080\n",
      "[235,     1] loss: 0.080\n",
      "[236,     1] loss: 0.079\n",
      "[237,     1] loss: 0.079\n",
      "[238,     1] loss: 0.078\n",
      "[239,     1] loss: 0.078\n",
      "[240,     1] loss: 0.077\n",
      "[241,     1] loss: 0.077\n",
      "[242,     1] loss: 0.076\n",
      "[243,     1] loss: 0.076\n",
      "[244,     1] loss: 0.075\n",
      "[245,     1] loss: 0.075\n",
      "[246,     1] loss: 0.074\n",
      "[247,     1] loss: 0.074\n",
      "[248,     1] loss: 0.074\n",
      "[249,     1] loss: 0.073\n",
      "[250,     1] loss: 0.073\n",
      "[251,     1] loss: 0.072\n",
      "[252,     1] loss: 0.072\n",
      "[253,     1] loss: 0.071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[254,     1] loss: 0.071\n",
      "[255,     1] loss: 0.070\n",
      "[256,     1] loss: 0.070\n",
      "[257,     1] loss: 0.070\n",
      "[258,     1] loss: 0.069\n",
      "[259,     1] loss: 0.069\n",
      "[260,     1] loss: 0.068\n",
      "[261,     1] loss: 0.068\n",
      "[262,     1] loss: 0.068\n",
      "[263,     1] loss: 0.067\n",
      "[264,     1] loss: 0.067\n",
      "[265,     1] loss: 0.066\n",
      "[266,     1] loss: 0.066\n",
      "[267,     1] loss: 0.066\n",
      "[268,     1] loss: 0.065\n",
      "[269,     1] loss: 0.065\n",
      "[270,     1] loss: 0.065\n",
      "[271,     1] loss: 0.064\n",
      "[272,     1] loss: 0.064\n",
      "[273,     1] loss: 0.063\n",
      "[274,     1] loss: 0.063\n",
      "[275,     1] loss: 0.063\n",
      "[276,     1] loss: 0.062\n",
      "[277,     1] loss: 0.062\n",
      "[278,     1] loss: 0.062\n",
      "[279,     1] loss: 0.061\n",
      "[280,     1] loss: 0.061\n",
      "[281,     1] loss: 0.061\n",
      "[282,     1] loss: 0.060\n",
      "[283,     1] loss: 0.060\n",
      "[284,     1] loss: 0.060\n",
      "[285,     1] loss: 0.059\n",
      "[286,     1] loss: 0.059\n",
      "[287,     1] loss: 0.059\n",
      "[288,     1] loss: 0.059\n",
      "[289,     1] loss: 0.058\n",
      "[290,     1] loss: 0.058\n",
      "[291,     1] loss: 0.058\n",
      "[292,     1] loss: 0.057\n",
      "[293,     1] loss: 0.057\n",
      "[294,     1] loss: 0.057\n",
      "[295,     1] loss: 0.056\n",
      "[296,     1] loss: 0.056\n",
      "[297,     1] loss: 0.056\n",
      "[298,     1] loss: 0.056\n",
      "[299,     1] loss: 0.055\n",
      "[300,     1] loss: 0.055\n",
      "Finished Training\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Accuracy of the network on the test dataset 1: 35 %\n",
      "Accuracy of the network on the test dataset 2: 65 %\n",
      "Accuracy of the network on the test dataset 3: 97 %\n",
      "Accuracy of the network on the test dataset 4: 100 %\n",
      "Accuracy of the network on the test dataset 5: 100 %\n",
      "Accuracy of the network on the test dataset 6: 100 %\n",
      "Accuracy of the network on the test dataset 7: 100 %\n",
      "Accuracy of the network on the test dataset 8: 100 %\n",
      "Accuracy of the network on the test dataset 9: 100 %\n",
      "Accuracy of the network on the test dataset 10: 100 %\n",
      "Accuracy of the network on the test dataset 11: 100 %\n",
      "Accuracy of the network on the test dataset 12: 35 %\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "training on data set   9\n",
      "[1,     1] loss: 5.415\n",
      "[2,     1] loss: 2.663\n",
      "[3,     1] loss: 2.619\n",
      "[4,     1] loss: 2.575\n",
      "[5,     1] loss: 2.531\n",
      "[6,     1] loss: 2.487\n",
      "[7,     1] loss: 2.444\n",
      "[8,     1] loss: 2.400\n",
      "[9,     1] loss: 2.357\n",
      "[10,     1] loss: 2.315\n",
      "[11,     1] loss: 2.273\n",
      "[12,     1] loss: 2.231\n",
      "[13,     1] loss: 2.189\n",
      "[14,     1] loss: 2.147\n",
      "[15,     1] loss: 2.106\n",
      "[16,     1] loss: 2.065\n",
      "[17,     1] loss: 2.025\n",
      "[18,     1] loss: 1.985\n",
      "[19,     1] loss: 1.945\n",
      "[20,     1] loss: 1.906\n",
      "[21,     1] loss: 1.866\n",
      "[22,     1] loss: 1.828\n",
      "[23,     1] loss: 1.789\n",
      "[24,     1] loss: 1.752\n",
      "[25,     1] loss: 1.714\n",
      "[26,     1] loss: 1.677\n",
      "[27,     1] loss: 1.640\n",
      "[28,     1] loss: 1.604\n",
      "[29,     1] loss: 1.568\n",
      "[30,     1] loss: 1.533\n",
      "[31,     1] loss: 1.498\n",
      "[32,     1] loss: 1.463\n",
      "[33,     1] loss: 1.429\n",
      "[34,     1] loss: 1.396\n",
      "[35,     1] loss: 1.363\n",
      "[36,     1] loss: 1.330\n",
      "[37,     1] loss: 1.298\n",
      "[38,     1] loss: 1.267\n",
      "[39,     1] loss: 1.236\n",
      "[40,     1] loss: 1.206\n",
      "[41,     1] loss: 1.176\n",
      "[42,     1] loss: 1.147\n",
      "[43,     1] loss: 1.118\n",
      "[44,     1] loss: 1.090\n",
      "[45,     1] loss: 1.062\n",
      "[46,     1] loss: 1.035\n",
      "[47,     1] loss: 1.008\n",
      "[48,     1] loss: 0.982\n",
      "[49,     1] loss: 0.957\n",
      "[50,     1] loss: 0.932\n",
      "[51,     1] loss: 0.908\n",
      "[52,     1] loss: 0.884\n",
      "[53,     1] loss: 0.861\n",
      "[54,     1] loss: 0.839\n",
      "[55,     1] loss: 0.817\n",
      "[56,     1] loss: 0.796\n",
      "[57,     1] loss: 0.775\n",
      "[58,     1] loss: 0.755\n",
      "[59,     1] loss: 0.735\n",
      "[60,     1] loss: 0.716\n",
      "[61,     1] loss: 0.698\n",
      "[62,     1] loss: 0.680\n",
      "[63,     1] loss: 0.662\n",
      "[64,     1] loss: 0.645\n",
      "[65,     1] loss: 0.629\n",
      "[66,     1] loss: 0.613\n",
      "[67,     1] loss: 0.597\n",
      "[68,     1] loss: 0.582\n",
      "[69,     1] loss: 0.568\n",
      "[70,     1] loss: 0.554\n",
      "[71,     1] loss: 0.540\n",
      "[72,     1] loss: 0.527\n",
      "[73,     1] loss: 0.514\n",
      "[74,     1] loss: 0.502\n",
      "[75,     1] loss: 0.490\n",
      "[76,     1] loss: 0.478\n",
      "[77,     1] loss: 0.467\n",
      "[78,     1] loss: 0.456\n",
      "[79,     1] loss: 0.445\n",
      "[80,     1] loss: 0.435\n",
      "[81,     1] loss: 0.426\n",
      "[82,     1] loss: 0.416\n",
      "[83,     1] loss: 0.407\n",
      "[84,     1] loss: 0.398\n",
      "[85,     1] loss: 0.389\n",
      "[86,     1] loss: 0.381\n",
      "[87,     1] loss: 0.373\n",
      "[88,     1] loss: 0.365\n",
      "[89,     1] loss: 0.357\n",
      "[90,     1] loss: 0.350\n",
      "[91,     1] loss: 0.343\n",
      "[92,     1] loss: 0.336\n",
      "[93,     1] loss: 0.329\n",
      "[94,     1] loss: 0.323\n",
      "[95,     1] loss: 0.317\n",
      "[96,     1] loss: 0.311\n",
      "[97,     1] loss: 0.305\n",
      "[98,     1] loss: 0.299\n",
      "[99,     1] loss: 0.294\n",
      "[100,     1] loss: 0.288\n",
      "[101,     1] loss: 0.283\n",
      "[102,     1] loss: 0.278\n",
      "[103,     1] loss: 0.273\n",
      "[104,     1] loss: 0.268\n",
      "[105,     1] loss: 0.264\n",
      "[106,     1] loss: 0.259\n",
      "[107,     1] loss: 0.255\n",
      "[108,     1] loss: 0.250\n",
      "[109,     1] loss: 0.246\n",
      "[110,     1] loss: 0.242\n",
      "[111,     1] loss: 0.238\n",
      "[112,     1] loss: 0.235\n",
      "[113,     1] loss: 0.231\n",
      "[114,     1] loss: 0.227\n",
      "[115,     1] loss: 0.224\n",
      "[116,     1] loss: 0.220\n",
      "[117,     1] loss: 0.217\n",
      "[118,     1] loss: 0.214\n",
      "[119,     1] loss: 0.211\n",
      "[120,     1] loss: 0.208\n",
      "[121,     1] loss: 0.205\n",
      "[122,     1] loss: 0.202\n",
      "[123,     1] loss: 0.199\n",
      "[124,     1] loss: 0.196\n",
      "[125,     1] loss: 0.193\n",
      "[126,     1] loss: 0.191\n",
      "[127,     1] loss: 0.188\n",
      "[128,     1] loss: 0.185\n",
      "[129,     1] loss: 0.183\n",
      "[130,     1] loss: 0.181\n",
      "[131,     1] loss: 0.178\n",
      "[132,     1] loss: 0.176\n",
      "[133,     1] loss: 0.174\n",
      "[134,     1] loss: 0.171\n",
      "[135,     1] loss: 0.169\n",
      "[136,     1] loss: 0.167\n",
      "[137,     1] loss: 0.165\n",
      "[138,     1] loss: 0.163\n",
      "[139,     1] loss: 0.161\n",
      "[140,     1] loss: 0.159\n",
      "[141,     1] loss: 0.157\n",
      "[142,     1] loss: 0.155\n",
      "[143,     1] loss: 0.153\n",
      "[144,     1] loss: 0.152\n",
      "[145,     1] loss: 0.150\n",
      "[146,     1] loss: 0.148\n",
      "[147,     1] loss: 0.147\n",
      "[148,     1] loss: 0.145\n",
      "[149,     1] loss: 0.143\n",
      "[150,     1] loss: 0.142\n",
      "[151,     1] loss: 0.140\n",
      "[152,     1] loss: 0.139\n",
      "[153,     1] loss: 0.137\n",
      "[154,     1] loss: 0.136\n",
      "[155,     1] loss: 0.134\n",
      "[156,     1] loss: 0.133\n",
      "[157,     1] loss: 0.131\n",
      "[158,     1] loss: 0.130\n",
      "[159,     1] loss: 0.129\n",
      "[160,     1] loss: 0.127\n",
      "[161,     1] loss: 0.126\n",
      "[162,     1] loss: 0.125\n",
      "[163,     1] loss: 0.124\n",
      "[164,     1] loss: 0.122\n",
      "[165,     1] loss: 0.121\n",
      "[166,     1] loss: 0.120\n",
      "[167,     1] loss: 0.119\n",
      "[168,     1] loss: 0.118\n",
      "[169,     1] loss: 0.116\n",
      "[170,     1] loss: 0.115\n",
      "[171,     1] loss: 0.114\n",
      "[172,     1] loss: 0.113\n",
      "[173,     1] loss: 0.112\n",
      "[174,     1] loss: 0.111\n",
      "[175,     1] loss: 0.110\n",
      "[176,     1] loss: 0.109\n",
      "[177,     1] loss: 0.108\n",
      "[178,     1] loss: 0.107\n",
      "[179,     1] loss: 0.106\n",
      "[180,     1] loss: 0.105\n",
      "[181,     1] loss: 0.104\n",
      "[182,     1] loss: 0.103\n",
      "[183,     1] loss: 0.102\n",
      "[184,     1] loss: 0.102\n",
      "[185,     1] loss: 0.101\n",
      "[186,     1] loss: 0.100\n",
      "[187,     1] loss: 0.099\n",
      "[188,     1] loss: 0.098\n",
      "[189,     1] loss: 0.097\n",
      "[190,     1] loss: 0.096\n",
      "[191,     1] loss: 0.096\n",
      "[192,     1] loss: 0.095\n",
      "[193,     1] loss: 0.094\n",
      "[194,     1] loss: 0.093\n",
      "[195,     1] loss: 0.093\n",
      "[196,     1] loss: 0.092\n",
      "[197,     1] loss: 0.091\n",
      "[198,     1] loss: 0.090\n",
      "[199,     1] loss: 0.090\n",
      "[200,     1] loss: 0.089\n",
      "[201,     1] loss: 0.088\n",
      "[202,     1] loss: 0.088\n",
      "[203,     1] loss: 0.087\n",
      "[204,     1] loss: 0.086\n",
      "[205,     1] loss: 0.086\n",
      "[206,     1] loss: 0.085\n",
      "[207,     1] loss: 0.084\n",
      "[208,     1] loss: 0.084\n",
      "[209,     1] loss: 0.083\n",
      "[210,     1] loss: 0.082\n",
      "[211,     1] loss: 0.082\n",
      "[212,     1] loss: 0.081\n",
      "[213,     1] loss: 0.081\n",
      "[214,     1] loss: 0.080\n",
      "[215,     1] loss: 0.079\n",
      "[216,     1] loss: 0.079\n",
      "[217,     1] loss: 0.078\n",
      "[218,     1] loss: 0.078\n",
      "[219,     1] loss: 0.077\n",
      "[220,     1] loss: 0.077\n",
      "[221,     1] loss: 0.076\n",
      "[222,     1] loss: 0.076\n",
      "[223,     1] loss: 0.075\n",
      "[224,     1] loss: 0.074\n",
      "[225,     1] loss: 0.074\n",
      "[226,     1] loss: 0.073\n",
      "[227,     1] loss: 0.073\n",
      "[228,     1] loss: 0.072\n",
      "[229,     1] loss: 0.072\n",
      "[230,     1] loss: 0.071\n",
      "[231,     1] loss: 0.071\n",
      "[232,     1] loss: 0.071\n",
      "[233,     1] loss: 0.070\n",
      "[234,     1] loss: 0.070\n",
      "[235,     1] loss: 0.069\n",
      "[236,     1] loss: 0.069\n",
      "[237,     1] loss: 0.068\n",
      "[238,     1] loss: 0.068\n",
      "[239,     1] loss: 0.067\n",
      "[240,     1] loss: 0.067\n",
      "[241,     1] loss: 0.066\n",
      "[242,     1] loss: 0.066\n",
      "[243,     1] loss: 0.066\n",
      "[244,     1] loss: 0.065\n",
      "[245,     1] loss: 0.065\n",
      "[246,     1] loss: 0.064\n",
      "[247,     1] loss: 0.064\n",
      "[248,     1] loss: 0.064\n",
      "[249,     1] loss: 0.063\n",
      "[250,     1] loss: 0.063\n",
      "[251,     1] loss: 0.062\n",
      "[252,     1] loss: 0.062\n",
      "[253,     1] loss: 0.062\n",
      "[254,     1] loss: 0.061\n",
      "[255,     1] loss: 0.061\n",
      "[256,     1] loss: 0.061\n",
      "[257,     1] loss: 0.060\n",
      "[258,     1] loss: 0.060\n",
      "[259,     1] loss: 0.060\n",
      "[260,     1] loss: 0.059\n",
      "[261,     1] loss: 0.059\n",
      "[262,     1] loss: 0.058\n",
      "[263,     1] loss: 0.058\n",
      "[264,     1] loss: 0.058\n",
      "[265,     1] loss: 0.057\n",
      "[266,     1] loss: 0.057\n",
      "[267,     1] loss: 0.057\n",
      "[268,     1] loss: 0.056\n",
      "[269,     1] loss: 0.056\n",
      "[270,     1] loss: 0.056\n",
      "[271,     1] loss: 0.056\n",
      "[272,     1] loss: 0.055\n",
      "[273,     1] loss: 0.055\n",
      "[274,     1] loss: 0.055\n",
      "[275,     1] loss: 0.054\n",
      "[276,     1] loss: 0.054\n",
      "[277,     1] loss: 0.054\n",
      "[278,     1] loss: 0.053\n",
      "[279,     1] loss: 0.053\n",
      "[280,     1] loss: 0.053\n",
      "[281,     1] loss: 0.053\n",
      "[282,     1] loss: 0.052\n",
      "[283,     1] loss: 0.052\n",
      "[284,     1] loss: 0.052\n",
      "[285,     1] loss: 0.051\n",
      "[286,     1] loss: 0.051\n",
      "[287,     1] loss: 0.051\n",
      "[288,     1] loss: 0.051\n",
      "[289,     1] loss: 0.050\n",
      "[290,     1] loss: 0.050\n",
      "[291,     1] loss: 0.050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[292,     1] loss: 0.050\n",
      "[293,     1] loss: 0.049\n",
      "[294,     1] loss: 0.049\n",
      "[295,     1] loss: 0.049\n",
      "[296,     1] loss: 0.049\n",
      "[297,     1] loss: 0.048\n",
      "[298,     1] loss: 0.048\n",
      "[299,     1] loss: 0.048\n",
      "[300,     1] loss: 0.048\n",
      "Finished Training\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Accuracy of the network on the test dataset 1: 35 %\n",
      "Accuracy of the network on the test dataset 2: 56 %\n",
      "Accuracy of the network on the test dataset 3: 95 %\n",
      "Accuracy of the network on the test dataset 4: 100 %\n",
      "Accuracy of the network on the test dataset 5: 100 %\n",
      "Accuracy of the network on the test dataset 6: 100 %\n",
      "Accuracy of the network on the test dataset 7: 100 %\n",
      "Accuracy of the network on the test dataset 8: 100 %\n",
      "Accuracy of the network on the test dataset 9: 100 %\n",
      "Accuracy of the network on the test dataset 10: 100 %\n",
      "Accuracy of the network on the test dataset 11: 100 %\n",
      "Accuracy of the network on the test dataset 12: 35 %\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "training on data set   10\n",
      "[1,     1] loss: 5.415\n",
      "[2,     1] loss: 2.663\n",
      "[3,     1] loss: 2.619\n",
      "[4,     1] loss: 2.575\n",
      "[5,     1] loss: 2.531\n",
      "[6,     1] loss: 2.487\n",
      "[7,     1] loss: 2.444\n",
      "[8,     1] loss: 2.400\n",
      "[9,     1] loss: 2.357\n",
      "[10,     1] loss: 2.315\n",
      "[11,     1] loss: 2.273\n",
      "[12,     1] loss: 2.231\n",
      "[13,     1] loss: 2.189\n",
      "[14,     1] loss: 2.147\n",
      "[15,     1] loss: 2.106\n",
      "[16,     1] loss: 2.065\n",
      "[17,     1] loss: 2.025\n",
      "[18,     1] loss: 1.985\n",
      "[19,     1] loss: 1.945\n",
      "[20,     1] loss: 1.906\n",
      "[21,     1] loss: 1.866\n",
      "[22,     1] loss: 1.828\n",
      "[23,     1] loss: 1.789\n",
      "[24,     1] loss: 1.752\n",
      "[25,     1] loss: 1.714\n",
      "[26,     1] loss: 1.677\n",
      "[27,     1] loss: 1.640\n",
      "[28,     1] loss: 1.604\n",
      "[29,     1] loss: 1.568\n",
      "[30,     1] loss: 1.533\n",
      "[31,     1] loss: 1.498\n",
      "[32,     1] loss: 1.463\n",
      "[33,     1] loss: 1.429\n",
      "[34,     1] loss: 1.396\n",
      "[35,     1] loss: 1.363\n",
      "[36,     1] loss: 1.330\n",
      "[37,     1] loss: 1.298\n",
      "[38,     1] loss: 1.267\n",
      "[39,     1] loss: 1.236\n",
      "[40,     1] loss: 1.206\n",
      "[41,     1] loss: 1.176\n",
      "[42,     1] loss: 1.147\n",
      "[43,     1] loss: 1.118\n",
      "[44,     1] loss: 1.090\n",
      "[45,     1] loss: 1.062\n",
      "[46,     1] loss: 1.035\n",
      "[47,     1] loss: 1.008\n",
      "[48,     1] loss: 0.982\n",
      "[49,     1] loss: 0.957\n",
      "[50,     1] loss: 0.932\n",
      "[51,     1] loss: 0.908\n",
      "[52,     1] loss: 0.884\n",
      "[53,     1] loss: 0.861\n",
      "[54,     1] loss: 0.839\n",
      "[55,     1] loss: 0.817\n",
      "[56,     1] loss: 0.796\n",
      "[57,     1] loss: 0.775\n",
      "[58,     1] loss: 0.755\n",
      "[59,     1] loss: 0.735\n",
      "[60,     1] loss: 0.716\n",
      "[61,     1] loss: 0.698\n",
      "[62,     1] loss: 0.680\n",
      "[63,     1] loss: 0.662\n",
      "[64,     1] loss: 0.645\n",
      "[65,     1] loss: 0.629\n",
      "[66,     1] loss: 0.613\n",
      "[67,     1] loss: 0.597\n",
      "[68,     1] loss: 0.582\n",
      "[69,     1] loss: 0.568\n",
      "[70,     1] loss: 0.554\n",
      "[71,     1] loss: 0.540\n",
      "[72,     1] loss: 0.527\n",
      "[73,     1] loss: 0.514\n",
      "[74,     1] loss: 0.502\n",
      "[75,     1] loss: 0.490\n",
      "[76,     1] loss: 0.478\n",
      "[77,     1] loss: 0.467\n",
      "[78,     1] loss: 0.456\n",
      "[79,     1] loss: 0.445\n",
      "[80,     1] loss: 0.435\n",
      "[81,     1] loss: 0.426\n",
      "[82,     1] loss: 0.416\n",
      "[83,     1] loss: 0.407\n",
      "[84,     1] loss: 0.398\n",
      "[85,     1] loss: 0.389\n",
      "[86,     1] loss: 0.381\n",
      "[87,     1] loss: 0.373\n",
      "[88,     1] loss: 0.365\n",
      "[89,     1] loss: 0.357\n",
      "[90,     1] loss: 0.350\n",
      "[91,     1] loss: 0.343\n",
      "[92,     1] loss: 0.336\n",
      "[93,     1] loss: 0.329\n",
      "[94,     1] loss: 0.323\n",
      "[95,     1] loss: 0.317\n",
      "[96,     1] loss: 0.311\n",
      "[97,     1] loss: 0.305\n",
      "[98,     1] loss: 0.299\n",
      "[99,     1] loss: 0.294\n",
      "[100,     1] loss: 0.288\n",
      "[101,     1] loss: 0.283\n",
      "[102,     1] loss: 0.278\n",
      "[103,     1] loss: 0.273\n",
      "[104,     1] loss: 0.268\n",
      "[105,     1] loss: 0.264\n",
      "[106,     1] loss: 0.259\n",
      "[107,     1] loss: 0.255\n",
      "[108,     1] loss: 0.250\n",
      "[109,     1] loss: 0.246\n",
      "[110,     1] loss: 0.242\n",
      "[111,     1] loss: 0.238\n",
      "[112,     1] loss: 0.235\n",
      "[113,     1] loss: 0.231\n",
      "[114,     1] loss: 0.227\n",
      "[115,     1] loss: 0.224\n",
      "[116,     1] loss: 0.220\n",
      "[117,     1] loss: 0.217\n",
      "[118,     1] loss: 0.214\n",
      "[119,     1] loss: 0.211\n",
      "[120,     1] loss: 0.208\n",
      "[121,     1] loss: 0.205\n",
      "[122,     1] loss: 0.202\n",
      "[123,     1] loss: 0.199\n",
      "[124,     1] loss: 0.196\n",
      "[125,     1] loss: 0.193\n",
      "[126,     1] loss: 0.191\n",
      "[127,     1] loss: 0.188\n",
      "[128,     1] loss: 0.185\n",
      "[129,     1] loss: 0.183\n",
      "[130,     1] loss: 0.181\n",
      "[131,     1] loss: 0.178\n",
      "[132,     1] loss: 0.176\n",
      "[133,     1] loss: 0.174\n",
      "[134,     1] loss: 0.171\n",
      "[135,     1] loss: 0.169\n",
      "[136,     1] loss: 0.167\n",
      "[137,     1] loss: 0.165\n",
      "[138,     1] loss: 0.163\n",
      "[139,     1] loss: 0.161\n",
      "[140,     1] loss: 0.159\n",
      "[141,     1] loss: 0.157\n",
      "[142,     1] loss: 0.155\n",
      "[143,     1] loss: 0.153\n",
      "[144,     1] loss: 0.152\n",
      "[145,     1] loss: 0.150\n",
      "[146,     1] loss: 0.148\n",
      "[147,     1] loss: 0.147\n",
      "[148,     1] loss: 0.145\n",
      "[149,     1] loss: 0.143\n",
      "[150,     1] loss: 0.142\n",
      "[151,     1] loss: 0.140\n",
      "[152,     1] loss: 0.139\n",
      "[153,     1] loss: 0.137\n",
      "[154,     1] loss: 0.136\n",
      "[155,     1] loss: 0.134\n",
      "[156,     1] loss: 0.133\n",
      "[157,     1] loss: 0.131\n",
      "[158,     1] loss: 0.130\n",
      "[159,     1] loss: 0.129\n",
      "[160,     1] loss: 0.127\n",
      "[161,     1] loss: 0.126\n",
      "[162,     1] loss: 0.125\n",
      "[163,     1] loss: 0.124\n",
      "[164,     1] loss: 0.122\n",
      "[165,     1] loss: 0.121\n",
      "[166,     1] loss: 0.120\n",
      "[167,     1] loss: 0.119\n",
      "[168,     1] loss: 0.118\n",
      "[169,     1] loss: 0.116\n",
      "[170,     1] loss: 0.115\n",
      "[171,     1] loss: 0.114\n",
      "[172,     1] loss: 0.113\n",
      "[173,     1] loss: 0.112\n",
      "[174,     1] loss: 0.111\n",
      "[175,     1] loss: 0.110\n",
      "[176,     1] loss: 0.109\n",
      "[177,     1] loss: 0.108\n",
      "[178,     1] loss: 0.107\n",
      "[179,     1] loss: 0.106\n",
      "[180,     1] loss: 0.105\n",
      "[181,     1] loss: 0.104\n",
      "[182,     1] loss: 0.103\n",
      "[183,     1] loss: 0.102\n",
      "[184,     1] loss: 0.102\n",
      "[185,     1] loss: 0.101\n",
      "[186,     1] loss: 0.100\n",
      "[187,     1] loss: 0.099\n",
      "[188,     1] loss: 0.098\n",
      "[189,     1] loss: 0.097\n",
      "[190,     1] loss: 0.096\n",
      "[191,     1] loss: 0.096\n",
      "[192,     1] loss: 0.095\n",
      "[193,     1] loss: 0.094\n",
      "[194,     1] loss: 0.093\n",
      "[195,     1] loss: 0.093\n",
      "[196,     1] loss: 0.092\n",
      "[197,     1] loss: 0.091\n",
      "[198,     1] loss: 0.090\n",
      "[199,     1] loss: 0.090\n",
      "[200,     1] loss: 0.089\n",
      "[201,     1] loss: 0.088\n",
      "[202,     1] loss: 0.088\n",
      "[203,     1] loss: 0.087\n",
      "[204,     1] loss: 0.086\n",
      "[205,     1] loss: 0.086\n",
      "[206,     1] loss: 0.085\n",
      "[207,     1] loss: 0.084\n",
      "[208,     1] loss: 0.084\n",
      "[209,     1] loss: 0.083\n",
      "[210,     1] loss: 0.082\n",
      "[211,     1] loss: 0.082\n",
      "[212,     1] loss: 0.081\n",
      "[213,     1] loss: 0.081\n",
      "[214,     1] loss: 0.080\n",
      "[215,     1] loss: 0.079\n",
      "[216,     1] loss: 0.079\n",
      "[217,     1] loss: 0.078\n",
      "[218,     1] loss: 0.078\n",
      "[219,     1] loss: 0.077\n",
      "[220,     1] loss: 0.077\n",
      "[221,     1] loss: 0.076\n",
      "[222,     1] loss: 0.076\n",
      "[223,     1] loss: 0.075\n",
      "[224,     1] loss: 0.074\n",
      "[225,     1] loss: 0.074\n",
      "[226,     1] loss: 0.073\n",
      "[227,     1] loss: 0.073\n",
      "[228,     1] loss: 0.072\n",
      "[229,     1] loss: 0.072\n",
      "[230,     1] loss: 0.071\n",
      "[231,     1] loss: 0.071\n",
      "[232,     1] loss: 0.071\n",
      "[233,     1] loss: 0.070\n",
      "[234,     1] loss: 0.070\n",
      "[235,     1] loss: 0.069\n",
      "[236,     1] loss: 0.069\n",
      "[237,     1] loss: 0.068\n",
      "[238,     1] loss: 0.068\n",
      "[239,     1] loss: 0.067\n",
      "[240,     1] loss: 0.067\n",
      "[241,     1] loss: 0.066\n",
      "[242,     1] loss: 0.066\n",
      "[243,     1] loss: 0.066\n",
      "[244,     1] loss: 0.065\n",
      "[245,     1] loss: 0.065\n",
      "[246,     1] loss: 0.064\n",
      "[247,     1] loss: 0.064\n",
      "[248,     1] loss: 0.064\n",
      "[249,     1] loss: 0.063\n",
      "[250,     1] loss: 0.063\n",
      "[251,     1] loss: 0.062\n",
      "[252,     1] loss: 0.062\n",
      "[253,     1] loss: 0.062\n",
      "[254,     1] loss: 0.061\n",
      "[255,     1] loss: 0.061\n",
      "[256,     1] loss: 0.061\n",
      "[257,     1] loss: 0.060\n",
      "[258,     1] loss: 0.060\n",
      "[259,     1] loss: 0.060\n",
      "[260,     1] loss: 0.059\n",
      "[261,     1] loss: 0.059\n",
      "[262,     1] loss: 0.058\n",
      "[263,     1] loss: 0.058\n",
      "[264,     1] loss: 0.058\n",
      "[265,     1] loss: 0.057\n",
      "[266,     1] loss: 0.057\n",
      "[267,     1] loss: 0.057\n",
      "[268,     1] loss: 0.056\n",
      "[269,     1] loss: 0.056\n",
      "[270,     1] loss: 0.056\n",
      "[271,     1] loss: 0.056\n",
      "[272,     1] loss: 0.055\n",
      "[273,     1] loss: 0.055\n",
      "[274,     1] loss: 0.055\n",
      "[275,     1] loss: 0.054\n",
      "[276,     1] loss: 0.054\n",
      "[277,     1] loss: 0.054\n",
      "[278,     1] loss: 0.053\n",
      "[279,     1] loss: 0.053\n",
      "[280,     1] loss: 0.053\n",
      "[281,     1] loss: 0.053\n",
      "[282,     1] loss: 0.052\n",
      "[283,     1] loss: 0.052\n",
      "[284,     1] loss: 0.052\n",
      "[285,     1] loss: 0.051\n",
      "[286,     1] loss: 0.051\n",
      "[287,     1] loss: 0.051\n",
      "[288,     1] loss: 0.051\n",
      "[289,     1] loss: 0.050\n",
      "[290,     1] loss: 0.050\n",
      "[291,     1] loss: 0.050\n",
      "[292,     1] loss: 0.050\n",
      "[293,     1] loss: 0.049\n",
      "[294,     1] loss: 0.049\n",
      "[295,     1] loss: 0.049\n",
      "[296,     1] loss: 0.049\n",
      "[297,     1] loss: 0.048\n",
      "[298,     1] loss: 0.048\n",
      "[299,     1] loss: 0.048\n",
      "[300,     1] loss: 0.048\n",
      "Finished Training\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Accuracy of the network on the test dataset 1: 35 %\n",
      "Accuracy of the network on the test dataset 2: 56 %\n",
      "Accuracy of the network on the test dataset 3: 95 %\n",
      "Accuracy of the network on the test dataset 4: 100 %\n",
      "Accuracy of the network on the test dataset 5: 100 %\n",
      "Accuracy of the network on the test dataset 6: 100 %\n",
      "Accuracy of the network on the test dataset 7: 100 %\n",
      "Accuracy of the network on the test dataset 8: 100 %\n",
      "Accuracy of the network on the test dataset 9: 100 %\n",
      "Accuracy of the network on the test dataset 10: 100 %\n",
      "Accuracy of the network on the test dataset 11: 100 %\n",
      "Accuracy of the network on the test dataset 12: 35 %\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "training on data set   11\n",
      "[1,     1] loss: 6.392\n",
      "[2,     1] loss: 3.140\n",
      "[3,     1] loss: 3.083\n",
      "[4,     1] loss: 3.027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,     1] loss: 2.972\n",
      "[6,     1] loss: 2.916\n",
      "[7,     1] loss: 2.861\n",
      "[8,     1] loss: 2.807\n",
      "[9,     1] loss: 2.753\n",
      "[10,     1] loss: 2.699\n",
      "[11,     1] loss: 2.645\n",
      "[12,     1] loss: 2.592\n",
      "[13,     1] loss: 2.539\n",
      "[14,     1] loss: 2.487\n",
      "[15,     1] loss: 2.435\n",
      "[16,     1] loss: 2.383\n",
      "[17,     1] loss: 2.332\n",
      "[18,     1] loss: 2.281\n",
      "[19,     1] loss: 2.231\n",
      "[20,     1] loss: 2.181\n",
      "[21,     1] loss: 2.131\n",
      "[22,     1] loss: 2.082\n",
      "[23,     1] loss: 2.034\n",
      "[24,     1] loss: 1.986\n",
      "[25,     1] loss: 1.938\n",
      "[26,     1] loss: 1.891\n",
      "[27,     1] loss: 1.844\n",
      "[28,     1] loss: 1.798\n",
      "[29,     1] loss: 1.752\n",
      "[30,     1] loss: 1.707\n",
      "[31,     1] loss: 1.663\n",
      "[32,     1] loss: 1.619\n",
      "[33,     1] loss: 1.576\n",
      "[34,     1] loss: 1.533\n",
      "[35,     1] loss: 1.491\n",
      "[36,     1] loss: 1.450\n",
      "[37,     1] loss: 1.409\n",
      "[38,     1] loss: 1.369\n",
      "[39,     1] loss: 1.330\n",
      "[40,     1] loss: 1.291\n",
      "[41,     1] loss: 1.253\n",
      "[42,     1] loss: 1.216\n",
      "[43,     1] loss: 1.180\n",
      "[44,     1] loss: 1.144\n",
      "[45,     1] loss: 1.109\n",
      "[46,     1] loss: 1.075\n",
      "[47,     1] loss: 1.042\n",
      "[48,     1] loss: 1.010\n",
      "[49,     1] loss: 0.978\n",
      "[50,     1] loss: 0.947\n",
      "[51,     1] loss: 0.917\n",
      "[52,     1] loss: 0.888\n",
      "[53,     1] loss: 0.860\n",
      "[54,     1] loss: 0.832\n",
      "[55,     1] loss: 0.806\n",
      "[56,     1] loss: 0.780\n",
      "[57,     1] loss: 0.755\n",
      "[58,     1] loss: 0.731\n",
      "[59,     1] loss: 0.707\n",
      "[60,     1] loss: 0.685\n",
      "[61,     1] loss: 0.663\n",
      "[62,     1] loss: 0.642\n",
      "[63,     1] loss: 0.622\n",
      "[64,     1] loss: 0.602\n",
      "[65,     1] loss: 0.583\n",
      "[66,     1] loss: 0.565\n",
      "[67,     1] loss: 0.548\n",
      "[68,     1] loss: 0.531\n",
      "[69,     1] loss: 0.515\n",
      "[70,     1] loss: 0.499\n",
      "[71,     1] loss: 0.485\n",
      "[72,     1] loss: 0.470\n",
      "[73,     1] loss: 0.457\n",
      "[74,     1] loss: 0.443\n",
      "[75,     1] loss: 0.431\n",
      "[76,     1] loss: 0.419\n",
      "[77,     1] loss: 0.407\n",
      "[78,     1] loss: 0.396\n",
      "[79,     1] loss: 0.385\n",
      "[80,     1] loss: 0.375\n",
      "[81,     1] loss: 0.365\n",
      "[82,     1] loss: 0.355\n",
      "[83,     1] loss: 0.346\n",
      "[84,     1] loss: 0.337\n",
      "[85,     1] loss: 0.329\n",
      "[86,     1] loss: 0.321\n",
      "[87,     1] loss: 0.313\n",
      "[88,     1] loss: 0.306\n",
      "[89,     1] loss: 0.298\n",
      "[90,     1] loss: 0.292\n",
      "[91,     1] loss: 0.285\n",
      "[92,     1] loss: 0.278\n",
      "[93,     1] loss: 0.272\n",
      "[94,     1] loss: 0.266\n",
      "[95,     1] loss: 0.261\n",
      "[96,     1] loss: 0.255\n",
      "[97,     1] loss: 0.250\n",
      "[98,     1] loss: 0.245\n",
      "[99,     1] loss: 0.240\n",
      "[100,     1] loss: 0.235\n",
      "[101,     1] loss: 0.230\n",
      "[102,     1] loss: 0.226\n",
      "[103,     1] loss: 0.221\n",
      "[104,     1] loss: 0.217\n",
      "[105,     1] loss: 0.213\n",
      "[106,     1] loss: 0.209\n",
      "[107,     1] loss: 0.205\n",
      "[108,     1] loss: 0.202\n",
      "[109,     1] loss: 0.198\n",
      "[110,     1] loss: 0.195\n",
      "[111,     1] loss: 0.191\n",
      "[112,     1] loss: 0.188\n",
      "[113,     1] loss: 0.185\n",
      "[114,     1] loss: 0.182\n",
      "[115,     1] loss: 0.179\n",
      "[116,     1] loss: 0.176\n",
      "[117,     1] loss: 0.173\n",
      "[118,     1] loss: 0.171\n",
      "[119,     1] loss: 0.168\n",
      "[120,     1] loss: 0.165\n",
      "[121,     1] loss: 0.163\n",
      "[122,     1] loss: 0.160\n",
      "[123,     1] loss: 0.158\n",
      "[124,     1] loss: 0.156\n",
      "[125,     1] loss: 0.153\n",
      "[126,     1] loss: 0.151\n",
      "[127,     1] loss: 0.149\n",
      "[128,     1] loss: 0.147\n",
      "[129,     1] loss: 0.145\n",
      "[130,     1] loss: 0.143\n",
      "[131,     1] loss: 0.141\n",
      "[132,     1] loss: 0.139\n",
      "[133,     1] loss: 0.137\n",
      "[134,     1] loss: 0.136\n",
      "[135,     1] loss: 0.134\n",
      "[136,     1] loss: 0.132\n",
      "[137,     1] loss: 0.130\n",
      "[138,     1] loss: 0.129\n",
      "[139,     1] loss: 0.127\n",
      "[140,     1] loss: 0.126\n",
      "[141,     1] loss: 0.124\n",
      "[142,     1] loss: 0.123\n",
      "[143,     1] loss: 0.121\n",
      "[144,     1] loss: 0.120\n",
      "[145,     1] loss: 0.118\n",
      "[146,     1] loss: 0.117\n",
      "[147,     1] loss: 0.116\n",
      "[148,     1] loss: 0.114\n",
      "[149,     1] loss: 0.113\n",
      "[150,     1] loss: 0.112\n",
      "[151,     1] loss: 0.110\n",
      "[152,     1] loss: 0.109\n",
      "[153,     1] loss: 0.108\n",
      "[154,     1] loss: 0.107\n",
      "[155,     1] loss: 0.106\n",
      "[156,     1] loss: 0.105\n",
      "[157,     1] loss: 0.103\n",
      "[158,     1] loss: 0.102\n",
      "[159,     1] loss: 0.101\n",
      "[160,     1] loss: 0.100\n",
      "[161,     1] loss: 0.099\n",
      "[162,     1] loss: 0.098\n",
      "[163,     1] loss: 0.097\n",
      "[164,     1] loss: 0.096\n",
      "[165,     1] loss: 0.095\n",
      "[166,     1] loss: 0.094\n",
      "[167,     1] loss: 0.093\n",
      "[168,     1] loss: 0.092\n",
      "[169,     1] loss: 0.092\n",
      "[170,     1] loss: 0.091\n",
      "[171,     1] loss: 0.090\n",
      "[172,     1] loss: 0.089\n",
      "[173,     1] loss: 0.088\n",
      "[174,     1] loss: 0.087\n",
      "[175,     1] loss: 0.087\n",
      "[176,     1] loss: 0.086\n",
      "[177,     1] loss: 0.085\n",
      "[178,     1] loss: 0.084\n",
      "[179,     1] loss: 0.083\n",
      "[180,     1] loss: 0.083\n",
      "[181,     1] loss: 0.082\n",
      "[182,     1] loss: 0.081\n",
      "[183,     1] loss: 0.081\n",
      "[184,     1] loss: 0.080\n",
      "[185,     1] loss: 0.079\n",
      "[186,     1] loss: 0.078\n",
      "[187,     1] loss: 0.078\n",
      "[188,     1] loss: 0.077\n",
      "[189,     1] loss: 0.076\n",
      "[190,     1] loss: 0.076\n",
      "[191,     1] loss: 0.075\n",
      "[192,     1] loss: 0.075\n",
      "[193,     1] loss: 0.074\n",
      "[194,     1] loss: 0.073\n",
      "[195,     1] loss: 0.073\n",
      "[196,     1] loss: 0.072\n",
      "[197,     1] loss: 0.072\n",
      "[198,     1] loss: 0.071\n",
      "[199,     1] loss: 0.070\n",
      "[200,     1] loss: 0.070\n",
      "[201,     1] loss: 0.069\n",
      "[202,     1] loss: 0.069\n",
      "[203,     1] loss: 0.068\n",
      "[204,     1] loss: 0.068\n",
      "[205,     1] loss: 0.067\n",
      "[206,     1] loss: 0.067\n",
      "[207,     1] loss: 0.066\n",
      "[208,     1] loss: 0.066\n",
      "[209,     1] loss: 0.065\n",
      "[210,     1] loss: 0.065\n",
      "[211,     1] loss: 0.064\n",
      "[212,     1] loss: 0.064\n",
      "[213,     1] loss: 0.063\n",
      "[214,     1] loss: 0.063\n",
      "[215,     1] loss: 0.062\n",
      "[216,     1] loss: 0.062\n",
      "[217,     1] loss: 0.061\n",
      "[218,     1] loss: 0.061\n",
      "[219,     1] loss: 0.061\n",
      "[220,     1] loss: 0.060\n",
      "[221,     1] loss: 0.060\n",
      "[222,     1] loss: 0.059\n",
      "[223,     1] loss: 0.059\n",
      "[224,     1] loss: 0.059\n",
      "[225,     1] loss: 0.058\n",
      "[226,     1] loss: 0.058\n",
      "[227,     1] loss: 0.057\n",
      "[228,     1] loss: 0.057\n",
      "[229,     1] loss: 0.057\n",
      "[230,     1] loss: 0.056\n",
      "[231,     1] loss: 0.056\n",
      "[232,     1] loss: 0.055\n",
      "[233,     1] loss: 0.055\n",
      "[234,     1] loss: 0.055\n",
      "[235,     1] loss: 0.054\n",
      "[236,     1] loss: 0.054\n",
      "[237,     1] loss: 0.054\n",
      "[238,     1] loss: 0.053\n",
      "[239,     1] loss: 0.053\n",
      "[240,     1] loss: 0.053\n",
      "[241,     1] loss: 0.052\n",
      "[242,     1] loss: 0.052\n",
      "[243,     1] loss: 0.052\n",
      "[244,     1] loss: 0.051\n",
      "[245,     1] loss: 0.051\n",
      "[246,     1] loss: 0.051\n",
      "[247,     1] loss: 0.050\n",
      "[248,     1] loss: 0.050\n",
      "[249,     1] loss: 0.050\n",
      "[250,     1] loss: 0.049\n",
      "[251,     1] loss: 0.049\n",
      "[252,     1] loss: 0.049\n",
      "[253,     1] loss: 0.048\n",
      "[254,     1] loss: 0.048\n",
      "[255,     1] loss: 0.048\n",
      "[256,     1] loss: 0.048\n",
      "[257,     1] loss: 0.047\n",
      "[258,     1] loss: 0.047\n",
      "[259,     1] loss: 0.047\n",
      "[260,     1] loss: 0.046\n",
      "[261,     1] loss: 0.046\n",
      "[262,     1] loss: 0.046\n",
      "[263,     1] loss: 0.046\n",
      "[264,     1] loss: 0.045\n",
      "[265,     1] loss: 0.045\n",
      "[266,     1] loss: 0.045\n",
      "[267,     1] loss: 0.045\n",
      "[268,     1] loss: 0.044\n",
      "[269,     1] loss: 0.044\n",
      "[270,     1] loss: 0.044\n",
      "[271,     1] loss: 0.044\n",
      "[272,     1] loss: 0.043\n",
      "[273,     1] loss: 0.043\n",
      "[274,     1] loss: 0.043\n",
      "[275,     1] loss: 0.043\n",
      "[276,     1] loss: 0.042\n",
      "[277,     1] loss: 0.042\n",
      "[278,     1] loss: 0.042\n",
      "[279,     1] loss: 0.042\n",
      "[280,     1] loss: 0.042\n",
      "[281,     1] loss: 0.041\n",
      "[282,     1] loss: 0.041\n",
      "[283,     1] loss: 0.041\n",
      "[284,     1] loss: 0.041\n",
      "[285,     1] loss: 0.040\n",
      "[286,     1] loss: 0.040\n",
      "[287,     1] loss: 0.040\n",
      "[288,     1] loss: 0.040\n",
      "[289,     1] loss: 0.040\n",
      "[290,     1] loss: 0.039\n",
      "[291,     1] loss: 0.039\n",
      "[292,     1] loss: 0.039\n",
      "[293,     1] loss: 0.039\n",
      "[294,     1] loss: 0.039\n",
      "[295,     1] loss: 0.038\n",
      "[296,     1] loss: 0.038\n",
      "[297,     1] loss: 0.038\n",
      "[298,     1] loss: 0.038\n",
      "[299,     1] loss: 0.038\n",
      "[300,     1] loss: 0.037\n",
      "Finished Training\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Accuracy of the network on the test dataset 1: 35 %\n",
      "Accuracy of the network on the test dataset 2: 37 %\n",
      "Accuracy of the network on the test dataset 3: 83 %\n",
      "Accuracy of the network on the test dataset 4: 97 %\n",
      "Accuracy of the network on the test dataset 5: 100 %\n",
      "Accuracy of the network on the test dataset 6: 100 %\n",
      "Accuracy of the network on the test dataset 7: 100 %\n",
      "Accuracy of the network on the test dataset 8: 100 %\n",
      "Accuracy of the network on the test dataset 9: 100 %\n",
      "Accuracy of the network on the test dataset 10: 100 %\n",
      "Accuracy of the network on the test dataset 11: 100 %\n",
      "Accuracy of the network on the test dataset 12: 35 %\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_loss_all=[]\n",
    "\n",
    "testloader_list= [ testloader_1, testloader_2, testloader_3, testloader_4, testloader_5, testloader_6,\n",
    "                 testloader_7, testloader_8, testloader_9, testloader_10,testloader_11,testloader_12]\n",
    "\n",
    "train_loss_all.append(train_all(trainloader_1, 1, testloader_list))\n",
    "train_loss_all.append(train_all(trainloader_2, 2, testloader_list))\n",
    "train_loss_all.append(train_all(trainloader_3, 3, testloader_list))\n",
    "train_loss_all.append(train_all(trainloader_4, 4, testloader_list))\n",
    "train_loss_all.append(train_all(trainloader_5, 5, testloader_list))\n",
    "train_loss_all.append(train_all(trainloader_6, 6, testloader_list))\n",
    "train_loss_all.append(train_all(trainloader_7, 7, testloader_list))\n",
    "train_loss_all.append(train_all(trainloader_8, 8, testloader_list))\n",
    "train_loss_all.append(train_all(trainloader_9, 9, testloader_list))\n",
    "train_loss_all.append(train_all(trainloader_10, 10, testloader_list))\n",
    "train_loss_all.append(train_all(trainloader_11, 11, testloader_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "ouG97JyQfnVX",
    "outputId": "e08b29c7-1295-4854-853a-21bd3ec5cef4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14ec5d130>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = plt.get_cmap('turbo')\n",
    "fig = plt.figure(figsize=(6,8))\n",
    "for i,j in enumerate(train_loss_all):\n",
    "    plt.plot(j,label =\"dataset \"+str(i+1),color = cm(i*20))\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training_loss\")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-DhO1NneYOf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CIN_dataset_3_m_500_size_2000_linear.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
