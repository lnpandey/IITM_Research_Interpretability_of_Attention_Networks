{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1634805014692,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "0vlCAi2JLSzD"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1634805014693,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "PiPNZm1iTgHy"
   },
   "outputs": [],
   "source": [
    "# path=\"/content/drive/MyDrive/Research/Hard_Attention/dataset_2/m_5_size_100/run_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1634805014693,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "SrZgZMlK-GDe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25004,
     "status": "ok",
     "timestamp": 1634805039693,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "N2_J4Rw2r0SQ",
    "outputId": "2e9af1d0-7605-4b70-90f7-1c488bee5e7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm as tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1947,
     "status": "ok",
     "timestamp": 1634805041636,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "-Dmy2iPWlgnc"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/hard_attention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6fjud_Fr0Sa"
   },
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1634805041640,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "CqdXHO0Cr0Sd",
    "outputId": "55a65df0-b570-448e-9841-e0bf957827c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 500\n",
      "1 500\n",
      "2 500\n",
      "3 500\n",
      "4 500\n",
      "5 500\n",
      "6 500\n",
      "7 500\n",
      "8 500\n",
      "9 500\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "y = np.concatenate((np.zeros(500),np.ones(500),np.ones(500)*2,np.ones(500)*3,np.ones(500)*4,\n",
    "                    np.ones(500)*5,np.ones(500)*6,np.ones(500)*7,np.ones(500)*8,np.ones(500)*9))\n",
    "#y = np.random.randint(0,3,6000)\n",
    "idx= []\n",
    "for i in range(10):\n",
    "    print(i,sum(y==i))\n",
    "    idx.append(y==i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1634805041640,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "ddhXyODwr0Sk"
   },
   "outputs": [],
   "source": [
    "x = np.zeros((5000,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1634805041641,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "DyV3N2DIr0Sp"
   },
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "x[idx[0],:] = np.random.multivariate_normal(mean = [4,6.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[0]))\n",
    "x[idx[1],:] = np.random.multivariate_normal(mean = [5.5,6],cov=[[0.01,0],[0,0.01]],size=sum(idx[1]))\n",
    "x[idx[2],:] = np.random.multivariate_normal(mean = [4.5,4.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[2]))\n",
    "x[idx[3],:] = np.random.multivariate_normal(mean = [3,3.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[3]))\n",
    "x[idx[4],:] = np.random.multivariate_normal(mean = [2.5,5.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[4]))\n",
    "x[idx[5],:] = np.random.multivariate_normal(mean = [3.5,8],cov=[[0.01,0],[0,0.01]],size=sum(idx[5]))\n",
    "x[idx[6],:] = np.random.multivariate_normal(mean = [5.5,8],cov=[[0.01,0],[0,0.01]],size=sum(idx[6]))\n",
    "x[idx[7],:] = np.random.multivariate_normal(mean = [7,6.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[7]))\n",
    "x[idx[8],:] = np.random.multivariate_normal(mean = [6.5,4.5],cov=[[0.01,0],[0,0.01]],size=sum(idx[8]))\n",
    "x[idx[9],:] = np.random.multivariate_normal(mean = [5,3],cov=[[0.01,0],[0,0.01]],size=sum(idx[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1634805041641,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "qh1mDScsU07I",
    "outputId": "14b6ce5c-fcd4-4198-810d-38613282dcd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.04729858, 6.43185741]), array([4.53008447, 4.5079931 ]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[idx[0]][0], x[idx[2]][5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1634805041641,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "9Vr5ErQ_wSrV",
    "outputId": "54cde011-53f2-4947-9ec6-b4ca2a0d2d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1634805041642,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "NG-3RpffwU_i"
   },
   "outputs": [],
   "source": [
    "idx= []\n",
    "for i in range(10):\n",
    "  idx.append(y==i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 1108,
     "status": "ok",
     "timestamp": 1634805042742,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "hJ8Jm7YUr0St",
    "outputId": "2cda1a1f-c910-460b-a9ae-4c7250d613aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2890bbfa0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(x[idx[i],0],x[idx[i],1],label=\"class_\"+str(i))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1634805042743,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "fNWgnhUJnWLV"
   },
   "outputs": [],
   "source": [
    "x = ( x -  np.mean(x,axis=0,keepdims=True) ) / np.std(x,axis=0,keepdims=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1634805042743,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "8-VLhUfDDeHt",
    "outputId": "328bf955-e35c-47bd-ca8a-a2290ac75781"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28a3dc400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.scatter(x[idx[i],0],x[idx[i],1],label=\"class_\"+str(i))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1634805042744,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "UfFHcZJOr0Sz"
   },
   "outputs": [],
   "source": [
    "foreground_classes = {'class_0','class_1' }\n",
    "\n",
    "background_classes = {'bg_classes',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 804,
     "status": "ok",
     "timestamp": 1634805043528,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "jqbvfbwVr0TN",
    "outputId": "dc7be6e6-3b9c-4ecd-e5d2-2872d09d0738"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1500/1500 [00:02<00:00, 647.36it/s]\n"
     ]
    }
   ],
   "source": [
    "desired_num = 1500\n",
    "mosaic_list_of_images =[]\n",
    "mosaic_label = []\n",
    "fore_idx=[]\n",
    "m = 100\n",
    "for j in tqdm(range(desired_num)):\n",
    "    np.random.seed(j)\n",
    "    fg_class  = np.random.randint(0,3)\n",
    "    fg_idx = np.random.randint(0,m)\n",
    "    a = []\n",
    "    for i in range(m):\n",
    "        if i == fg_idx:\n",
    "            b = np.random.choice(np.where(idx[fg_class]==True)[0],size=1)\n",
    "            a.append(x[b])\n",
    "#             print(\"foreground \"+str(fg_class)+\" present at \" + str(fg_idx))\n",
    "        else:\n",
    "            bg_class = np.random.randint(3,10)\n",
    "            b = np.random.choice(np.where(idx[bg_class]==True)[0],size=1)\n",
    "            a.append(x[b])\n",
    "#             print(\"background \"+str(bg_class)+\" present at \" + str(i))\n",
    "    a = np.concatenate(a,axis=0)\n",
    "    mosaic_list_of_images.append(np.reshape(a,(m,2)))\n",
    "    mosaic_label.append(fg_class)\n",
    "    fore_idx.append(fg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1634805043529,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "BOsFmWfMr0TR"
   },
   "outputs": [],
   "source": [
    "# mosaic_list_of_images = np.concatenate(mosaic_list_of_images,axis=1).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634805043529,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "2aIPMgLXNiXW",
    "outputId": "2ceefa71-71ba-4d90-f0de-75e5673f7cd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,\n",
       " array([[ 1.41860713, -0.6338838 ],\n",
       "        [ 0.60177752,  1.40622261],\n",
       "        [ 0.64672986,  1.41882828],\n",
       "        [-1.69776679, -0.08130752],\n",
       "        [ 1.27946811, -0.71643805],\n",
       "        [ 1.45704   ,  0.60485745],\n",
       "        [ 0.18423713, -1.55664656],\n",
       "        [-1.22655811, -1.21367441],\n",
       "        [-0.91172816,  1.57430636],\n",
       "        [ 0.15127428, -1.62296362],\n",
       "        [ 0.1344424 , -1.55689301],\n",
       "        [-1.69472731, -0.13317729],\n",
       "        [-1.48633975, -0.11413025],\n",
       "        [-1.28089583, -1.35206685],\n",
       "        [ 1.65185875,  0.62351016],\n",
       "        [-1.15951149, -1.22729989],\n",
       "        [ 1.38896738, -0.56645068],\n",
       "        [-1.18761801, -1.25787568],\n",
       "        [ 0.61278208,  1.60577174],\n",
       "        [-1.69274759, -0.07362477],\n",
       "        [ 1.39540616, -0.70341419],\n",
       "        [ 0.6484437 ,  1.36911164],\n",
       "        [-1.19959749, -1.37680104],\n",
       "        [-1.64713463, -0.03977351],\n",
       "        [-1.28776671, -1.24072576],\n",
       "        [-0.91020867,  1.53719333],\n",
       "        [ 0.61165152,  1.3779105 ],\n",
       "        [-0.84921877,  1.54958677],\n",
       "        [ 1.66187652,  0.55663566],\n",
       "        [-1.21920526, -1.37879562],\n",
       "        [ 1.68270895,  0.56733039],\n",
       "        [ 1.31045949, -0.70408025],\n",
       "        [-1.14817234, -1.25084758],\n",
       "        [-1.71088451, -0.04830865],\n",
       "        [ 1.62270482,  0.51768303],\n",
       "        [-0.81087159,  1.53322431],\n",
       "        [-1.27069138, -1.30609293],\n",
       "        [-1.69914455, -0.16147701],\n",
       "        [-1.65628865, -0.02423347],\n",
       "        [ 0.60460631,  1.44797892],\n",
       "        [ 0.58236704,  1.54894797],\n",
       "        [-0.75807128,  1.49637913],\n",
       "        [-1.28724192, -1.24386289],\n",
       "        [ 0.50158931,  1.43804287],\n",
       "        [ 1.60446175,  0.54857951],\n",
       "        [-0.73901596,  1.4622779 ],\n",
       "        [ 0.54263288,  1.44790818],\n",
       "        [-0.49505214,  0.60082382],\n",
       "        [ 1.71498428,  0.59954835],\n",
       "        [ 1.43641796,  0.45305328],\n",
       "        [ 1.55656178,  0.54573264],\n",
       "        [ 1.602678  ,  0.58268934],\n",
       "        [ 0.33530206, -1.52692569],\n",
       "        [ 1.79593358,  0.59840443],\n",
       "        [-0.80669488,  1.49720238],\n",
       "        [ 1.33428603, -0.65794801],\n",
       "        [ 1.27575595, -0.58010711],\n",
       "        [-1.44928269, -0.21540968],\n",
       "        [-1.62968697, -0.05435677],\n",
       "        [-1.14705658, -1.32173496],\n",
       "        [ 1.26347519, -0.67608686],\n",
       "        [-1.22613356, -1.23095984],\n",
       "        [-0.9408243 ,  1.49533605],\n",
       "        [-0.85868868,  1.45722051],\n",
       "        [ 1.22226935, -0.73183849],\n",
       "        [-1.0063457 ,  1.49934918],\n",
       "        [ 1.30597669, -0.69626665],\n",
       "        [ 1.26087483, -0.71083003],\n",
       "        [-1.18691723, -1.13322982],\n",
       "        [-0.76520942,  1.48175297],\n",
       "        [-0.83556166,  1.46827423],\n",
       "        [ 0.58276434,  1.50428082],\n",
       "        [-1.6086103 , -0.06712453],\n",
       "        [ 0.31810705, -1.61167082],\n",
       "        [ 0.09632852, -1.63056099],\n",
       "        [ 0.64150161,  1.40909262],\n",
       "        [ 0.09309813, -1.6306057 ],\n",
       "        [ 1.66239728,  0.59086736],\n",
       "        [-0.7828917 ,  1.46492326],\n",
       "        [ 0.2534351 , -1.61532233],\n",
       "        [-0.91172816,  1.57430636],\n",
       "        [ 1.63154468,  0.61032896],\n",
       "        [ 0.35113688, -1.57927957],\n",
       "        [-1.14814207, -1.32320798],\n",
       "        [-0.83193521,  1.29685967],\n",
       "        [-1.1908979 , -1.29775027],\n",
       "        [ 0.23826136, -1.5664998 ],\n",
       "        [ 0.21538706, -1.71336868],\n",
       "        [ 0.28184423, -1.5868274 ],\n",
       "        [ 0.64181542,  1.47919748],\n",
       "        [ 1.602678  ,  0.58268934],\n",
       "        [ 1.2015697 , -0.68408351],\n",
       "        [-1.15822387, -1.22934664],\n",
       "        [-0.85719594,  1.48370672],\n",
       "        [ 0.22408263, -1.58458172],\n",
       "        [ 0.56915048,  1.44188275],\n",
       "        [-1.20710459, -1.25338625],\n",
       "        [-1.33011081, -1.3672702 ],\n",
       "        [-1.2898084 , -1.34407395],\n",
       "        [-0.6872284 ,  1.44944975]]),\n",
       " (100, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mosaic_list_of_images), mosaic_list_of_images[0],mosaic_list_of_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1634805043529,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "iPoIwbMHx44n"
   },
   "outputs": [],
   "source": [
    "class MosaicDataset(Dataset):\n",
    "  \"\"\"MosaicDataset dataset.\"\"\"\n",
    "\n",
    "  def __init__(self, mosaic_list_of_images, mosaic_label, fore_idx):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "        csv_file (string): Path to the csv file with annotations.\n",
    "        root_dir (string): Directory with all the images.\n",
    "        transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "    \"\"\"\n",
    "    self.mosaic = mosaic_list_of_images\n",
    "    self.label = mosaic_label\n",
    "    self.fore_idx = fore_idx\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.label)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.mosaic[idx] , self.label[idx], self.fore_idx[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1634805043530,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "fOPAJQJeW8Ah"
   },
   "outputs": [],
   "source": [
    "batch = 50\n",
    "msd1 = MosaicDataset(mosaic_list_of_images[0:500], mosaic_label[0:500] , fore_idx[0:500])\n",
    "train_loader = DataLoader( msd1 ,batch_size= batch ,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1634805043530,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "aWBIcyvGApLt"
   },
   "outputs": [],
   "source": [
    "data,_,_=iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1634805043530,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "cauJIvKEAxKM",
    "outputId": "c0b5ce01-f4e6-4a17-946d-9d3036719125"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 100, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634805043531,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "qjNiQgxZW8bA"
   },
   "outputs": [],
   "source": [
    "batch = 250\n",
    "msd2 = MosaicDataset(mosaic_list_of_images[500:], mosaic_label[500:] , fore_idx[500:])\n",
    "test_loader = DataLoader( msd2 ,batch_size= batch ,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634805043531,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "yda1E5ApiKpH"
   },
   "outputs": [],
   "source": [
    "class Focus(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Focus, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,50, bias=False)\n",
    "        self.fc2 = nn.Linear(50,1,bias=False)\n",
    "        torch.nn.init.xavier_normal_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_normal_(self.fc2.weight)\n",
    "        #self.fc2 = nn.Linear(64, 1, bias=False)\n",
    "        #torch.nn.init.xavier_normal_(self.fc2.weight)\n",
    "\n",
    "    def forward(self,z):\n",
    "        #print(\"data\",z)\n",
    "        batch = z.size(0)\n",
    "        patches = z.size(1)\n",
    "        z = z.view(batch,patches,2*1)\n",
    "        alp1,ft1 = self.helper(z)\n",
    "\n",
    "        alpha = F.softmax(alp1,dim=1)\n",
    "        #print(self.training)\n",
    "        \n",
    "        if self.training:\n",
    "            alpha =alpha[:,:,0]\n",
    "            y = ft1 \n",
    "            return alpha,y\n",
    "        else:\n",
    "            #alpha_cumsum = torch.cumsum(alpha, dim = 1)\n",
    "            #print(alpha_cumsum)\n",
    "            #len_batch = alpha_cumsum.size(0)\n",
    "            #patches = alpha_cumsum.size(1)\n",
    "            #rand_prob = torch.rand(len_batch,patches, 1).to(device)\n",
    "            #alpha_relu = F.relu(rand_prob-alpha_cumsum)\n",
    "            #print(alpha_relu)\n",
    "            #alpha_index = torch.count_nonzero(alpha_relu,dim=1)\n",
    "            #alpha_hard = F.one_hot(alpha_index,num_classes=patches)\n",
    "            #print(alpha_hard)\n",
    "            #alpha_hard = torch.transpose(alpha_hard,dim0=1,dim1=2)\n",
    "            #print(ft1,\"alpha_hard\",alpha_hard) \n",
    "            #y = torch.sum(alpha_hard*ft1,dim=1)\n",
    "            #print(alpha,alpha.shape)\n",
    "         \n",
    "        \n",
    "            index = torch.argmax(alpha,dim=1)\n",
    "            hard_alpha = torch.nn.functional.one_hot(index[:,0], patches)\n",
    "            y = torch.sum(hard_alpha[:,:,None]*ft1,dim=1)\n",
    "            alpha = alpha[:,:,0]\n",
    "            return alpha,y\n",
    "    \n",
    "    def helper(self, x):\n",
    "        x1 = x\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x,x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1634805043531,
     "user": {
      "displayName": "Rahul Vashisht cs18d006",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07093414448675380290"
     },
     "user_tz": -330
    },
    "id": "0dYXnywAD-4l"
   },
   "outputs": [],
   "source": [
    "class Classification(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Classification, self).__init__()\n",
    "    self.fc1 = nn.Linear(2, 3)\n",
    "    torch.nn.init.xavier_normal_(self.fc1.weight)\n",
    "    torch.nn.init.zeros_(self.fc1.bias)\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(x.shape)\n",
    "    #x = x.view(-1, 1)\n",
    "    #print(x.shape)\n",
    "    x = self.fc1(x)\n",
    "    # print(x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "lSa6O9f6XNf4"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "focus_net = Focus().double()\n",
    "focus_net = focus_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "36k3H2G-XO9A"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "classify = Classification().double()\n",
    "classify = classify.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "bK78aII8-GDl"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer_classify = optim.Adam(classify.parameters(), lr=0.008 ) #, momentum=0.9)\n",
    "optimizer_focus = optim.Adam(focus_net.parameters(), lr=0.008 ) #, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "h0mjWiFG-GDl"
   },
   "outputs": [],
   "source": [
    "def my_cross_entropy(output,target,alpha):\n",
    "    criterion = nn.CrossEntropyLoss(reduce=False)\n",
    "    \n",
    "    batch = output.size(0)\n",
    "    #print(batch)\n",
    "    patches = output.size(1)\n",
    "    classes = output.size(2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    output = torch.reshape(output,(batch*patches,classes))\n",
    "    \n",
    "    \n",
    "    target = target.repeat_interleave(patches)\n",
    "    \n",
    "    loss = criterion(output,target)\n",
    "    \n",
    "    #print(loss,loss.shape)\n",
    "    loss = torch.reshape(loss,(batch,patches))\n",
    "    #print(loss.size())\n",
    "    final_loss = torch.sum(torch.mul(loss,alpha),dim=1)\n",
    "    #print(final_loss.shape)\n",
    "    final_loss = torch.mean(final_loss,dim=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(final_loss)\n",
    "    return final_loss\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "pjD2VZuV9Ed4"
   },
   "outputs": [],
   "source": [
    "col1=[]\n",
    "col2=[]\n",
    "col3=[]\n",
    "col4=[]\n",
    "col5=[]\n",
    "col6=[]\n",
    "col7=[]\n",
    "col8=[]\n",
    "col9=[]\n",
    "col10=[]\n",
    "col11=[]\n",
    "col12=[]\n",
    "col13=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "eEVrBg7d-GDl"
   },
   "outputs": [],
   "source": [
    "def plot_attended_data(trainloader,net,epoch):\n",
    "    attd_data =[]\n",
    "    lbls = []\n",
    "    for data in trainloader:\n",
    "        inputs, labels , fore_idx = data\n",
    "        inputs = inputs.double()\n",
    "        inputs, labels , fore_idx = inputs.to(device),labels.to(device), fore_idx.to(device)\n",
    "        alphas, avg_images = focus_net(inputs)\n",
    "        attd_data.append(avg_images.numpy())\n",
    "        lbls.append(labels)\n",
    "    attd_data = np.concatenate(attd_data,axis=0)\n",
    "    lbls = np.concatenate(lbls,axis=0)\n",
    "    plt.figure(figsize=(6,8))\n",
    "    plt.scatter(attd_data[:,0],attd_data[:,1],c=lbls)\n",
    "    plt.title(\"EPOCH_\"+str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "uALi25pmzQHV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1920, dtype=torch.float64)\n",
      "tensor(1.1948, dtype=torch.float64)\n",
      "tensor(1.1889, dtype=torch.float64)\n",
      "tensor(1.1839, dtype=torch.float64)\n",
      "tensor(1.1927, dtype=torch.float64)\n",
      "tensor(1.1999, dtype=torch.float64)\n",
      "tensor(1.1916, dtype=torch.float64)\n",
      "tensor(1.1964, dtype=torch.float64)\n",
      "tensor(1.1997, dtype=torch.float64)\n",
      "tensor(1.1831, dtype=torch.float64)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "count = 0\n",
    "flag = 1\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  for data in train_loader:\n",
    "    inputs, labels , fore_idx = data\n",
    "    inputs = inputs.double()\n",
    "    inputs, labels , fore_idx = inputs.to(device),labels.to(device), fore_idx.to(device)\n",
    "    alphas, avg_images = focus_net(inputs)\n",
    "    outputs = classify(avg_images)\n",
    "    loss = my_cross_entropy(outputs,labels,alphas)\n",
    "    print(loss)\n",
    "    # print(outputs.shape)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "\n",
    "print(\"=\"*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "4vmNprlPzTjP"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "count = 0\n",
    "flag = 1\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  for data in test_loader:\n",
    "    inputs, labels , fore_idx = data\n",
    "    inputs = inputs.double()\n",
    "    inputs, labels , fore_idx = inputs.to(device),labels.to(device), fore_idx.to(device)\n",
    "    alphas, avg_images = focus_net(inputs)\n",
    "    outputs = classify(avg_images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "_nvicAzw-GDm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fc1.weight', Parameter containing:\n",
      "tensor([[-0.1235,  0.3437],\n",
      "        [ 0.1704, -0.2588],\n",
      "        [ 0.0472,  0.0784],\n",
      "        [ 0.4953, -0.1659],\n",
      "        [ 0.3371,  0.3451],\n",
      "        [ 0.3131, -0.1927],\n",
      "        [-0.1788,  0.0314],\n",
      "        [ 0.1934,  0.0747],\n",
      "        [-0.0699,  0.2935],\n",
      "        [ 0.0524, -0.1017],\n",
      "        [-0.2094, -0.3588],\n",
      "        [ 0.2079, -0.0692],\n",
      "        [-0.0396,  0.2914],\n",
      "        [-0.2280,  0.0319],\n",
      "        [-0.1798,  0.1602],\n",
      "        [ 0.1488, -0.0822],\n",
      "        [ 0.2434,  0.1657],\n",
      "        [-0.1537, -0.0442],\n",
      "        [-0.2106,  0.2442],\n",
      "        [-0.1865, -0.1679],\n",
      "        [-0.3746,  0.1089],\n",
      "        [ 0.0765,  0.0746],\n",
      "        [ 0.0194,  0.5148],\n",
      "        [-0.0150, -0.0721],\n",
      "        [-0.2615,  0.0124],\n",
      "        [ 0.2550,  0.0677],\n",
      "        [ 0.1783, -0.1196],\n",
      "        [ 0.1869,  0.2055],\n",
      "        [-0.0041, -0.1310],\n",
      "        [-0.0923,  0.0208],\n",
      "        [-0.1519, -0.2190],\n",
      "        [-0.0142, -0.0720],\n",
      "        [ 0.1204,  0.0586],\n",
      "        [-0.2943,  0.2803],\n",
      "        [ 0.0041,  0.0944],\n",
      "        [-0.0306, -0.0983],\n",
      "        [ 0.1264, -0.1432],\n",
      "        [-0.2297, -0.2029],\n",
      "        [-0.4360,  0.1309],\n",
      "        [ 0.2729, -0.1434],\n",
      "        [-0.1905, -0.0718],\n",
      "        [ 0.4859,  0.3518],\n",
      "        [-0.1163, -0.1056],\n",
      "        [ 0.0843,  0.2349],\n",
      "        [-0.2124,  0.0694],\n",
      "        [ 0.1559,  0.4671],\n",
      "        [ 0.0944,  0.2184],\n",
      "        [-0.1632, -0.0640],\n",
      "        [ 0.3447,  0.0719],\n",
      "        [-0.0065, -0.2574]], dtype=torch.float64, requires_grad=True))\n",
      "('fc2.weight', Parameter containing:\n",
      "tensor([[ 0.2877,  0.2409, -0.1060,  0.0798,  0.0235,  0.5752,  0.2892,  0.3077,\n",
      "         -0.0946,  0.0924, -0.1857,  0.1151, -0.0581, -0.1602, -0.0622, -0.3845,\n",
      "          0.2236, -0.0697, -0.1184, -0.0754,  0.0007,  0.0488,  0.0265, -0.2130,\n",
      "         -0.1718, -0.1714, -0.2712, -0.1121,  0.2311, -0.3507, -0.0884,  0.1573,\n",
      "          0.0479, -0.2186, -0.1205,  0.1774,  0.4210, -0.0055,  0.0760, -0.3396,\n",
      "          0.0821,  0.1663,  0.0678, -0.4594,  0.1509,  0.1229,  0.0456, -0.3413,\n",
      "          0.1490, -0.1123]], dtype=torch.float64, requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for param in focus_net.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Yl41sE8vFERk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 1.166\n",
      "[2,    10] loss: 1.126\n",
      "[3,    10] loss: 1.110\n",
      "[4,    10] loss: 1.105\n",
      "[5,    10] loss: 1.101\n",
      "[6,    10] loss: 1.101\n",
      "[7,    10] loss: 1.101\n",
      "[8,    10] loss: 1.100\n",
      "[9,    10] loss: 1.099\n",
      "[10,    10] loss: 1.099\n",
      "[11,    10] loss: 1.099\n",
      "[12,    10] loss: 1.099\n",
      "[13,    10] loss: 1.099\n",
      "[14,    10] loss: 1.099\n",
      "[15,    10] loss: 1.099\n",
      "[16,    10] loss: 1.099\n",
      "[17,    10] loss: 1.099\n",
      "[18,    10] loss: 1.099\n",
      "[19,    10] loss: 1.099\n",
      "[20,    10] loss: 1.099\n",
      "[21,    10] loss: 1.099\n",
      "[22,    10] loss: 1.099\n",
      "[23,    10] loss: 1.099\n",
      "[24,    10] loss: 1.100\n",
      "[25,    10] loss: 1.100\n",
      "[26,    10] loss: 1.099\n",
      "[27,    10] loss: 1.100\n",
      "[28,    10] loss: 1.100\n",
      "[29,    10] loss: 1.099\n",
      "[30,    10] loss: 1.100\n",
      "[31,    10] loss: 1.099\n",
      "[32,    10] loss: 1.099\n",
      "[33,    10] loss: 1.100\n",
      "[34,    10] loss: 1.099\n",
      "[35,    10] loss: 1.099\n",
      "[36,    10] loss: 1.099\n",
      "[37,    10] loss: 1.100\n",
      "[38,    10] loss: 1.099\n",
      "[39,    10] loss: 1.099\n",
      "[40,    10] loss: 1.099\n",
      "[41,    10] loss: 1.100\n",
      "[42,    10] loss: 1.100\n",
      "[43,    10] loss: 1.099\n",
      "[44,    10] loss: 1.100\n",
      "[45,    10] loss: 1.100\n",
      "[46,    10] loss: 1.100\n",
      "[47,    10] loss: 1.099\n",
      "[48,    10] loss: 1.099\n",
      "[49,    10] loss: 1.099\n",
      "[50,    10] loss: 1.099\n",
      "[51,    10] loss: 1.099\n",
      "[52,    10] loss: 1.099\n",
      "[53,    10] loss: 1.100\n",
      "[54,    10] loss: 1.100\n",
      "[55,    10] loss: 1.100\n",
      "[56,    10] loss: 1.099\n",
      "[57,    10] loss: 1.099\n",
      "[58,    10] loss: 1.099\n",
      "[59,    10] loss: 1.100\n",
      "[60,    10] loss: 1.099\n",
      "[61,    10] loss: 1.100\n",
      "[62,    10] loss: 1.099\n",
      "[63,    10] loss: 1.099\n",
      "[64,    10] loss: 1.099\n",
      "[65,    10] loss: 1.099\n",
      "[66,    10] loss: 1.100\n",
      "[67,    10] loss: 1.099\n",
      "[68,    10] loss: 1.099\n",
      "[69,    10] loss: 1.099\n",
      "[70,    10] loss: 1.099\n",
      "[71,    10] loss: 1.100\n",
      "[72,    10] loss: 1.099\n",
      "[73,    10] loss: 1.099\n",
      "[74,    10] loss: 1.099\n",
      "[75,    10] loss: 1.099\n",
      "[76,    10] loss: 1.099\n",
      "[77,    10] loss: 1.099\n",
      "[78,    10] loss: 1.100\n",
      "[79,    10] loss: 1.100\n",
      "[80,    10] loss: 1.099\n",
      "[81,    10] loss: 1.100\n",
      "[82,    10] loss: 1.098\n",
      "[83,    10] loss: 1.099\n",
      "[84,    10] loss: 1.100\n",
      "[85,    10] loss: 1.099\n",
      "[86,    10] loss: 1.099\n",
      "[87,    10] loss: 1.099\n",
      "[88,    10] loss: 1.099\n",
      "[89,    10] loss: 1.099\n",
      "[90,    10] loss: 1.099\n",
      "[91,    10] loss: 1.099\n",
      "[92,    10] loss: 1.098\n",
      "[93,    10] loss: 1.099\n",
      "[94,    10] loss: 1.099\n",
      "[95,    10] loss: 1.099\n",
      "[96,    10] loss: 1.099\n",
      "[97,    10] loss: 1.098\n",
      "[98,    10] loss: 1.100\n",
      "[99,    10] loss: 1.099\n",
      "[100,    10] loss: 1.099\n",
      "[101,    10] loss: 1.098\n",
      "[102,    10] loss: 1.100\n",
      "[103,    10] loss: 1.099\n",
      "[104,    10] loss: 1.098\n",
      "[105,    10] loss: 1.099\n",
      "[106,    10] loss: 1.099\n",
      "[107,    10] loss: 1.099\n",
      "[108,    10] loss: 1.099\n",
      "[109,    10] loss: 1.099\n",
      "[110,    10] loss: 1.099\n",
      "[111,    10] loss: 1.100\n",
      "[112,    10] loss: 1.098\n",
      "[113,    10] loss: 1.099\n",
      "[114,    10] loss: 1.100\n",
      "[115,    10] loss: 1.102\n",
      "[116,    10] loss: 1.099\n",
      "[117,    10] loss: 1.098\n",
      "[118,    10] loss: 1.099\n",
      "[119,    10] loss: 1.099\n",
      "[120,    10] loss: 1.100\n",
      "[121,    10] loss: 1.099\n",
      "[122,    10] loss: 1.099\n",
      "[123,    10] loss: 1.100\n",
      "[124,    10] loss: 1.098\n",
      "[125,    10] loss: 1.098\n",
      "[126,    10] loss: 1.099\n",
      "[127,    10] loss: 1.099\n",
      "[128,    10] loss: 1.099\n",
      "[129,    10] loss: 1.099\n",
      "[130,    10] loss: 1.100\n",
      "[131,    10] loss: 1.099\n",
      "[132,    10] loss: 1.099\n",
      "[133,    10] loss: 1.098\n",
      "[134,    10] loss: 1.099\n",
      "[135,    10] loss: 1.099\n",
      "[136,    10] loss: 1.098\n",
      "[137,    10] loss: 1.099\n",
      "[138,    10] loss: 1.099\n",
      "[139,    10] loss: 1.099\n",
      "[140,    10] loss: 1.100\n",
      "[141,    10] loss: 1.098\n",
      "[142,    10] loss: 1.099\n",
      "[143,    10] loss: 1.098\n",
      "[144,    10] loss: 1.098\n",
      "[145,    10] loss: 1.098\n",
      "[146,    10] loss: 1.099\n",
      "[147,    10] loss: 1.098\n",
      "[148,    10] loss: 1.098\n",
      "[149,    10] loss: 1.099\n",
      "[150,    10] loss: 1.098\n",
      "[151,    10] loss: 1.099\n",
      "[152,    10] loss: 1.098\n",
      "[153,    10] loss: 1.099\n",
      "[154,    10] loss: 1.099\n",
      "[155,    10] loss: 1.098\n",
      "[156,    10] loss: 1.099\n",
      "[157,    10] loss: 1.099\n",
      "[158,    10] loss: 1.098\n",
      "[159,    10] loss: 1.098\n",
      "[160,    10] loss: 1.098\n",
      "[161,    10] loss: 1.098\n",
      "[162,    10] loss: 1.098\n",
      "[163,    10] loss: 1.098\n",
      "[164,    10] loss: 1.098\n",
      "[165,    10] loss: 1.098\n",
      "[166,    10] loss: 1.098\n",
      "[167,    10] loss: 1.098\n",
      "[168,    10] loss: 1.098\n",
      "[169,    10] loss: 1.098\n",
      "[170,    10] loss: 1.098\n",
      "[171,    10] loss: 1.098\n",
      "[172,    10] loss: 1.098\n",
      "[173,    10] loss: 1.098\n",
      "[174,    10] loss: 1.099\n",
      "[175,    10] loss: 1.098\n",
      "[176,    10] loss: 1.098\n",
      "[177,    10] loss: 1.098\n",
      "[178,    10] loss: 1.099\n",
      "[179,    10] loss: 1.098\n",
      "[180,    10] loss: 1.098\n",
      "[181,    10] loss: 1.098\n",
      "[182,    10] loss: 1.098\n",
      "[183,    10] loss: 1.098\n",
      "[184,    10] loss: 1.098\n",
      "[185,    10] loss: 1.098\n",
      "[186,    10] loss: 1.098\n",
      "[187,    10] loss: 1.098\n",
      "[188,    10] loss: 1.097\n",
      "[189,    10] loss: 1.098\n",
      "[190,    10] loss: 1.098\n",
      "[191,    10] loss: 1.098\n",
      "[192,    10] loss: 1.098\n",
      "[193,    10] loss: 1.097\n",
      "[194,    10] loss: 1.098\n",
      "[195,    10] loss: 1.098\n",
      "[196,    10] loss: 1.097\n",
      "[197,    10] loss: 1.098\n",
      "[198,    10] loss: 1.098\n",
      "[199,    10] loss: 1.097\n",
      "[200,    10] loss: 1.098\n",
      "[201,    10] loss: 1.097\n",
      "[202,    10] loss: 1.098\n",
      "[203,    10] loss: 1.098\n",
      "[204,    10] loss: 1.098\n",
      "[205,    10] loss: 1.097\n",
      "[206,    10] loss: 1.098\n",
      "[207,    10] loss: 1.098\n",
      "[208,    10] loss: 1.098\n",
      "[209,    10] loss: 1.098\n",
      "[210,    10] loss: 1.098\n",
      "[211,    10] loss: 1.098\n",
      "[212,    10] loss: 1.097\n",
      "[213,    10] loss: 1.097\n",
      "[214,    10] loss: 1.098\n",
      "[215,    10] loss: 1.097\n",
      "[216,    10] loss: 1.098\n",
      "[217,    10] loss: 1.097\n",
      "[218,    10] loss: 1.097\n",
      "[219,    10] loss: 1.097\n",
      "[220,    10] loss: 1.097\n",
      "[221,    10] loss: 1.098\n",
      "[222,    10] loss: 1.097\n",
      "[223,    10] loss: 1.097\n",
      "[224,    10] loss: 1.097\n",
      "[225,    10] loss: 1.097\n",
      "[226,    10] loss: 1.098\n",
      "[227,    10] loss: 1.097\n",
      "[228,    10] loss: 1.097\n",
      "[229,    10] loss: 1.097\n",
      "[230,    10] loss: 1.098\n",
      "[231,    10] loss: 1.097\n",
      "[232,    10] loss: 1.097\n",
      "[233,    10] loss: 1.098\n",
      "[234,    10] loss: 1.098\n",
      "[235,    10] loss: 1.098\n",
      "[236,    10] loss: 1.097\n",
      "[237,    10] loss: 1.097\n",
      "[238,    10] loss: 1.097\n",
      "[239,    10] loss: 1.097\n",
      "[240,    10] loss: 1.099\n",
      "[241,    10] loss: 1.097\n",
      "[242,    10] loss: 1.099\n",
      "[243,    10] loss: 1.097\n",
      "[244,    10] loss: 1.097\n",
      "[245,    10] loss: 1.097\n",
      "[246,    10] loss: 1.097\n",
      "[247,    10] loss: 1.097\n",
      "[248,    10] loss: 1.097\n",
      "[249,    10] loss: 1.097\n",
      "[250,    10] loss: 1.098\n",
      "[251,    10] loss: 1.097\n",
      "[252,    10] loss: 1.097\n",
      "[253,    10] loss: 1.097\n",
      "[254,    10] loss: 1.097\n",
      "[255,    10] loss: 1.097\n",
      "[256,    10] loss: 1.097\n",
      "[257,    10] loss: 1.097\n",
      "[258,    10] loss: 1.097\n",
      "[259,    10] loss: 1.097\n",
      "[260,    10] loss: 1.098\n",
      "[261,    10] loss: 1.097\n",
      "[262,    10] loss: 1.098\n",
      "[263,    10] loss: 1.098\n",
      "[264,    10] loss: 1.097\n",
      "[265,    10] loss: 1.097\n",
      "[266,    10] loss: 1.097\n",
      "[267,    10] loss: 1.097\n",
      "[268,    10] loss: 1.097\n",
      "[269,    10] loss: 1.097\n",
      "[270,    10] loss: 1.097\n",
      "[271,    10] loss: 1.097\n",
      "[272,    10] loss: 1.099\n",
      "[273,    10] loss: 1.097\n",
      "[274,    10] loss: 1.097\n",
      "[275,    10] loss: 1.097\n",
      "[276,    10] loss: 1.097\n",
      "[277,    10] loss: 1.097\n",
      "[278,    10] loss: 1.097\n",
      "[279,    10] loss: 1.097\n",
      "[280,    10] loss: 1.096\n",
      "[281,    10] loss: 1.097\n",
      "[282,    10] loss: 1.097\n",
      "[283,    10] loss: 1.097\n",
      "[284,    10] loss: 1.097\n",
      "[285,    10] loss: 1.097\n",
      "[286,    10] loss: 1.096\n",
      "[287,    10] loss: 1.097\n",
      "[288,    10] loss: 1.096\n",
      "[289,    10] loss: 1.097\n",
      "[290,    10] loss: 1.097\n",
      "[291,    10] loss: 1.097\n",
      "[292,    10] loss: 1.097\n",
      "[293,    10] loss: 1.097\n",
      "[294,    10] loss: 1.096\n",
      "[295,    10] loss: 1.096\n",
      "[296,    10] loss: 1.097\n",
      "[297,    10] loss: 1.097\n",
      "[298,    10] loss: 1.097\n",
      "[299,    10] loss: 1.097\n",
      "[300,    10] loss: 1.097\n",
      "[301,    10] loss: 1.097\n",
      "[302,    10] loss: 1.097\n",
      "[303,    10] loss: 1.097\n",
      "[304,    10] loss: 1.096\n",
      "[305,    10] loss: 1.097\n",
      "[306,    10] loss: 1.096\n",
      "[307,    10] loss: 1.096\n",
      "[308,    10] loss: 1.097\n",
      "[309,    10] loss: 1.096\n",
      "[310,    10] loss: 1.097\n",
      "[311,    10] loss: 1.096\n",
      "[312,    10] loss: 1.098\n",
      "[313,    10] loss: 1.097\n",
      "[314,    10] loss: 1.097\n",
      "[315,    10] loss: 1.097\n",
      "[316,    10] loss: 1.096\n",
      "[317,    10] loss: 1.097\n",
      "[318,    10] loss: 1.096\n",
      "[319,    10] loss: 1.096\n",
      "[320,    10] loss: 1.096\n",
      "[321,    10] loss: 1.096\n",
      "[322,    10] loss: 1.096\n",
      "[323,    10] loss: 1.096\n",
      "[324,    10] loss: 1.097\n",
      "[325,    10] loss: 1.097\n",
      "[326,    10] loss: 1.097\n",
      "[327,    10] loss: 1.098\n",
      "[328,    10] loss: 1.099\n",
      "[329,    10] loss: 1.096\n",
      "[330,    10] loss: 1.097\n",
      "[331,    10] loss: 1.096\n",
      "[332,    10] loss: 1.097\n",
      "[333,    10] loss: 1.096\n",
      "[334,    10] loss: 1.096\n",
      "[335,    10] loss: 1.096\n",
      "[336,    10] loss: 1.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[337,    10] loss: 1.096\n",
      "[338,    10] loss: 1.096\n",
      "[339,    10] loss: 1.096\n",
      "[340,    10] loss: 1.096\n",
      "[341,    10] loss: 1.096\n",
      "[342,    10] loss: 1.097\n",
      "[343,    10] loss: 1.097\n",
      "[344,    10] loss: 1.097\n",
      "[345,    10] loss: 1.096\n",
      "[346,    10] loss: 1.096\n",
      "[347,    10] loss: 1.096\n",
      "[348,    10] loss: 1.097\n",
      "[349,    10] loss: 1.097\n",
      "[350,    10] loss: 1.096\n",
      "[351,    10] loss: 1.096\n",
      "[352,    10] loss: 1.097\n",
      "[353,    10] loss: 1.096\n",
      "[354,    10] loss: 1.096\n",
      "[355,    10] loss: 1.097\n",
      "[356,    10] loss: 1.096\n",
      "[357,    10] loss: 1.096\n",
      "[358,    10] loss: 1.096\n",
      "[359,    10] loss: 1.096\n",
      "[360,    10] loss: 1.097\n",
      "[361,    10] loss: 1.097\n",
      "[362,    10] loss: 1.096\n",
      "[363,    10] loss: 1.096\n",
      "[364,    10] loss: 1.097\n",
      "[365,    10] loss: 1.096\n",
      "[366,    10] loss: 1.096\n",
      "[367,    10] loss: 1.097\n",
      "[368,    10] loss: 1.096\n",
      "[369,    10] loss: 1.096\n",
      "[370,    10] loss: 1.097\n",
      "[371,    10] loss: 1.097\n",
      "[372,    10] loss: 1.097\n",
      "[373,    10] loss: 1.096\n",
      "[374,    10] loss: 1.096\n",
      "[375,    10] loss: 1.096\n",
      "[376,    10] loss: 1.096\n",
      "[377,    10] loss: 1.096\n",
      "[378,    10] loss: 1.096\n",
      "[379,    10] loss: 1.096\n",
      "[380,    10] loss: 1.096\n",
      "[381,    10] loss: 1.096\n",
      "[382,    10] loss: 1.096\n",
      "[383,    10] loss: 1.096\n",
      "[384,    10] loss: 1.095\n",
      "[385,    10] loss: 1.096\n",
      "[386,    10] loss: 1.096\n",
      "[387,    10] loss: 1.096\n",
      "[388,    10] loss: 1.095\n",
      "[389,    10] loss: 1.097\n",
      "[390,    10] loss: 1.095\n",
      "[391,    10] loss: 1.097\n",
      "[392,    10] loss: 1.095\n",
      "[393,    10] loss: 1.096\n",
      "[394,    10] loss: 1.096\n",
      "[395,    10] loss: 1.096\n",
      "[396,    10] loss: 1.096\n",
      "[397,    10] loss: 1.095\n",
      "[398,    10] loss: 1.096\n",
      "[399,    10] loss: 1.095\n",
      "[400,    10] loss: 1.095\n",
      "[401,    10] loss: 1.095\n",
      "[402,    10] loss: 1.095\n",
      "[403,    10] loss: 1.095\n",
      "[404,    10] loss: 1.095\n",
      "[405,    10] loss: 1.095\n",
      "[406,    10] loss: 1.095\n",
      "[407,    10] loss: 1.095\n",
      "[408,    10] loss: 1.096\n",
      "[409,    10] loss: 1.096\n",
      "[410,    10] loss: 1.095\n",
      "[411,    10] loss: 1.095\n",
      "[412,    10] loss: 1.095\n",
      "[413,    10] loss: 1.095\n",
      "[414,    10] loss: 1.096\n",
      "[415,    10] loss: 1.095\n",
      "[416,    10] loss: 1.095\n",
      "[417,    10] loss: 1.095\n",
      "[418,    10] loss: 1.095\n",
      "[419,    10] loss: 1.096\n",
      "[420,    10] loss: 1.096\n",
      "[421,    10] loss: 1.097\n",
      "[422,    10] loss: 1.095\n",
      "[423,    10] loss: 1.095\n",
      "[424,    10] loss: 1.095\n",
      "[425,    10] loss: 1.096\n",
      "[426,    10] loss: 1.095\n",
      "[427,    10] loss: 1.095\n",
      "[428,    10] loss: 1.095\n",
      "[429,    10] loss: 1.095\n",
      "[430,    10] loss: 1.096\n",
      "[431,    10] loss: 1.095\n",
      "[432,    10] loss: 1.095\n",
      "[433,    10] loss: 1.094\n",
      "[434,    10] loss: 1.095\n",
      "[435,    10] loss: 1.095\n",
      "[436,    10] loss: 1.095\n",
      "[437,    10] loss: 1.095\n",
      "[438,    10] loss: 1.096\n",
      "[439,    10] loss: 1.096\n",
      "[440,    10] loss: 1.096\n",
      "[441,    10] loss: 1.095\n",
      "[442,    10] loss: 1.095\n",
      "[443,    10] loss: 1.095\n",
      "[444,    10] loss: 1.095\n",
      "[445,    10] loss: 1.095\n",
      "[446,    10] loss: 1.095\n",
      "[447,    10] loss: 1.095\n",
      "[448,    10] loss: 1.095\n",
      "[449,    10] loss: 1.095\n",
      "[450,    10] loss: 1.095\n",
      "[451,    10] loss: 1.094\n",
      "[452,    10] loss: 1.095\n",
      "[453,    10] loss: 1.095\n",
      "[454,    10] loss: 1.094\n",
      "[455,    10] loss: 1.094\n",
      "[456,    10] loss: 1.095\n",
      "[457,    10] loss: 1.095\n",
      "[458,    10] loss: 1.094\n",
      "[459,    10] loss: 1.095\n",
      "[460,    10] loss: 1.095\n",
      "[461,    10] loss: 1.098\n",
      "[462,    10] loss: 1.096\n",
      "[463,    10] loss: 1.095\n",
      "[464,    10] loss: 1.095\n",
      "[465,    10] loss: 1.094\n",
      "[466,    10] loss: 1.095\n",
      "[467,    10] loss: 1.094\n",
      "[468,    10] loss: 1.094\n",
      "[469,    10] loss: 1.094\n",
      "[470,    10] loss: 1.095\n",
      "[471,    10] loss: 1.094\n",
      "[472,    10] loss: 1.095\n",
      "[473,    10] loss: 1.094\n",
      "[474,    10] loss: 1.095\n",
      "[475,    10] loss: 1.094\n",
      "[476,    10] loss: 1.094\n",
      "[477,    10] loss: 1.094\n",
      "[478,    10] loss: 1.094\n",
      "[479,    10] loss: 1.094\n",
      "[480,    10] loss: 1.094\n",
      "[481,    10] loss: 1.095\n",
      "[482,    10] loss: 1.094\n",
      "[483,    10] loss: 1.094\n",
      "[484,    10] loss: 1.095\n",
      "[485,    10] loss: 1.094\n",
      "[486,    10] loss: 1.094\n",
      "[487,    10] loss: 1.095\n",
      "[488,    10] loss: 1.094\n",
      "[489,    10] loss: 1.095\n",
      "[490,    10] loss: 1.095\n",
      "[491,    10] loss: 1.094\n",
      "[492,    10] loss: 1.095\n",
      "[493,    10] loss: 1.096\n",
      "[494,    10] loss: 1.094\n",
      "[495,    10] loss: 1.094\n",
      "[496,    10] loss: 1.095\n",
      "[497,    10] loss: 1.094\n",
      "[498,    10] loss: 1.095\n",
      "[499,    10] loss: 1.095\n",
      "[500,    10] loss: 1.094\n",
      "[501,    10] loss: 1.095\n",
      "[502,    10] loss: 1.095\n",
      "[503,    10] loss: 1.095\n",
      "[504,    10] loss: 1.094\n",
      "[505,    10] loss: 1.094\n",
      "[506,    10] loss: 1.094\n",
      "[507,    10] loss: 1.095\n",
      "[508,    10] loss: 1.096\n",
      "[509,    10] loss: 1.094\n",
      "[510,    10] loss: 1.094\n",
      "[511,    10] loss: 1.094\n",
      "[512,    10] loss: 1.096\n",
      "[513,    10] loss: 1.095\n",
      "[514,    10] loss: 1.094\n",
      "[515,    10] loss: 1.095\n",
      "[516,    10] loss: 1.094\n",
      "[517,    10] loss: 1.093\n",
      "[518,    10] loss: 1.094\n",
      "[519,    10] loss: 1.094\n",
      "[520,    10] loss: 1.094\n",
      "[521,    10] loss: 1.095\n",
      "[522,    10] loss: 1.094\n",
      "[523,    10] loss: 1.094\n",
      "[524,    10] loss: 1.094\n",
      "[525,    10] loss: 1.094\n",
      "[526,    10] loss: 1.094\n",
      "[527,    10] loss: 1.095\n",
      "[528,    10] loss: 1.094\n",
      "[529,    10] loss: 1.094\n",
      "[530,    10] loss: 1.093\n",
      "[531,    10] loss: 1.095\n",
      "[532,    10] loss: 1.094\n",
      "[533,    10] loss: 1.094\n",
      "[534,    10] loss: 1.094\n",
      "[535,    10] loss: 1.094\n",
      "[536,    10] loss: 1.094\n",
      "[537,    10] loss: 1.094\n",
      "[538,    10] loss: 1.094\n",
      "[539,    10] loss: 1.097\n",
      "[540,    10] loss: 1.094\n",
      "[541,    10] loss: 1.093\n",
      "[542,    10] loss: 1.095\n",
      "[543,    10] loss: 1.094\n",
      "[544,    10] loss: 1.094\n",
      "[545,    10] loss: 1.093\n",
      "[546,    10] loss: 1.094\n",
      "[547,    10] loss: 1.093\n",
      "[548,    10] loss: 1.093\n",
      "[549,    10] loss: 1.094\n",
      "[550,    10] loss: 1.094\n",
      "[551,    10] loss: 1.094\n",
      "[552,    10] loss: 1.093\n",
      "[553,    10] loss: 1.093\n",
      "[554,    10] loss: 1.093\n",
      "[555,    10] loss: 1.094\n",
      "[556,    10] loss: 1.093\n",
      "[557,    10] loss: 1.094\n",
      "[558,    10] loss: 1.094\n",
      "[559,    10] loss: 1.093\n",
      "[560,    10] loss: 1.093\n",
      "[561,    10] loss: 1.093\n",
      "[562,    10] loss: 1.093\n",
      "[563,    10] loss: 1.093\n",
      "[564,    10] loss: 1.094\n",
      "[565,    10] loss: 1.093\n",
      "[566,    10] loss: 1.093\n",
      "[567,    10] loss: 1.093\n",
      "[568,    10] loss: 1.094\n",
      "[569,    10] loss: 1.093\n",
      "[570,    10] loss: 1.094\n",
      "[571,    10] loss: 1.093\n",
      "[572,    10] loss: 1.093\n",
      "[573,    10] loss: 1.093\n",
      "[574,    10] loss: 1.096\n",
      "[575,    10] loss: 1.094\n",
      "[576,    10] loss: 1.093\n",
      "[577,    10] loss: 1.094\n",
      "[578,    10] loss: 1.093\n",
      "[579,    10] loss: 1.094\n",
      "[580,    10] loss: 1.094\n",
      "[581,    10] loss: 1.094\n",
      "[582,    10] loss: 1.093\n",
      "[583,    10] loss: 1.093\n",
      "[584,    10] loss: 1.093\n",
      "[585,    10] loss: 1.094\n",
      "[586,    10] loss: 1.093\n",
      "[587,    10] loss: 1.094\n",
      "[588,    10] loss: 1.094\n",
      "[589,    10] loss: 1.094\n",
      "[590,    10] loss: 1.093\n",
      "[591,    10] loss: 1.093\n",
      "[592,    10] loss: 1.093\n",
      "[593,    10] loss: 1.094\n",
      "[594,    10] loss: 1.093\n",
      "[595,    10] loss: 1.094\n",
      "[596,    10] loss: 1.093\n",
      "[597,    10] loss: 1.093\n",
      "[598,    10] loss: 1.093\n",
      "[599,    10] loss: 1.093\n",
      "[600,    10] loss: 1.093\n",
      "[601,    10] loss: 1.093\n",
      "[602,    10] loss: 1.094\n",
      "[603,    10] loss: 1.093\n",
      "[604,    10] loss: 1.093\n",
      "[605,    10] loss: 1.093\n",
      "[606,    10] loss: 1.094\n",
      "[607,    10] loss: 1.093\n",
      "[608,    10] loss: 1.094\n",
      "[609,    10] loss: 1.093\n",
      "[610,    10] loss: 1.093\n",
      "[611,    10] loss: 1.093\n",
      "[612,    10] loss: 1.094\n",
      "[613,    10] loss: 1.093\n",
      "[614,    10] loss: 1.093\n",
      "[615,    10] loss: 1.093\n",
      "[616,    10] loss: 1.093\n",
      "[617,    10] loss: 1.093\n",
      "[618,    10] loss: 1.093\n",
      "[619,    10] loss: 1.093\n",
      "[620,    10] loss: 1.093\n",
      "[621,    10] loss: 1.093\n",
      "[622,    10] loss: 1.093\n",
      "[623,    10] loss: 1.093\n",
      "[624,    10] loss: 1.093\n",
      "[625,    10] loss: 1.094\n",
      "[626,    10] loss: 1.092\n",
      "[627,    10] loss: 1.094\n",
      "[628,    10] loss: 1.093\n",
      "[629,    10] loss: 1.093\n",
      "[630,    10] loss: 1.093\n",
      "[631,    10] loss: 1.093\n",
      "[632,    10] loss: 1.093\n",
      "[633,    10] loss: 1.093\n",
      "[634,    10] loss: 1.093\n",
      "[635,    10] loss: 1.093\n",
      "[636,    10] loss: 1.092\n",
      "[637,    10] loss: 1.093\n",
      "[638,    10] loss: 1.093\n",
      "[639,    10] loss: 1.093\n",
      "[640,    10] loss: 1.093\n",
      "[641,    10] loss: 1.093\n",
      "[642,    10] loss: 1.093\n",
      "[643,    10] loss: 1.092\n",
      "[644,    10] loss: 1.093\n",
      "[645,    10] loss: 1.093\n",
      "[646,    10] loss: 1.093\n",
      "[647,    10] loss: 1.093\n",
      "[648,    10] loss: 1.093\n",
      "[649,    10] loss: 1.093\n",
      "[650,    10] loss: 1.093\n",
      "[651,    10] loss: 1.093\n",
      "[652,    10] loss: 1.093\n",
      "[653,    10] loss: 1.092\n",
      "[654,    10] loss: 1.092\n",
      "[655,    10] loss: 1.092\n",
      "[656,    10] loss: 1.093\n",
      "[657,    10] loss: 1.093\n",
      "[658,    10] loss: 1.093\n",
      "[659,    10] loss: 1.092\n",
      "[660,    10] loss: 1.093\n",
      "[661,    10] loss: 1.092\n",
      "[662,    10] loss: 1.093\n",
      "[663,    10] loss: 1.093\n",
      "[664,    10] loss: 1.092\n",
      "[665,    10] loss: 1.092\n",
      "[666,    10] loss: 1.092\n",
      "[667,    10] loss: 1.092\n",
      "[668,    10] loss: 1.093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[669,    10] loss: 1.093\n",
      "[670,    10] loss: 1.093\n",
      "[671,    10] loss: 1.093\n",
      "[672,    10] loss: 1.092\n",
      "[673,    10] loss: 1.092\n",
      "[674,    10] loss: 1.092\n",
      "[675,    10] loss: 1.093\n",
      "[676,    10] loss: 1.092\n",
      "[677,    10] loss: 1.093\n",
      "[678,    10] loss: 1.092\n",
      "[679,    10] loss: 1.093\n",
      "[680,    10] loss: 1.092\n",
      "[681,    10] loss: 1.092\n",
      "[682,    10] loss: 1.092\n",
      "[683,    10] loss: 1.092\n",
      "[684,    10] loss: 1.092\n",
      "[685,    10] loss: 1.092\n",
      "[686,    10] loss: 1.092\n",
      "[687,    10] loss: 1.092\n",
      "[688,    10] loss: 1.093\n",
      "[689,    10] loss: 1.093\n",
      "[690,    10] loss: 1.093\n",
      "[691,    10] loss: 1.092\n",
      "[692,    10] loss: 1.093\n",
      "[693,    10] loss: 1.093\n",
      "[694,    10] loss: 1.092\n",
      "[695,    10] loss: 1.092\n",
      "[696,    10] loss: 1.092\n",
      "[697,    10] loss: 1.093\n",
      "[698,    10] loss: 1.092\n",
      "[699,    10] loss: 1.093\n",
      "[700,    10] loss: 1.092\n",
      "[701,    10] loss: 1.092\n",
      "[702,    10] loss: 1.092\n",
      "[703,    10] loss: 1.092\n",
      "[704,    10] loss: 1.092\n",
      "[705,    10] loss: 1.093\n",
      "[706,    10] loss: 1.092\n",
      "[707,    10] loss: 1.093\n",
      "[708,    10] loss: 1.093\n",
      "[709,    10] loss: 1.093\n",
      "[710,    10] loss: 1.092\n",
      "[711,    10] loss: 1.093\n",
      "[712,    10] loss: 1.092\n",
      "[713,    10] loss: 1.092\n",
      "[714,    10] loss: 1.092\n",
      "[715,    10] loss: 1.092\n",
      "[716,    10] loss: 1.094\n",
      "[717,    10] loss: 1.092\n",
      "[718,    10] loss: 1.092\n",
      "[719,    10] loss: 1.092\n",
      "[720,    10] loss: 1.092\n",
      "[721,    10] loss: 1.091\n",
      "[722,    10] loss: 1.092\n",
      "[723,    10] loss: 1.092\n",
      "[724,    10] loss: 1.092\n",
      "[725,    10] loss: 1.092\n",
      "[726,    10] loss: 1.092\n",
      "[727,    10] loss: 1.092\n",
      "[728,    10] loss: 1.092\n",
      "[729,    10] loss: 1.093\n",
      "[730,    10] loss: 1.092\n",
      "[731,    10] loss: 1.092\n",
      "[732,    10] loss: 1.092\n",
      "[733,    10] loss: 1.092\n",
      "[734,    10] loss: 1.091\n",
      "[735,    10] loss: 1.092\n",
      "[736,    10] loss: 1.091\n",
      "[737,    10] loss: 1.092\n",
      "[738,    10] loss: 1.092\n",
      "[739,    10] loss: 1.092\n",
      "[740,    10] loss: 1.093\n",
      "[741,    10] loss: 1.092\n",
      "[742,    10] loss: 1.092\n",
      "[743,    10] loss: 1.092\n",
      "[744,    10] loss: 1.092\n",
      "[745,    10] loss: 1.092\n",
      "[746,    10] loss: 1.092\n",
      "[747,    10] loss: 1.092\n",
      "[748,    10] loss: 1.092\n",
      "[749,    10] loss: 1.092\n",
      "[750,    10] loss: 1.092\n",
      "[751,    10] loss: 1.092\n",
      "[752,    10] loss: 1.091\n",
      "[753,    10] loss: 1.091\n",
      "[754,    10] loss: 1.091\n",
      "[755,    10] loss: 1.091\n",
      "[756,    10] loss: 1.091\n",
      "[757,    10] loss: 1.091\n",
      "[758,    10] loss: 1.092\n",
      "[759,    10] loss: 1.091\n",
      "[760,    10] loss: 1.092\n",
      "[761,    10] loss: 1.091\n",
      "[762,    10] loss: 1.092\n",
      "[763,    10] loss: 1.092\n",
      "[764,    10] loss: 1.091\n",
      "[765,    10] loss: 1.092\n",
      "[766,    10] loss: 1.093\n",
      "[767,    10] loss: 1.093\n",
      "[768,    10] loss: 1.091\n",
      "[769,    10] loss: 1.091\n",
      "[770,    10] loss: 1.092\n",
      "[771,    10] loss: 1.093\n",
      "[772,    10] loss: 1.091\n",
      "[773,    10] loss: 1.092\n",
      "[774,    10] loss: 1.091\n",
      "[775,    10] loss: 1.092\n",
      "[776,    10] loss: 1.091\n",
      "[777,    10] loss: 1.091\n",
      "[778,    10] loss: 1.091\n",
      "[779,    10] loss: 1.092\n",
      "[780,    10] loss: 1.092\n",
      "[781,    10] loss: 1.092\n",
      "[782,    10] loss: 1.091\n",
      "[783,    10] loss: 1.092\n",
      "[784,    10] loss: 1.092\n",
      "[785,    10] loss: 1.092\n",
      "[786,    10] loss: 1.092\n",
      "[787,    10] loss: 1.093\n",
      "[788,    10] loss: 1.091\n",
      "[789,    10] loss: 1.091\n",
      "[790,    10] loss: 1.091\n",
      "[791,    10] loss: 1.092\n",
      "[792,    10] loss: 1.091\n",
      "[793,    10] loss: 1.091\n",
      "[794,    10] loss: 1.091\n",
      "[795,    10] loss: 1.091\n",
      "[796,    10] loss: 1.092\n",
      "[797,    10] loss: 1.092\n",
      "[798,    10] loss: 1.092\n",
      "[799,    10] loss: 1.091\n",
      "[800,    10] loss: 1.092\n",
      "[801,    10] loss: 1.091\n",
      "[802,    10] loss: 1.091\n",
      "[803,    10] loss: 1.091\n",
      "[804,    10] loss: 1.091\n",
      "[805,    10] loss: 1.091\n",
      "[806,    10] loss: 1.092\n",
      "[807,    10] loss: 1.092\n",
      "[808,    10] loss: 1.092\n",
      "[809,    10] loss: 1.093\n",
      "[810,    10] loss: 1.090\n",
      "[811,    10] loss: 1.091\n",
      "[812,    10] loss: 1.091\n",
      "[813,    10] loss: 1.091\n",
      "[814,    10] loss: 1.093\n",
      "[815,    10] loss: 1.091\n",
      "[816,    10] loss: 1.091\n",
      "[817,    10] loss: 1.091\n",
      "[818,    10] loss: 1.092\n",
      "[819,    10] loss: 1.091\n",
      "[820,    10] loss: 1.092\n",
      "[821,    10] loss: 1.092\n",
      "[822,    10] loss: 1.092\n",
      "[823,    10] loss: 1.091\n",
      "[824,    10] loss: 1.091\n",
      "[825,    10] loss: 1.092\n",
      "[826,    10] loss: 1.091\n",
      "[827,    10] loss: 1.091\n",
      "[828,    10] loss: 1.091\n",
      "[829,    10] loss: 1.091\n",
      "[830,    10] loss: 1.092\n",
      "[831,    10] loss: 1.092\n",
      "[832,    10] loss: 1.091\n",
      "[833,    10] loss: 1.091\n",
      "[834,    10] loss: 1.091\n",
      "[835,    10] loss: 1.091\n",
      "[836,    10] loss: 1.091\n",
      "[837,    10] loss: 1.092\n",
      "[838,    10] loss: 1.091\n",
      "[839,    10] loss: 1.092\n",
      "[840,    10] loss: 1.092\n",
      "[841,    10] loss: 1.091\n",
      "[842,    10] loss: 1.091\n",
      "[843,    10] loss: 1.091\n",
      "[844,    10] loss: 1.090\n",
      "[845,    10] loss: 1.091\n",
      "[846,    10] loss: 1.091\n",
      "[847,    10] loss: 1.091\n",
      "[848,    10] loss: 1.091\n",
      "[849,    10] loss: 1.091\n",
      "[850,    10] loss: 1.091\n",
      "[851,    10] loss: 1.092\n",
      "[852,    10] loss: 1.091\n",
      "[853,    10] loss: 1.091\n",
      "[854,    10] loss: 1.091\n",
      "[855,    10] loss: 1.090\n",
      "[856,    10] loss: 1.091\n",
      "[857,    10] loss: 1.091\n",
      "[858,    10] loss: 1.092\n",
      "[859,    10] loss: 1.091\n",
      "[860,    10] loss: 1.091\n",
      "[861,    10] loss: 1.091\n",
      "[862,    10] loss: 1.091\n",
      "[863,    10] loss: 1.091\n",
      "[864,    10] loss: 1.091\n",
      "[865,    10] loss: 1.090\n",
      "[866,    10] loss: 1.091\n",
      "[867,    10] loss: 1.091\n",
      "[868,    10] loss: 1.091\n",
      "[869,    10] loss: 1.091\n",
      "[870,    10] loss: 1.090\n",
      "[871,    10] loss: 1.091\n",
      "[872,    10] loss: 1.092\n",
      "[873,    10] loss: 1.090\n",
      "[874,    10] loss: 1.091\n",
      "[875,    10] loss: 1.091\n",
      "[876,    10] loss: 1.090\n",
      "[877,    10] loss: 1.091\n",
      "[878,    10] loss: 1.091\n",
      "[879,    10] loss: 1.091\n",
      "[880,    10] loss: 1.090\n",
      "[881,    10] loss: 1.090\n",
      "[882,    10] loss: 1.091\n",
      "[883,    10] loss: 1.091\n",
      "[884,    10] loss: 1.091\n",
      "[885,    10] loss: 1.091\n",
      "[886,    10] loss: 1.091\n",
      "[887,    10] loss: 1.091\n",
      "[888,    10] loss: 1.091\n",
      "[889,    10] loss: 1.090\n",
      "[890,    10] loss: 1.091\n",
      "[891,    10] loss: 1.091\n",
      "[892,    10] loss: 1.091\n",
      "[893,    10] loss: 1.091\n",
      "[894,    10] loss: 1.091\n",
      "[895,    10] loss: 1.090\n",
      "[896,    10] loss: 1.090\n",
      "[897,    10] loss: 1.090\n",
      "[898,    10] loss: 1.091\n",
      "[899,    10] loss: 1.091\n",
      "[900,    10] loss: 1.091\n",
      "[901,    10] loss: 1.090\n",
      "[902,    10] loss: 1.091\n",
      "[903,    10] loss: 1.091\n",
      "[904,    10] loss: 1.090\n",
      "[905,    10] loss: 1.091\n",
      "[906,    10] loss: 1.091\n",
      "[907,    10] loss: 1.090\n",
      "[908,    10] loss: 1.091\n",
      "[909,    10] loss: 1.092\n",
      "[910,    10] loss: 1.090\n",
      "[911,    10] loss: 1.091\n",
      "[912,    10] loss: 1.091\n",
      "[913,    10] loss: 1.090\n",
      "[914,    10] loss: 1.091\n",
      "[915,    10] loss: 1.091\n",
      "[916,    10] loss: 1.090\n",
      "[917,    10] loss: 1.091\n",
      "[918,    10] loss: 1.091\n",
      "[919,    10] loss: 1.090\n",
      "[920,    10] loss: 1.090\n",
      "[921,    10] loss: 1.091\n",
      "[922,    10] loss: 1.091\n",
      "[923,    10] loss: 1.090\n",
      "[924,    10] loss: 1.091\n",
      "[925,    10] loss: 1.090\n",
      "[926,    10] loss: 1.090\n",
      "[927,    10] loss: 1.090\n",
      "[928,    10] loss: 1.091\n",
      "[929,    10] loss: 1.091\n",
      "[930,    10] loss: 1.090\n",
      "[931,    10] loss: 1.090\n",
      "[932,    10] loss: 1.091\n",
      "[933,    10] loss: 1.090\n",
      "[934,    10] loss: 1.090\n",
      "[935,    10] loss: 1.091\n",
      "[936,    10] loss: 1.091\n",
      "[937,    10] loss: 1.090\n",
      "[938,    10] loss: 1.091\n",
      "[939,    10] loss: 1.090\n",
      "[940,    10] loss: 1.090\n",
      "[941,    10] loss: 1.091\n",
      "[942,    10] loss: 1.091\n",
      "[943,    10] loss: 1.090\n",
      "[944,    10] loss: 1.091\n",
      "[945,    10] loss: 1.090\n",
      "[946,    10] loss: 1.091\n",
      "[947,    10] loss: 1.090\n",
      "[948,    10] loss: 1.090\n",
      "[949,    10] loss: 1.090\n",
      "[950,    10] loss: 1.091\n",
      "[951,    10] loss: 1.090\n",
      "[952,    10] loss: 1.090\n",
      "[953,    10] loss: 1.090\n",
      "[954,    10] loss: 1.091\n",
      "[955,    10] loss: 1.091\n",
      "[956,    10] loss: 1.090\n",
      "[957,    10] loss: 1.090\n",
      "[958,    10] loss: 1.090\n",
      "[959,    10] loss: 1.090\n",
      "[960,    10] loss: 1.090\n",
      "[961,    10] loss: 1.090\n",
      "[962,    10] loss: 1.090\n",
      "[963,    10] loss: 1.090\n",
      "[964,    10] loss: 1.091\n",
      "[965,    10] loss: 1.091\n",
      "[966,    10] loss: 1.090\n",
      "[967,    10] loss: 1.091\n",
      "[968,    10] loss: 1.090\n",
      "[969,    10] loss: 1.090\n",
      "[970,    10] loss: 1.091\n",
      "[971,    10] loss: 1.090\n",
      "[972,    10] loss: 1.090\n",
      "[973,    10] loss: 1.091\n",
      "[974,    10] loss: 1.090\n",
      "[975,    10] loss: 1.090\n",
      "[976,    10] loss: 1.090\n",
      "[977,    10] loss: 1.090\n",
      "[978,    10] loss: 1.090\n",
      "[979,    10] loss: 1.090\n",
      "[980,    10] loss: 1.091\n",
      "[981,    10] loss: 1.090\n",
      "[982,    10] loss: 1.090\n",
      "[983,    10] loss: 1.090\n",
      "[984,    10] loss: 1.090\n",
      "[985,    10] loss: 1.091\n",
      "[986,    10] loss: 1.090\n",
      "[987,    10] loss: 1.090\n",
      "[988,    10] loss: 1.090\n",
      "[989,    10] loss: 1.090\n",
      "[990,    10] loss: 1.090\n",
      "[991,    10] loss: 1.090\n",
      "[992,    10] loss: 1.090\n",
      "[993,    10] loss: 1.090\n",
      "[994,    10] loss: 1.091\n",
      "[995,    10] loss: 1.091\n",
      "[996,    10] loss: 1.090\n",
      "[997,    10] loss: 1.090\n",
      "[998,    10] loss: 1.090\n",
      "[999,    10] loss: 1.091\n",
      "[1000,    10] loss: 1.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1001,    10] loss: 1.090\n",
      "[1002,    10] loss: 1.090\n",
      "[1003,    10] loss: 1.090\n",
      "[1004,    10] loss: 1.090\n",
      "[1005,    10] loss: 1.090\n",
      "[1006,    10] loss: 1.090\n",
      "[1007,    10] loss: 1.091\n",
      "[1008,    10] loss: 1.090\n",
      "[1009,    10] loss: 1.090\n",
      "[1010,    10] loss: 1.091\n",
      "[1011,    10] loss: 1.090\n",
      "[1012,    10] loss: 1.090\n",
      "[1013,    10] loss: 1.090\n",
      "[1014,    10] loss: 1.090\n",
      "[1015,    10] loss: 1.090\n",
      "[1016,    10] loss: 1.090\n",
      "[1017,    10] loss: 1.090\n",
      "[1018,    10] loss: 1.090\n",
      "[1019,    10] loss: 1.090\n",
      "[1020,    10] loss: 1.089\n",
      "[1021,    10] loss: 1.090\n",
      "[1022,    10] loss: 1.090\n",
      "[1023,    10] loss: 1.089\n",
      "[1024,    10] loss: 1.089\n",
      "[1025,    10] loss: 1.090\n",
      "[1026,    10] loss: 1.091\n",
      "[1027,    10] loss: 1.093\n",
      "[1028,    10] loss: 1.091\n",
      "[1029,    10] loss: 1.089\n",
      "[1030,    10] loss: 1.091\n",
      "[1031,    10] loss: 1.091\n",
      "[1032,    10] loss: 1.090\n",
      "[1033,    10] loss: 1.090\n",
      "[1034,    10] loss: 1.091\n",
      "[1035,    10] loss: 1.092\n",
      "[1036,    10] loss: 1.090\n",
      "[1037,    10] loss: 1.090\n",
      "[1038,    10] loss: 1.090\n",
      "[1039,    10] loss: 1.090\n",
      "[1040,    10] loss: 1.090\n",
      "[1041,    10] loss: 1.090\n",
      "[1042,    10] loss: 1.091\n",
      "[1043,    10] loss: 1.089\n",
      "[1044,    10] loss: 1.090\n",
      "[1045,    10] loss: 1.089\n",
      "[1046,    10] loss: 1.090\n",
      "[1047,    10] loss: 1.090\n",
      "[1048,    10] loss: 1.091\n",
      "[1049,    10] loss: 1.090\n",
      "[1050,    10] loss: 1.089\n",
      "[1051,    10] loss: 1.089\n",
      "[1052,    10] loss: 1.090\n",
      "[1053,    10] loss: 1.089\n",
      "[1054,    10] loss: 1.089\n",
      "[1055,    10] loss: 1.089\n",
      "[1056,    10] loss: 1.091\n",
      "[1057,    10] loss: 1.090\n",
      "[1058,    10] loss: 1.090\n",
      "[1059,    10] loss: 1.089\n",
      "[1060,    10] loss: 1.090\n",
      "[1061,    10] loss: 1.089\n",
      "[1062,    10] loss: 1.090\n",
      "[1063,    10] loss: 1.091\n",
      "[1064,    10] loss: 1.089\n",
      "[1065,    10] loss: 1.090\n",
      "[1066,    10] loss: 1.089\n",
      "[1067,    10] loss: 1.090\n",
      "[1068,    10] loss: 1.090\n",
      "[1069,    10] loss: 1.090\n",
      "[1070,    10] loss: 1.089\n",
      "[1071,    10] loss: 1.089\n",
      "[1072,    10] loss: 1.089\n",
      "[1073,    10] loss: 1.090\n",
      "[1074,    10] loss: 1.089\n",
      "[1075,    10] loss: 1.090\n",
      "[1076,    10] loss: 1.090\n",
      "[1077,    10] loss: 1.090\n",
      "[1078,    10] loss: 1.091\n",
      "[1079,    10] loss: 1.089\n",
      "[1080,    10] loss: 1.090\n",
      "[1081,    10] loss: 1.090\n",
      "[1082,    10] loss: 1.090\n",
      "[1083,    10] loss: 1.089\n",
      "[1084,    10] loss: 1.089\n",
      "[1085,    10] loss: 1.089\n",
      "[1086,    10] loss: 1.090\n",
      "[1087,    10] loss: 1.091\n",
      "[1088,    10] loss: 1.090\n",
      "[1089,    10] loss: 1.090\n",
      "[1090,    10] loss: 1.090\n",
      "[1091,    10] loss: 1.090\n",
      "[1092,    10] loss: 1.090\n",
      "[1093,    10] loss: 1.090\n",
      "[1094,    10] loss: 1.089\n",
      "[1095,    10] loss: 1.089\n",
      "[1096,    10] loss: 1.089\n",
      "[1097,    10] loss: 1.090\n",
      "[1098,    10] loss: 1.090\n",
      "[1099,    10] loss: 1.089\n",
      "[1100,    10] loss: 1.089\n",
      "[1101,    10] loss: 1.091\n",
      "[1102,    10] loss: 1.090\n",
      "[1103,    10] loss: 1.091\n",
      "[1104,    10] loss: 1.090\n",
      "[1105,    10] loss: 1.090\n",
      "[1106,    10] loss: 1.089\n",
      "[1107,    10] loss: 1.089\n",
      "[1108,    10] loss: 1.089\n",
      "[1109,    10] loss: 1.089\n",
      "[1110,    10] loss: 1.091\n",
      "[1111,    10] loss: 1.089\n",
      "[1112,    10] loss: 1.091\n",
      "[1113,    10] loss: 1.089\n",
      "[1114,    10] loss: 1.089\n",
      "[1115,    10] loss: 1.089\n",
      "[1116,    10] loss: 1.090\n",
      "[1117,    10] loss: 1.091\n",
      "[1118,    10] loss: 1.089\n",
      "[1119,    10] loss: 1.089\n",
      "[1120,    10] loss: 1.090\n",
      "[1121,    10] loss: 1.089\n",
      "[1122,    10] loss: 1.089\n",
      "[1123,    10] loss: 1.089\n",
      "[1124,    10] loss: 1.089\n",
      "[1125,    10] loss: 1.090\n",
      "[1126,    10] loss: 1.089\n",
      "[1127,    10] loss: 1.089\n",
      "[1128,    10] loss: 1.090\n",
      "[1129,    10] loss: 1.090\n",
      "[1130,    10] loss: 1.089\n",
      "[1131,    10] loss: 1.089\n",
      "[1132,    10] loss: 1.089\n",
      "[1133,    10] loss: 1.089\n",
      "[1134,    10] loss: 1.089\n",
      "[1135,    10] loss: 1.089\n",
      "[1136,    10] loss: 1.089\n",
      "[1137,    10] loss: 1.089\n",
      "[1138,    10] loss: 1.089\n",
      "[1139,    10] loss: 1.089\n",
      "[1140,    10] loss: 1.089\n",
      "[1141,    10] loss: 1.089\n",
      "[1142,    10] loss: 1.089\n",
      "[1143,    10] loss: 1.089\n",
      "[1144,    10] loss: 1.089\n",
      "[1145,    10] loss: 1.090\n",
      "[1146,    10] loss: 1.089\n",
      "[1147,    10] loss: 1.090\n",
      "[1148,    10] loss: 1.090\n",
      "[1149,    10] loss: 1.089\n",
      "[1150,    10] loss: 1.089\n",
      "[1151,    10] loss: 1.089\n",
      "[1152,    10] loss: 1.089\n",
      "[1153,    10] loss: 1.089\n",
      "[1154,    10] loss: 1.089\n",
      "[1155,    10] loss: 1.090\n",
      "[1156,    10] loss: 1.089\n",
      "[1157,    10] loss: 1.089\n",
      "[1158,    10] loss: 1.089\n",
      "[1159,    10] loss: 1.089\n",
      "[1160,    10] loss: 1.090\n",
      "[1161,    10] loss: 1.092\n",
      "[1162,    10] loss: 1.090\n",
      "[1163,    10] loss: 1.090\n",
      "[1164,    10] loss: 1.089\n",
      "[1165,    10] loss: 1.089\n",
      "[1166,    10] loss: 1.090\n",
      "[1167,    10] loss: 1.089\n",
      "[1168,    10] loss: 1.089\n",
      "[1169,    10] loss: 1.089\n",
      "[1170,    10] loss: 1.089\n",
      "[1171,    10] loss: 1.090\n",
      "[1172,    10] loss: 1.089\n",
      "[1173,    10] loss: 1.089\n",
      "[1174,    10] loss: 1.089\n",
      "[1175,    10] loss: 1.091\n",
      "[1176,    10] loss: 1.089\n",
      "[1177,    10] loss: 1.089\n",
      "[1178,    10] loss: 1.089\n",
      "[1179,    10] loss: 1.089\n",
      "[1180,    10] loss: 1.089\n",
      "[1181,    10] loss: 1.089\n",
      "[1182,    10] loss: 1.089\n",
      "[1183,    10] loss: 1.089\n",
      "[1184,    10] loss: 1.089\n",
      "[1185,    10] loss: 1.089\n",
      "[1186,    10] loss: 1.090\n",
      "[1187,    10] loss: 1.089\n",
      "[1188,    10] loss: 1.089\n",
      "[1189,    10] loss: 1.089\n",
      "[1190,    10] loss: 1.089\n",
      "[1191,    10] loss: 1.089\n",
      "[1192,    10] loss: 1.089\n",
      "[1193,    10] loss: 1.089\n",
      "[1194,    10] loss: 1.089\n",
      "[1195,    10] loss: 1.089\n",
      "[1196,    10] loss: 1.089\n",
      "[1197,    10] loss: 1.089\n",
      "[1198,    10] loss: 1.089\n",
      "[1199,    10] loss: 1.089\n",
      "[1200,    10] loss: 1.089\n",
      "[1201,    10] loss: 1.089\n",
      "[1202,    10] loss: 1.089\n",
      "[1203,    10] loss: 1.090\n",
      "[1204,    10] loss: 1.089\n",
      "[1205,    10] loss: 1.089\n",
      "[1206,    10] loss: 1.090\n",
      "[1207,    10] loss: 1.089\n",
      "[1208,    10] loss: 1.089\n",
      "[1209,    10] loss: 1.089\n",
      "[1210,    10] loss: 1.089\n",
      "[1211,    10] loss: 1.089\n",
      "[1212,    10] loss: 1.089\n",
      "[1213,    10] loss: 1.089\n",
      "[1214,    10] loss: 1.089\n",
      "[1215,    10] loss: 1.090\n",
      "[1216,    10] loss: 1.090\n",
      "[1217,    10] loss: 1.089\n",
      "[1218,    10] loss: 1.090\n",
      "[1219,    10] loss: 1.089\n",
      "[1220,    10] loss: 1.088\n",
      "[1221,    10] loss: 1.089\n",
      "[1222,    10] loss: 1.090\n",
      "[1223,    10] loss: 1.089\n",
      "[1224,    10] loss: 1.090\n",
      "[1225,    10] loss: 1.088\n",
      "[1226,    10] loss: 1.089\n",
      "[1227,    10] loss: 1.089\n",
      "[1228,    10] loss: 1.089\n",
      "[1229,    10] loss: 1.088\n",
      "[1230,    10] loss: 1.089\n",
      "[1231,    10] loss: 1.089\n",
      "[1232,    10] loss: 1.088\n",
      "[1233,    10] loss: 1.089\n",
      "[1234,    10] loss: 1.089\n",
      "[1235,    10] loss: 1.089\n",
      "[1236,    10] loss: 1.089\n",
      "[1237,    10] loss: 1.089\n",
      "[1238,    10] loss: 1.089\n",
      "[1239,    10] loss: 1.089\n",
      "[1240,    10] loss: 1.089\n",
      "[1241,    10] loss: 1.090\n",
      "[1242,    10] loss: 1.089\n",
      "[1243,    10] loss: 1.089\n",
      "[1244,    10] loss: 1.089\n",
      "[1245,    10] loss: 1.089\n",
      "[1246,    10] loss: 1.088\n",
      "[1247,    10] loss: 1.089\n",
      "[1248,    10] loss: 1.090\n",
      "[1249,    10] loss: 1.090\n",
      "[1250,    10] loss: 1.088\n",
      "[1251,    10] loss: 1.090\n",
      "[1252,    10] loss: 1.089\n",
      "[1253,    10] loss: 1.089\n",
      "[1254,    10] loss: 1.088\n",
      "[1255,    10] loss: 1.089\n",
      "[1256,    10] loss: 1.089\n",
      "[1257,    10] loss: 1.089\n",
      "[1258,    10] loss: 1.088\n",
      "[1259,    10] loss: 1.089\n",
      "[1260,    10] loss: 1.088\n",
      "[1261,    10] loss: 1.089\n",
      "[1262,    10] loss: 1.089\n",
      "[1263,    10] loss: 1.089\n",
      "[1264,    10] loss: 1.089\n",
      "[1265,    10] loss: 1.088\n",
      "[1266,    10] loss: 1.089\n",
      "[1267,    10] loss: 1.089\n",
      "[1268,    10] loss: 1.089\n",
      "[1269,    10] loss: 1.089\n",
      "[1270,    10] loss: 1.089\n",
      "[1271,    10] loss: 1.088\n",
      "[1272,    10] loss: 1.088\n",
      "[1273,    10] loss: 1.088\n",
      "[1274,    10] loss: 1.089\n",
      "[1275,    10] loss: 1.089\n",
      "[1276,    10] loss: 1.089\n",
      "[1277,    10] loss: 1.089\n",
      "[1278,    10] loss: 1.088\n",
      "[1279,    10] loss: 1.089\n",
      "[1280,    10] loss: 1.089\n",
      "[1281,    10] loss: 1.089\n",
      "[1282,    10] loss: 1.088\n",
      "[1283,    10] loss: 1.090\n",
      "[1284,    10] loss: 1.088\n",
      "[1285,    10] loss: 1.089\n",
      "[1286,    10] loss: 1.089\n",
      "[1287,    10] loss: 1.088\n",
      "[1288,    10] loss: 1.088\n",
      "[1289,    10] loss: 1.089\n",
      "[1290,    10] loss: 1.089\n",
      "[1291,    10] loss: 1.089\n",
      "[1292,    10] loss: 1.088\n",
      "[1293,    10] loss: 1.088\n",
      "[1294,    10] loss: 1.088\n",
      "[1295,    10] loss: 1.088\n",
      "[1296,    10] loss: 1.088\n",
      "[1297,    10] loss: 1.089\n",
      "[1298,    10] loss: 1.089\n",
      "[1299,    10] loss: 1.088\n",
      "[1300,    10] loss: 1.089\n",
      "[1301,    10] loss: 1.089\n",
      "[1302,    10] loss: 1.089\n",
      "[1303,    10] loss: 1.089\n",
      "[1304,    10] loss: 1.088\n",
      "[1305,    10] loss: 1.089\n",
      "[1306,    10] loss: 1.088\n",
      "[1307,    10] loss: 1.088\n",
      "[1308,    10] loss: 1.088\n",
      "[1309,    10] loss: 1.089\n",
      "[1310,    10] loss: 1.089\n",
      "[1311,    10] loss: 1.089\n",
      "[1312,    10] loss: 1.088\n",
      "[1313,    10] loss: 1.089\n",
      "[1314,    10] loss: 1.089\n",
      "[1315,    10] loss: 1.088\n",
      "[1316,    10] loss: 1.089\n",
      "[1317,    10] loss: 1.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1318,    10] loss: 1.088\n",
      "[1319,    10] loss: 1.088\n",
      "[1320,    10] loss: 1.088\n",
      "[1321,    10] loss: 1.088\n",
      "[1322,    10] loss: 1.088\n",
      "[1323,    10] loss: 1.089\n",
      "[1324,    10] loss: 1.088\n",
      "[1325,    10] loss: 1.089\n",
      "[1326,    10] loss: 1.088\n",
      "[1327,    10] loss: 1.088\n",
      "[1328,    10] loss: 1.088\n",
      "[1329,    10] loss: 1.089\n",
      "[1330,    10] loss: 1.088\n",
      "[1331,    10] loss: 1.088\n",
      "[1332,    10] loss: 1.090\n",
      "[1333,    10] loss: 1.088\n",
      "[1334,    10] loss: 1.088\n",
      "[1335,    10] loss: 1.089\n",
      "[1336,    10] loss: 1.088\n",
      "[1337,    10] loss: 1.089\n",
      "[1338,    10] loss: 1.089\n",
      "[1339,    10] loss: 1.088\n",
      "[1340,    10] loss: 1.088\n",
      "[1341,    10] loss: 1.089\n",
      "[1342,    10] loss: 1.088\n",
      "[1343,    10] loss: 1.088\n",
      "[1344,    10] loss: 1.088\n",
      "[1345,    10] loss: 1.089\n",
      "[1346,    10] loss: 1.089\n",
      "[1347,    10] loss: 1.089\n",
      "[1348,    10] loss: 1.088\n",
      "[1349,    10] loss: 1.089\n",
      "[1350,    10] loss: 1.088\n",
      "[1351,    10] loss: 1.088\n",
      "[1352,    10] loss: 1.088\n",
      "[1353,    10] loss: 1.089\n",
      "[1354,    10] loss: 1.088\n",
      "[1355,    10] loss: 1.089\n",
      "[1356,    10] loss: 1.088\n",
      "[1357,    10] loss: 1.088\n",
      "[1358,    10] loss: 1.088\n",
      "[1359,    10] loss: 1.089\n",
      "[1360,    10] loss: 1.088\n",
      "[1361,    10] loss: 1.088\n",
      "[1362,    10] loss: 1.088\n",
      "[1363,    10] loss: 1.089\n",
      "[1364,    10] loss: 1.088\n",
      "[1365,    10] loss: 1.088\n",
      "[1366,    10] loss: 1.088\n",
      "[1367,    10] loss: 1.088\n",
      "[1368,    10] loss: 1.088\n",
      "[1369,    10] loss: 1.088\n",
      "[1370,    10] loss: 1.088\n",
      "[1371,    10] loss: 1.088\n",
      "[1372,    10] loss: 1.088\n",
      "[1373,    10] loss: 1.088\n",
      "[1374,    10] loss: 1.088\n",
      "[1375,    10] loss: 1.088\n",
      "[1376,    10] loss: 1.088\n",
      "[1377,    10] loss: 1.088\n",
      "[1378,    10] loss: 1.088\n",
      "[1379,    10] loss: 1.089\n",
      "[1380,    10] loss: 1.088\n",
      "[1381,    10] loss: 1.089\n",
      "[1382,    10] loss: 1.089\n",
      "[1383,    10] loss: 1.088\n",
      "[1384,    10] loss: 1.088\n",
      "[1385,    10] loss: 1.088\n",
      "[1386,    10] loss: 1.088\n",
      "[1387,    10] loss: 1.088\n",
      "[1388,    10] loss: 1.088\n",
      "[1389,    10] loss: 1.089\n",
      "[1390,    10] loss: 1.088\n",
      "[1391,    10] loss: 1.088\n",
      "[1392,    10] loss: 1.089\n",
      "[1393,    10] loss: 1.089\n",
      "[1394,    10] loss: 1.088\n",
      "[1395,    10] loss: 1.088\n",
      "[1396,    10] loss: 1.089\n",
      "[1397,    10] loss: 1.088\n",
      "[1398,    10] loss: 1.088\n",
      "[1399,    10] loss: 1.088\n",
      "[1400,    10] loss: 1.088\n",
      "[1401,    10] loss: 1.089\n",
      "[1402,    10] loss: 1.088\n",
      "[1403,    10] loss: 1.088\n",
      "[1404,    10] loss: 1.089\n",
      "[1405,    10] loss: 1.088\n",
      "[1406,    10] loss: 1.088\n",
      "[1407,    10] loss: 1.088\n",
      "[1408,    10] loss: 1.088\n",
      "[1409,    10] loss: 1.088\n",
      "[1410,    10] loss: 1.088\n",
      "[1411,    10] loss: 1.088\n",
      "[1412,    10] loss: 1.088\n",
      "[1413,    10] loss: 1.088\n",
      "[1414,    10] loss: 1.089\n",
      "[1415,    10] loss: 1.088\n",
      "[1416,    10] loss: 1.088\n",
      "[1417,    10] loss: 1.088\n",
      "[1418,    10] loss: 1.089\n",
      "[1419,    10] loss: 1.089\n",
      "[1420,    10] loss: 1.089\n",
      "[1421,    10] loss: 1.089\n",
      "[1422,    10] loss: 1.089\n",
      "[1423,    10] loss: 1.089\n",
      "[1424,    10] loss: 1.088\n",
      "[1425,    10] loss: 1.089\n",
      "[1426,    10] loss: 1.088\n",
      "[1427,    10] loss: 1.088\n",
      "[1428,    10] loss: 1.088\n",
      "[1429,    10] loss: 1.089\n",
      "[1430,    10] loss: 1.088\n",
      "[1431,    10] loss: 1.088\n",
      "[1432,    10] loss: 1.088\n",
      "[1433,    10] loss: 1.088\n",
      "[1434,    10] loss: 1.088\n",
      "[1435,    10] loss: 1.088\n",
      "[1436,    10] loss: 1.088\n",
      "[1437,    10] loss: 1.088\n",
      "[1438,    10] loss: 1.089\n",
      "[1439,    10] loss: 1.088\n",
      "[1440,    10] loss: 1.088\n",
      "[1441,    10] loss: 1.088\n",
      "[1442,    10] loss: 1.088\n",
      "[1443,    10] loss: 1.088\n",
      "[1444,    10] loss: 1.088\n",
      "[1445,    10] loss: 1.088\n",
      "[1446,    10] loss: 1.088\n",
      "[1447,    10] loss: 1.088\n",
      "[1448,    10] loss: 1.088\n",
      "[1449,    10] loss: 1.088\n",
      "[1450,    10] loss: 1.088\n",
      "[1451,    10] loss: 1.088\n",
      "[1452,    10] loss: 1.088\n",
      "[1453,    10] loss: 1.090\n",
      "[1454,    10] loss: 1.088\n",
      "[1455,    10] loss: 1.088\n",
      "[1456,    10] loss: 1.088\n",
      "[1457,    10] loss: 1.088\n",
      "[1458,    10] loss: 1.089\n",
      "[1459,    10] loss: 1.088\n",
      "[1460,    10] loss: 1.088\n",
      "[1461,    10] loss: 1.088\n",
      "[1462,    10] loss: 1.088\n",
      "[1463,    10] loss: 1.088\n",
      "[1464,    10] loss: 1.088\n",
      "[1465,    10] loss: 1.088\n",
      "[1466,    10] loss: 1.088\n",
      "[1467,    10] loss: 1.088\n",
      "[1468,    10] loss: 1.088\n",
      "[1469,    10] loss: 1.089\n",
      "[1470,    10] loss: 1.088\n",
      "[1471,    10] loss: 1.088\n",
      "[1472,    10] loss: 1.088\n",
      "[1473,    10] loss: 1.088\n",
      "[1474,    10] loss: 1.088\n",
      "[1475,    10] loss: 1.088\n",
      "[1476,    10] loss: 1.088\n",
      "[1477,    10] loss: 1.088\n",
      "[1478,    10] loss: 1.088\n",
      "[1479,    10] loss: 1.088\n",
      "[1480,    10] loss: 1.088\n",
      "[1481,    10] loss: 1.088\n",
      "[1482,    10] loss: 1.089\n",
      "[1483,    10] loss: 1.088\n",
      "[1484,    10] loss: 1.088\n",
      "[1485,    10] loss: 1.088\n",
      "[1486,    10] loss: 1.088\n",
      "[1487,    10] loss: 1.088\n",
      "[1488,    10] loss: 1.088\n",
      "[1489,    10] loss: 1.088\n",
      "[1490,    10] loss: 1.088\n",
      "[1491,    10] loss: 1.088\n",
      "[1492,    10] loss: 1.088\n",
      "[1493,    10] loss: 1.088\n",
      "[1494,    10] loss: 1.088\n",
      "[1495,    10] loss: 1.088\n",
      "[1496,    10] loss: 1.087\n",
      "[1497,    10] loss: 1.088\n",
      "[1498,    10] loss: 1.088\n",
      "[1499,    10] loss: 1.087\n",
      "[1500,    10] loss: 1.088\n",
      "[1501,    10] loss: 1.089\n",
      "[1502,    10] loss: 1.088\n",
      "[1503,    10] loss: 1.088\n",
      "[1504,    10] loss: 1.088\n",
      "[1505,    10] loss: 1.088\n",
      "[1506,    10] loss: 1.088\n",
      "[1507,    10] loss: 1.088\n",
      "[1508,    10] loss: 1.089\n",
      "[1509,    10] loss: 1.088\n",
      "[1510,    10] loss: 1.087\n",
      "[1511,    10] loss: 1.088\n",
      "[1512,    10] loss: 1.089\n",
      "[1513,    10] loss: 1.088\n",
      "[1514,    10] loss: 1.088\n",
      "[1515,    10] loss: 1.089\n",
      "[1516,    10] loss: 1.088\n",
      "[1517,    10] loss: 1.087\n",
      "[1518,    10] loss: 1.088\n",
      "[1519,    10] loss: 1.089\n",
      "[1520,    10] loss: 1.088\n",
      "[1521,    10] loss: 1.088\n",
      "[1522,    10] loss: 1.088\n",
      "[1523,    10] loss: 1.088\n",
      "[1524,    10] loss: 1.087\n",
      "[1525,    10] loss: 1.088\n",
      "[1526,    10] loss: 1.088\n",
      "[1527,    10] loss: 1.087\n",
      "[1528,    10] loss: 1.088\n",
      "[1529,    10] loss: 1.088\n",
      "[1530,    10] loss: 1.088\n",
      "[1531,    10] loss: 1.088\n",
      "[1532,    10] loss: 1.088\n",
      "[1533,    10] loss: 1.087\n",
      "[1534,    10] loss: 1.088\n",
      "[1535,    10] loss: 1.090\n",
      "[1536,    10] loss: 1.088\n",
      "[1537,    10] loss: 1.088\n",
      "[1538,    10] loss: 1.088\n",
      "[1539,    10] loss: 1.088\n",
      "[1540,    10] loss: 1.088\n",
      "[1541,    10] loss: 1.088\n",
      "[1542,    10] loss: 1.087\n",
      "[1543,    10] loss: 1.088\n",
      "[1544,    10] loss: 1.088\n",
      "[1545,    10] loss: 1.088\n",
      "[1546,    10] loss: 1.088\n",
      "[1547,    10] loss: 1.088\n",
      "[1548,    10] loss: 1.088\n",
      "[1549,    10] loss: 1.088\n",
      "[1550,    10] loss: 1.088\n",
      "[1551,    10] loss: 1.088\n",
      "[1552,    10] loss: 1.087\n",
      "[1553,    10] loss: 1.088\n",
      "[1554,    10] loss: 1.088\n",
      "[1555,    10] loss: 1.089\n",
      "[1556,    10] loss: 1.087\n",
      "[1557,    10] loss: 1.088\n",
      "[1558,    10] loss: 1.088\n",
      "[1559,    10] loss: 1.088\n",
      "[1560,    10] loss: 1.088\n",
      "[1561,    10] loss: 1.087\n",
      "[1562,    10] loss: 1.089\n",
      "[1563,    10] loss: 1.087\n",
      "[1564,    10] loss: 1.088\n",
      "[1565,    10] loss: 1.088\n",
      "[1566,    10] loss: 1.089\n",
      "[1567,    10] loss: 1.088\n",
      "[1568,    10] loss: 1.088\n",
      "[1569,    10] loss: 1.087\n",
      "[1570,    10] loss: 1.088\n",
      "[1571,    10] loss: 1.088\n",
      "[1572,    10] loss: 1.088\n",
      "[1573,    10] loss: 1.088\n",
      "[1574,    10] loss: 1.088\n",
      "[1575,    10] loss: 1.088\n",
      "[1576,    10] loss: 1.088\n",
      "[1577,    10] loss: 1.088\n",
      "[1578,    10] loss: 1.087\n",
      "[1579,    10] loss: 1.088\n",
      "[1580,    10] loss: 1.088\n",
      "[1581,    10] loss: 1.088\n",
      "[1582,    10] loss: 1.088\n",
      "[1583,    10] loss: 1.088\n",
      "[1584,    10] loss: 1.088\n",
      "[1585,    10] loss: 1.089\n",
      "[1586,    10] loss: 1.088\n",
      "[1587,    10] loss: 1.088\n",
      "[1588,    10] loss: 1.088\n",
      "[1589,    10] loss: 1.088\n",
      "[1590,    10] loss: 1.087\n",
      "[1591,    10] loss: 1.088\n",
      "[1592,    10] loss: 1.088\n",
      "[1593,    10] loss: 1.088\n",
      "[1594,    10] loss: 1.088\n",
      "[1595,    10] loss: 1.087\n",
      "[1596,    10] loss: 1.089\n",
      "[1597,    10] loss: 1.088\n",
      "[1598,    10] loss: 1.088\n",
      "[1599,    10] loss: 1.088\n",
      "[1600,    10] loss: 1.087\n",
      "[1601,    10] loss: 1.088\n",
      "[1602,    10] loss: 1.088\n",
      "[1603,    10] loss: 1.089\n",
      "[1604,    10] loss: 1.087\n",
      "[1605,    10] loss: 1.088\n",
      "[1606,    10] loss: 1.087\n",
      "[1607,    10] loss: 1.088\n",
      "[1608,    10] loss: 1.087\n",
      "[1609,    10] loss: 1.088\n",
      "[1610,    10] loss: 1.088\n",
      "[1611,    10] loss: 1.087\n",
      "[1612,    10] loss: 1.088\n",
      "[1613,    10] loss: 1.087\n",
      "[1614,    10] loss: 1.088\n",
      "[1615,    10] loss: 1.087\n",
      "[1616,    10] loss: 1.088\n",
      "[1617,    10] loss: 1.088\n",
      "[1618,    10] loss: 1.088\n",
      "[1619,    10] loss: 1.088\n",
      "[1620,    10] loss: 1.087\n",
      "[1621,    10] loss: 1.088\n",
      "[1622,    10] loss: 1.088\n",
      "[1623,    10] loss: 1.087\n",
      "[1624,    10] loss: 1.088\n",
      "[1625,    10] loss: 1.088\n",
      "[1626,    10] loss: 1.087\n",
      "[1627,    10] loss: 1.087\n",
      "[1628,    10] loss: 1.087\n",
      "[1629,    10] loss: 1.087\n",
      "[1630,    10] loss: 1.088\n",
      "[1631,    10] loss: 1.087\n",
      "[1632,    10] loss: 1.088\n",
      "[1633,    10] loss: 1.087\n",
      "[1634,    10] loss: 1.087\n",
      "[1635,    10] loss: 1.087\n",
      "[1636,    10] loss: 1.087\n",
      "[1637,    10] loss: 1.088\n",
      "[1638,    10] loss: 1.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1639,    10] loss: 1.088\n",
      "[1640,    10] loss: 1.087\n",
      "[1641,    10] loss: 1.088\n",
      "[1642,    10] loss: 1.087\n",
      "[1643,    10] loss: 1.088\n",
      "[1644,    10] loss: 1.087\n",
      "[1645,    10] loss: 1.087\n",
      "[1646,    10] loss: 1.088\n",
      "[1647,    10] loss: 1.087\n",
      "[1648,    10] loss: 1.088\n",
      "[1649,    10] loss: 1.088\n",
      "[1650,    10] loss: 1.088\n",
      "[1651,    10] loss: 1.088\n",
      "[1652,    10] loss: 1.088\n",
      "[1653,    10] loss: 1.089\n",
      "[1654,    10] loss: 1.087\n",
      "[1655,    10] loss: 1.088\n",
      "[1656,    10] loss: 1.089\n",
      "[1657,    10] loss: 1.087\n",
      "[1658,    10] loss: 1.088\n",
      "[1659,    10] loss: 1.087\n",
      "[1660,    10] loss: 1.087\n",
      "[1661,    10] loss: 1.087\n",
      "[1662,    10] loss: 1.087\n",
      "[1663,    10] loss: 1.088\n",
      "[1664,    10] loss: 1.087\n",
      "[1665,    10] loss: 1.088\n",
      "[1666,    10] loss: 1.087\n",
      "[1667,    10] loss: 1.088\n",
      "[1668,    10] loss: 1.087\n",
      "[1669,    10] loss: 1.087\n",
      "[1670,    10] loss: 1.087\n",
      "[1671,    10] loss: 1.087\n",
      "[1672,    10] loss: 1.087\n",
      "[1673,    10] loss: 1.088\n",
      "[1674,    10] loss: 1.087\n",
      "[1675,    10] loss: 1.088\n",
      "[1676,    10] loss: 1.087\n",
      "[1677,    10] loss: 1.087\n",
      "[1678,    10] loss: 1.087\n",
      "[1679,    10] loss: 1.087\n",
      "[1680,    10] loss: 1.087\n",
      "[1681,    10] loss: 1.087\n",
      "[1682,    10] loss: 1.087\n",
      "[1683,    10] loss: 1.088\n",
      "[1684,    10] loss: 1.088\n",
      "[1685,    10] loss: 1.088\n",
      "[1686,    10] loss: 1.087\n",
      "[1687,    10] loss: 1.087\n",
      "[1688,    10] loss: 1.088\n",
      "[1689,    10] loss: 1.087\n",
      "[1690,    10] loss: 1.087\n",
      "[1691,    10] loss: 1.088\n",
      "[1692,    10] loss: 1.088\n",
      "[1693,    10] loss: 1.087\n",
      "[1694,    10] loss: 1.087\n",
      "[1695,    10] loss: 1.087\n",
      "[1696,    10] loss: 1.087\n",
      "[1697,    10] loss: 1.088\n",
      "[1698,    10] loss: 1.087\n",
      "[1699,    10] loss: 1.087\n",
      "[1700,    10] loss: 1.087\n",
      "[1701,    10] loss: 1.088\n",
      "[1702,    10] loss: 1.087\n",
      "[1703,    10] loss: 1.087\n",
      "[1704,    10] loss: 1.087\n",
      "[1705,    10] loss: 1.087\n",
      "[1706,    10] loss: 1.087\n",
      "[1707,    10] loss: 1.087\n",
      "[1708,    10] loss: 1.088\n",
      "[1709,    10] loss: 1.087\n",
      "[1710,    10] loss: 1.087\n",
      "[1711,    10] loss: 1.087\n",
      "[1712,    10] loss: 1.087\n",
      "[1713,    10] loss: 1.087\n",
      "[1714,    10] loss: 1.088\n",
      "[1715,    10] loss: 1.087\n",
      "[1716,    10] loss: 1.087\n",
      "[1717,    10] loss: 1.087\n",
      "[1718,    10] loss: 1.087\n",
      "[1719,    10] loss: 1.087\n",
      "[1720,    10] loss: 1.088\n",
      "[1721,    10] loss: 1.087\n",
      "[1722,    10] loss: 1.087\n",
      "[1723,    10] loss: 1.087\n",
      "[1724,    10] loss: 1.087\n",
      "[1725,    10] loss: 1.089\n",
      "[1726,    10] loss: 1.087\n",
      "[1727,    10] loss: 1.089\n",
      "[1728,    10] loss: 1.088\n",
      "[1729,    10] loss: 1.087\n",
      "[1730,    10] loss: 1.087\n",
      "[1731,    10] loss: 1.087\n",
      "[1732,    10] loss: 1.087\n",
      "[1733,    10] loss: 1.087\n",
      "[1734,    10] loss: 1.087\n",
      "[1735,    10] loss: 1.088\n",
      "[1736,    10] loss: 1.087\n",
      "[1737,    10] loss: 1.087\n",
      "[1738,    10] loss: 1.088\n",
      "[1739,    10] loss: 1.088\n",
      "[1740,    10] loss: 1.087\n",
      "[1741,    10] loss: 1.087\n",
      "[1742,    10] loss: 1.087\n",
      "[1743,    10] loss: 1.087\n",
      "[1744,    10] loss: 1.087\n",
      "[1745,    10] loss: 1.088\n",
      "[1746,    10] loss: 1.087\n",
      "[1747,    10] loss: 1.087\n",
      "[1748,    10] loss: 1.087\n",
      "[1749,    10] loss: 1.087\n",
      "[1750,    10] loss: 1.089\n",
      "[1751,    10] loss: 1.087\n",
      "[1752,    10] loss: 1.087\n",
      "[1753,    10] loss: 1.087\n",
      "[1754,    10] loss: 1.087\n",
      "[1755,    10] loss: 1.087\n",
      "[1756,    10] loss: 1.087\n",
      "[1757,    10] loss: 1.088\n",
      "[1758,    10] loss: 1.088\n",
      "[1759,    10] loss: 1.089\n",
      "[1760,    10] loss: 1.087\n",
      "[1761,    10] loss: 1.087\n",
      "[1762,    10] loss: 1.087\n",
      "[1763,    10] loss: 1.088\n",
      "[1764,    10] loss: 1.088\n",
      "[1765,    10] loss: 1.088\n",
      "[1766,    10] loss: 1.087\n",
      "[1767,    10] loss: 1.087\n",
      "[1768,    10] loss: 1.087\n",
      "[1769,    10] loss: 1.087\n",
      "[1770,    10] loss: 1.087\n",
      "[1771,    10] loss: 1.087\n",
      "[1772,    10] loss: 1.087\n",
      "[1773,    10] loss: 1.088\n",
      "[1774,    10] loss: 1.088\n",
      "[1775,    10] loss: 1.087\n",
      "[1776,    10] loss: 1.087\n",
      "[1777,    10] loss: 1.087\n",
      "[1778,    10] loss: 1.087\n",
      "[1779,    10] loss: 1.087\n",
      "[1780,    10] loss: 1.088\n",
      "[1781,    10] loss: 1.087\n",
      "[1782,    10] loss: 1.087\n",
      "[1783,    10] loss: 1.088\n",
      "[1784,    10] loss: 1.088\n",
      "[1785,    10] loss: 1.087\n",
      "[1786,    10] loss: 1.087\n",
      "[1787,    10] loss: 1.088\n",
      "[1788,    10] loss: 1.087\n",
      "[1789,    10] loss: 1.087\n",
      "[1790,    10] loss: 1.087\n",
      "[1791,    10] loss: 1.087\n",
      "[1792,    10] loss: 1.087\n",
      "[1793,    10] loss: 1.088\n",
      "[1794,    10] loss: 1.087\n",
      "[1795,    10] loss: 1.087\n",
      "[1796,    10] loss: 1.088\n",
      "[1797,    10] loss: 1.087\n",
      "[1798,    10] loss: 1.087\n",
      "[1799,    10] loss: 1.087\n",
      "[1800,    10] loss: 1.088\n",
      "[1801,    10] loss: 1.087\n",
      "[1802,    10] loss: 1.088\n",
      "[1803,    10] loss: 1.087\n",
      "[1804,    10] loss: 1.087\n",
      "[1805,    10] loss: 1.088\n",
      "[1806,    10] loss: 1.087\n",
      "[1807,    10] loss: 1.087\n",
      "[1808,    10] loss: 1.087\n",
      "[1809,    10] loss: 1.087\n",
      "[1810,    10] loss: 1.087\n",
      "[1811,    10] loss: 1.087\n",
      "[1812,    10] loss: 1.087\n",
      "[1813,    10] loss: 1.089\n",
      "[1814,    10] loss: 1.087\n",
      "[1815,    10] loss: 1.087\n",
      "[1816,    10] loss: 1.087\n",
      "[1817,    10] loss: 1.088\n",
      "[1818,    10] loss: 1.087\n",
      "[1819,    10] loss: 1.087\n",
      "[1820,    10] loss: 1.087\n",
      "[1821,    10] loss: 1.087\n",
      "[1822,    10] loss: 1.087\n",
      "[1823,    10] loss: 1.087\n",
      "[1824,    10] loss: 1.087\n",
      "[1825,    10] loss: 1.087\n",
      "[1826,    10] loss: 1.087\n",
      "[1827,    10] loss: 1.088\n",
      "[1828,    10] loss: 1.087\n",
      "[1829,    10] loss: 1.087\n",
      "[1830,    10] loss: 1.087\n",
      "[1831,    10] loss: 1.087\n",
      "[1832,    10] loss: 1.087\n",
      "[1833,    10] loss: 1.087\n",
      "[1834,    10] loss: 1.087\n",
      "[1835,    10] loss: 1.087\n",
      "[1836,    10] loss: 1.087\n",
      "[1837,    10] loss: 1.088\n",
      "[1838,    10] loss: 1.087\n",
      "[1839,    10] loss: 1.089\n",
      "[1840,    10] loss: 1.088\n",
      "[1841,    10] loss: 1.087\n",
      "[1842,    10] loss: 1.087\n",
      "[1843,    10] loss: 1.087\n",
      "[1844,    10] loss: 1.087\n",
      "[1845,    10] loss: 1.087\n",
      "[1846,    10] loss: 1.087\n",
      "[1847,    10] loss: 1.087\n",
      "[1848,    10] loss: 1.088\n",
      "[1849,    10] loss: 1.088\n",
      "[1850,    10] loss: 1.087\n",
      "[1851,    10] loss: 1.087\n",
      "[1852,    10] loss: 1.087\n",
      "[1853,    10] loss: 1.087\n",
      "[1854,    10] loss: 1.087\n",
      "[1855,    10] loss: 1.087\n",
      "[1856,    10] loss: 1.087\n",
      "[1857,    10] loss: 1.087\n",
      "[1858,    10] loss: 1.087\n",
      "[1859,    10] loss: 1.087\n",
      "[1860,    10] loss: 1.088\n",
      "[1861,    10] loss: 1.086\n",
      "[1862,    10] loss: 1.087\n",
      "[1863,    10] loss: 1.087\n",
      "[1864,    10] loss: 1.089\n",
      "[1865,    10] loss: 1.087\n",
      "[1866,    10] loss: 1.087\n",
      "[1867,    10] loss: 1.087\n",
      "[1868,    10] loss: 1.087\n",
      "[1869,    10] loss: 1.087\n",
      "[1870,    10] loss: 1.087\n",
      "[1871,    10] loss: 1.087\n",
      "[1872,    10] loss: 1.087\n",
      "[1873,    10] loss: 1.087\n",
      "[1874,    10] loss: 1.087\n",
      "[1875,    10] loss: 1.087\n",
      "[1876,    10] loss: 1.087\n",
      "[1877,    10] loss: 1.087\n",
      "[1878,    10] loss: 1.087\n",
      "[1879,    10] loss: 1.088\n",
      "[1880,    10] loss: 1.088\n",
      "[1881,    10] loss: 1.088\n",
      "[1882,    10] loss: 1.088\n",
      "[1883,    10] loss: 1.089\n",
      "[1884,    10] loss: 1.087\n",
      "[1885,    10] loss: 1.087\n",
      "[1886,    10] loss: 1.087\n",
      "[1887,    10] loss: 1.087\n",
      "[1888,    10] loss: 1.087\n",
      "[1889,    10] loss: 1.087\n",
      "[1890,    10] loss: 1.088\n",
      "[1891,    10] loss: 1.087\n",
      "[1892,    10] loss: 1.087\n",
      "[1893,    10] loss: 1.087\n",
      "[1894,    10] loss: 1.087\n",
      "[1895,    10] loss: 1.087\n",
      "[1896,    10] loss: 1.087\n",
      "[1897,    10] loss: 1.088\n",
      "[1898,    10] loss: 1.087\n",
      "[1899,    10] loss: 1.087\n",
      "[1900,    10] loss: 1.087\n",
      "[1901,    10] loss: 1.087\n",
      "[1902,    10] loss: 1.088\n",
      "[1903,    10] loss: 1.087\n",
      "[1904,    10] loss: 1.087\n",
      "[1905,    10] loss: 1.087\n",
      "[1906,    10] loss: 1.087\n",
      "[1907,    10] loss: 1.088\n",
      "[1908,    10] loss: 1.087\n",
      "[1909,    10] loss: 1.088\n",
      "[1910,    10] loss: 1.087\n",
      "[1911,    10] loss: 1.087\n",
      "[1912,    10] loss: 1.087\n",
      "[1913,    10] loss: 1.088\n",
      "[1914,    10] loss: 1.087\n",
      "[1915,    10] loss: 1.087\n",
      "[1916,    10] loss: 1.088\n",
      "[1917,    10] loss: 1.087\n",
      "[1918,    10] loss: 1.089\n",
      "[1919,    10] loss: 1.088\n",
      "[1920,    10] loss: 1.087\n",
      "[1921,    10] loss: 1.087\n",
      "[1922,    10] loss: 1.087\n",
      "[1923,    10] loss: 1.087\n",
      "[1924,    10] loss: 1.088\n",
      "[1925,    10] loss: 1.087\n",
      "[1926,    10] loss: 1.086\n",
      "[1927,    10] loss: 1.086\n",
      "[1928,    10] loss: 1.088\n",
      "[1929,    10] loss: 1.087\n",
      "[1930,    10] loss: 1.086\n",
      "[1931,    10] loss: 1.088\n",
      "[1932,    10] loss: 1.087\n",
      "[1933,    10] loss: 1.087\n",
      "[1934,    10] loss: 1.087\n",
      "[1935,    10] loss: 1.087\n",
      "[1936,    10] loss: 1.087\n",
      "[1937,    10] loss: 1.088\n",
      "[1938,    10] loss: 1.087\n",
      "[1939,    10] loss: 1.086\n",
      "[1940,    10] loss: 1.087\n",
      "[1941,    10] loss: 1.087\n",
      "[1942,    10] loss: 1.087\n",
      "[1943,    10] loss: 1.087\n",
      "[1944,    10] loss: 1.087\n",
      "[1945,    10] loss: 1.087\n",
      "[1946,    10] loss: 1.087\n",
      "[1947,    10] loss: 1.087\n",
      "[1948,    10] loss: 1.086\n",
      "[1949,    10] loss: 1.086\n",
      "[1950,    10] loss: 1.087\n",
      "[1951,    10] loss: 1.087\n",
      "[1952,    10] loss: 1.087\n",
      "[1953,    10] loss: 1.086\n",
      "[1954,    10] loss: 1.089\n",
      "[1955,    10] loss: 1.087\n",
      "[1956,    10] loss: 1.087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1957,    10] loss: 1.087\n",
      "[1958,    10] loss: 1.088\n",
      "[1959,    10] loss: 1.087\n",
      "[1960,    10] loss: 1.087\n",
      "[1961,    10] loss: 1.086\n",
      "[1962,    10] loss: 1.087\n",
      "[1963,    10] loss: 1.087\n",
      "[1964,    10] loss: 1.087\n",
      "[1965,    10] loss: 1.086\n",
      "[1966,    10] loss: 1.087\n",
      "[1967,    10] loss: 1.089\n",
      "[1968,    10] loss: 1.087\n",
      "[1969,    10] loss: 1.087\n",
      "[1970,    10] loss: 1.088\n",
      "[1971,    10] loss: 1.088\n",
      "[1972,    10] loss: 1.087\n",
      "[1973,    10] loss: 1.088\n",
      "[1974,    10] loss: 1.087\n",
      "[1975,    10] loss: 1.087\n",
      "[1976,    10] loss: 1.087\n",
      "[1977,    10] loss: 1.087\n",
      "[1978,    10] loss: 1.087\n",
      "[1979,    10] loss: 1.087\n",
      "[1980,    10] loss: 1.087\n",
      "[1981,    10] loss: 1.087\n",
      "[1982,    10] loss: 1.087\n",
      "[1983,    10] loss: 1.087\n",
      "[1984,    10] loss: 1.086\n",
      "[1985,    10] loss: 1.087\n",
      "[1986,    10] loss: 1.086\n",
      "[1987,    10] loss: 1.087\n",
      "[1988,    10] loss: 1.088\n",
      "[1989,    10] loss: 1.087\n",
      "[1990,    10] loss: 1.087\n",
      "[1991,    10] loss: 1.087\n",
      "[1992,    10] loss: 1.087\n",
      "[1993,    10] loss: 1.086\n",
      "[1994,    10] loss: 1.088\n",
      "[1995,    10] loss: 1.086\n",
      "[1996,    10] loss: 1.086\n",
      "[1997,    10] loss: 1.087\n",
      "[1998,    10] loss: 1.087\n",
      "[1999,    10] loss: 1.087\n",
      "[2000,    10] loss: 1.087\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "nos_epochs = 2000\n",
    "focus_true_pred_true =0\n",
    "focus_false_pred_true =0\n",
    "focus_true_pred_false =0\n",
    "focus_false_pred_false =0\n",
    "\n",
    "argmax_more_than_half = 0\n",
    "argmax_less_than_half =0\n",
    "\n",
    "\n",
    "for epoch in range(nos_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "  focus_true_pred_true =0\n",
    "  focus_false_pred_true =0\n",
    "  focus_true_pred_false =0\n",
    "  focus_false_pred_false =0\n",
    "  \n",
    "  argmax_more_than_half = 0\n",
    "  argmax_less_than_half =0\n",
    "  \n",
    "  running_loss = 0.0\n",
    "  epoch_loss = []\n",
    "  cnt=0\n",
    "\n",
    "  iteration = desired_num // batch\n",
    "  \n",
    "  #training data set\n",
    "  \n",
    "  for i, data in  enumerate(train_loader):\n",
    "    inputs , labels , fore_idx = data\n",
    "    batch = inputs.size(0)\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    inputs = inputs.double()\n",
    "    # zero the parameter gradients\n",
    "    \n",
    "    optimizer_focus.zero_grad()\n",
    "    optimizer_classify.zero_grad()\n",
    "    \n",
    "    alphas, avg_images = focus_net(inputs)\n",
    "    outputs = classify(avg_images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "#     print(outputs)\n",
    "#     print(outputs.shape,labels.shape , torch.argmax(outputs, dim=1))\n",
    "\n",
    "    loss = my_cross_entropy(outputs, labels,alphas) \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "    optimizer_focus.step()\n",
    "    optimizer_classify.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    mini = 10\n",
    "    if cnt % mini == mini-1:    # print every 40 mini-batches\n",
    "      print('[%d, %5d] loss: %.3f' %(epoch + 1, cnt + 1, running_loss / mini))\n",
    "      epoch_loss.append(running_loss/mini)\n",
    "      running_loss = 0.0\n",
    "    cnt=cnt+1\n",
    "\n",
    "  if(np.mean(epoch_loss) <= 0.01):\n",
    "      break;\n",
    "  #plot_attended_data(train_loader,focus_net,epoch)\n",
    "\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "3xPsiBtU-GDn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fc1.weight', Parameter containing:\n",
      "tensor([[ -0.3246,   0.1496],\n",
      "        [  1.7570,  -2.1820],\n",
      "        [ -1.2389,   5.6221],\n",
      "        [  2.4567,  -2.2924],\n",
      "        [  2.4819,  -2.2089],\n",
      "        [  1.7584,  -1.8166],\n",
      "        [ -0.1748,  -0.0348],\n",
      "        [  1.8127,  -1.9011],\n",
      "        [ -1.2842,   5.0753],\n",
      "        [  2.3568,  -2.6019],\n",
      "        [  1.0751,  -2.7403],\n",
      "        [  2.1752,  -2.2030],\n",
      "        [ -1.2927,   5.4325],\n",
      "        [ -1.4497,   6.7109],\n",
      "        [ -1.2271,   5.5345],\n",
      "        [  0.7638,  -1.8016],\n",
      "        [  1.8896,  -1.9791],\n",
      "        [  1.9970, -10.0956],\n",
      "        [ -1.2625,   4.9759],\n",
      "        [  1.3613,  -3.0547],\n",
      "        [ -0.5123,   0.0814],\n",
      "        [  2.4468,  -2.4988],\n",
      "        [ -1.4388,   6.5369],\n",
      "        [  1.1773,  -6.0286],\n",
      "        [ -1.3692,   6.3010],\n",
      "        [  0.8749,  -1.8563],\n",
      "        [  0.7871,  -1.8411],\n",
      "        [ -1.2276,   4.8497],\n",
      "        [  1.9861,  -2.3672],\n",
      "        [ -1.1496,   4.9154],\n",
      "        [  1.2011,  -2.7868],\n",
      "        [  2.4380,  -2.6385],\n",
      "        [  2.4209,  -2.4233],\n",
      "        [ -1.0191,   2.9194],\n",
      "        [ -1.2096,   5.1646],\n",
      "        [  2.3874,  -2.6633],\n",
      "        [  1.6556,  -1.8962],\n",
      "        [  1.9447,  -9.8114],\n",
      "        [ -0.4402,   0.0465],\n",
      "        [  0.5335,  -1.3726],\n",
      "        [ -0.2336,  -0.0230],\n",
      "        [  2.0858,  -1.7673],\n",
      "        [ -0.1920,  -0.0199],\n",
      "        [ -0.5677,   1.5943],\n",
      "        [ -0.2093,  -0.0216],\n",
      "        [  1.7159,  -1.8531],\n",
      "        [  2.4829,  -2.6933],\n",
      "        [  0.7494,  -1.7982],\n",
      "        [  2.1172,  -2.0219],\n",
      "        [  1.1925,  -6.3255]], dtype=torch.float64, requires_grad=True))\n",
      "('fc2.weight', Parameter containing:\n",
      "tensor([[ 1.1676e-01,  3.1446e+00, -9.2359e+00,  2.4790e+00,  2.2145e+00,\n",
      "          2.9161e+00,  2.2776e-01,  2.7525e+00, -8.1719e+00,  3.6844e+00,\n",
      "          1.4835e+01,  2.8492e+00, -7.7389e+00, -1.1278e+01, -8.4313e+00,\n",
      "          7.9307e+00,  2.5885e+00, -1.6699e+01, -9.4184e+00,  7.2474e+00,\n",
      "         -9.3741e-02,  3.3711e+00, -7.0900e+00, -1.1256e+01, -1.0724e+01,\n",
      "          3.3848e+00,  4.9907e+00, -9.0392e+00,  3.4927e+00, -1.0887e+01,\n",
      "          1.0042e+01,  3.9238e+00,  3.1127e+00, -4.7776e+00, -9.0398e+00,\n",
      "          3.8735e+00,  3.1913e+00, -1.2306e+01, -1.4737e-02,  2.8887e+00,\n",
      "          5.1415e-02,  1.9964e+00,  2.9469e-04, -2.4872e+00,  6.4797e-02,\n",
      "          1.7841e+00,  3.0017e+00,  3.7765e+00,  2.4182e+00, -7.7109e+00]],\n",
      "       dtype=torch.float64, requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for param in focus_net.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "jhvhkEAyeRpt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 39.400000 %\n",
      "total correct 197\n",
      "total train set images 500\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "focus_net.eval()\n",
    "classify.eval()\n",
    "with torch.no_grad():\n",
    "  for data in train_loader:\n",
    "    inputs, labels , fore_idx = data\n",
    "    inputs = inputs.double()\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    alphas, avg_images = focus_net(inputs)\n",
    "    outputs = classify(avg_images)\n",
    "    #print(outputs.shape)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the train images: %f %%' % ( 100 * correct / total))\n",
    "print(\"total correct\", correct)\n",
    "print(\"total train set images\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "OKcmpKwGeS8M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 32.400000 %\n",
      "total correct 324\n",
      "total train set images 1000\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for data in test_loader:\n",
    "    inputs, labels , fore_idx = data\n",
    "    inputs = inputs.double()\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    alphas, avg_images = focus_net(inputs)\n",
    "    outputs = classify(avg_images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f %%' % ( 100 * correct / total))\n",
    "print(\"total correct\", correct)\n",
    "print(\"total train set images\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hard_attention_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
