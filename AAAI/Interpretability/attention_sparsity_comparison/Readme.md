### Compare different algorithms

- Dataset 2 (elliptical blob 5d data) Architecture (6,12)
- Adam optimizer with initial learning rate 0.001 (specified if some other is used)
- zeroth layer averaging
- * only 2 out of 5 runs worked

 ## Table A1
| Attention Activation | Avg Accuracy  | Avg FTPT | Sparsity value  | Simplex distance | entropy | 
| -----------------    | ---------     | -------  | -----           | ---               | -----  |
| softmax | 99.86  |  81.60  | 1.221   |  0.036  | 0.101 |
| sparsemax | 99.99 |  99.36 |   1.0914 | 0.018   |  0.0509 |
| spherical softmax* |  98.44  | 63.33  |   2.747       |   0.224      |  0.686       |
 
## Table A2: Dataset 1 (type4 data)  Architecture (focus-50,50, classification -50)

| Attention Activation | Avg Accuracy  | Avg FTPT | Sparsity value  | Simplex distance | entropy | 
| -----------------    | ---------     | -------  | -----    | ---       |        ----- | 
| softmax |  98.89  |  77.50  | 2.407   |  0.241  | 0.677 |
| sparsemax |  98.57  | 76.95 | 1.61  | 0.740  | 0.394|
| spherical softmax |  96.16 |   71.38  |    3.294  |   0.338    |  1.0381     |



 
 
 <!---  | zero | softmax  |  99.89 |84.41 | 15.48 | 10 | 99.89 | 84.41 | 15.48 | 
 | zero |  sparsemax (lr 0.01 just checked)|  80.81 | 67.19 | 13.61 |  7 | 99.90 | 94.90 | 5.08 | 
 | zero | sparsemax  |   99.85 | 76.86 | 22.99 | 10 | 99.85 | 76.86 | 22.99 |--->
 
 ## Table 2: CIFAR - Entropy
 - Focus net has no bias and weights are initialised to xavier norm, Classification weights are initialised to xavier norm and bias with zeros.
 - Attention is softmax
 - seed = 0,1,2 for run1,2,3
 - LR = 0.0005
 #### Zeroth Layer
 |SNo | avg layer | k-value | Train Acc  | Train FTPT | Train avg sparsity | Train avg Simplex dist | Train avg entropy |Test Acc  | Test FTPT | Test avg sparsity | Test avg Simplex dist | Test avg entropy |
 |----|-----------|--------|-------|-------|--------|--------|--------|-------|-------|--------|--------|--------|
 |1.1 | zeroth    |  0     | 99.12 | 84.49 | 3.7806 | 0.2217 | 0.8835 | 95.00 | 81.13 | 4.0006 | 0.2429 | 0.9579 |
 |1.2 | zeroth    |  0     | 99.25 | 79.69 | 4.1903 | 0.2628 | 1.0372 | 95.58 | 76.58 | 4.5127 | 0.2841 | 1.1240 |
 |1.3 | zeroth    |  0     | 99.41 | 84.36 | 3.9280 | 0.2303 | 0.9230 | 95.66 | 81.71 | 4.1814 | 0.2512 | 0.9998 |
 |2.1 | zeroth    |  0.001 | 99.14 | 81.40 | 4.0554 | 0.2584 | 1.0071 | 95.64 | 78.60 | 4.2983 | 0.2764 | 1.0767 |
 |2.2 | zeroth    |  0.001 | 99.18 | 80.85 | 3.9913 | 0.2540 | 0.9804 | 95.17 | 77.66 | 4.2464 | 0.2687 | 1.0466 |
 |2.3 | zeroth    |  0.001 | 99.09 | 82.26 | 3.8060 | 0.2362 | 0.9173 | 94.85 | 79.13 | 4.0511 | 0.2535 | 0.9838 |
 |3.1 | zeroth    |  0.003 | 99.25 | 85.68 | 3.2710 | 0.1913 | 0.7424 | 95.34 | 82.15 | 3.4910 | 0.2150 | 0.8208 |
 |3.2 | zeroth    |  0.003 | 99.14 | 81.41 | 3.8096 | 0.2301 | 0.8928 | 95.16 | 78.49 | 4.0678 | 0.2509 | 0.9727 |
 |3.3 | zeroth    |  0.003 | 99.18 | 85.55 | 3.4764 | 0.2006 | 0.7903 | 95.30 | 82.30 | 3.7163 | 0.2227 | 0.8678 |
 |4.1 | zeroth    |  0.005 | 98.99 | 85.29 | 3.2804 | 0.1923 | 0.7434 | 95.17 | 82.06 | 3.4616 | 0.2095 | 0.8048 |
 |4.2 | zeroth    |  0.005 | 72.03 | 36.13 | 1.0066 | 0.0014 | - | 61.98 | 36.41 | 1.0078 | 0.0014 | - |
 |4.3 | zeroth    |  0.005 | 98.89 | 85.40 | 3.3360 | 0.1931 | 0.7521 | 94.91 | 81.94 | 3.5238 | 0.2132 | 0.8174 |
 
  #### Sixth Layer
 |SNo | avg layer | k-value | Train Acc  | Train FTPT | Train avg sparsity | Train avg Simplex dist | Train avg entropy |Test Acc  | Test FTPT | Test avg sparsity | Test avg Simplex dist | Test avg entropy |
 |----|----------|--------|-------|-------|--------|--------|--------|-------|-------|--------|--------|--------|
 |1.1 | sixth    |  0     | 99.42 | 88.08 | 5.4162 | 0.2936 | 1.2625 | 94.92 | 84.19 | 5.5623 | 0.3142 | 1.3223 |
 |1.2 | sixth    |  0     | 98.68 | 81.83 | 4.4469 | 0.2581 | 1.0470 | 94.20 | 78.58 | 4.6381 | 0.2707 | 1.0960 |
 |1.3 | sixth    |  0     | 98.79 | 84.42 | 3.8865 | 0.2345 | 0.9257 | 93.87 | 80.44 | 4.0270 | 0.2479 | 0.9711 |
 |2.1 | sixth    |  0.001 | 99.38 | 87.17 | 5.0885 | 0.2930 | 1.2191 | 94.06 | 82.52 | 5.2185 | 0.3110 | 1.2735 |
 |2.2 | sixth    |  0.001 | 99.21 | 87.83 | 4.4528 | 0.2417 | 1.0152 | 94.75 | 83.46 | 4.6813 | 0.2646 | 1.0893 |
 |2.3 | sixth    |  0.001 | 99.61 | 86.50 | 4.0217 | 0.2339 | 0.9455 | 95.23 | 82.61 | 4.2151 | 0.2529 | 1.0101 |
 |3.1 | sixth    |  0.003 | 99.07 | 87.04 | 4.4610 | 0.2626 | 1.0673 | 94.47 | 83.29 | 4.5881 | 0.2794 | 1.1164 |
 |3.2 | sixth    |  0.003 | 99.31 | 85.09 | 3.6083 | 0.2040 | 0.8107 | 94.17 | 81.38 | 3.7821 | 0.2171 | 0.8599 |
 |3.3 | sixth    |  0.003 | 99.43 | 86.98 | 3.6828 | 0.2149 | 0.8550 | 94.98 | 82.72 | 3.8587 | 0.2317 | 0.9139 |
 |4.1 | sixth    |  0.005 | 99.12 | 88.07 | 3.8194 | 0.2212 | 0.8912 | 94.39 | 83.63 | 3.9774 | 0.2434 | 0.9587 |
 |4.2 | sixth    |  0.005 | 99.52 | 87.47 | 3.5587 | 0.2016 | 0.8077 | 95.58 | 83.99 | 3.7357 | 0.2200 | 0.8680 |
 |4.3 | sixth    |  0.005 | 99.25 | 86.89 | 2.9577 | 0.1718 | 0.6593 | 94.78 | 82.98 | 3.1089 | 0.1893 | 0.7132 |

 
 ## Table 3: CIFAR - SparseMax / Spherical softmax / Softmax 
 - Focus net has no bias and weights are initialised to xavier norm, Classification weights are initialised to xavier norm and bias with zeros.
 - seed = 0
 
 |SNo | Seed |avg layer | Attention |  Learning Rate | Train Acc  | Train FTPT | Train avg sparsity | Smplx dist| Entropy | Test Acc  | Test FTPT | Test avg sparsity | Smplx dist |Test Entropy |
 |----|-----------|----------------------|-------|-------|-------|--------| ---------  |-------|-------|--------| --------- | ------ | ---- | ---- | 
 | 1  | 0 | zeroth  | SparseMax         | 0.0005 | 99.01 | 86.03 | 1.89 |  0.177    | 0.476 | 94.7  | 82.88 | 1.98 | 0.196    | 0.527 |
 | 2  | 1 | zeroth  | SparseMax         | 0.0005 | 98.98 | 85.74 | 1.66 | 0.137 | 0.361  | 95.32 | 82.9  | 1.73 | 0.155 | 0.404 |
 | 3  | 2 | zeroth  | SparseMax         | 0.0005 | 99.05 | 85.23 | 1.95 | 0.176 | 0.487 | 95.47 | 82.51 | 2.02 | 0.192 | 0.529 |
 | 4 | 0 |sixth    | SparseMax         | 0.0005 | 98.95 | 86.33 | 2.33 | 0.223 | 0.652 |94.39 | 82.26 | 2.44 | 0.245  | 0.709 |
 | 5  | 1 | sixth   | SparseMax         | 0.0005 | 98.9  | 83.00 | 2.35 | 0.224 | 0.653 |94.59 | 79.82 | 2.45 | 0.2412 |  0.704 |
 | 6  | 2 | sixth   | SparseMax         | 0.0005 | 99.15 | 86.94 | 2.37 | 0.230 | 0.667 | 94.55 | 82.56 | 2.49 | 0.2538 | 0.731 |
 | 7 | 0 |zeroth   | Spherical softmax | 0.0005 | 99.26 | 85.08 | 4.78 | 0.259 | 1.118 |94.77 | 81.62 | 5.05 | 0.281 | 1.196 | 
 | 8 | 1 | zeroth |  Spherical softmax | 0.0005 | 99.01 | 84.54 | 4.05 | 0.230 | 0.958 | 94.81 | 81.28 | 4.30 | 0.2499 | 1.027 |
 | 9 | 2 | zeroth | Spherical softmax  | 0.0005 | 99.13 | 88.55 | 4.00 | 0.207 |  0.892 | 95.42 |  85.26 | 4.23 | 0.231 | 0.970 |
 | 10 | 0 | sixth   | Spherical softmax | 0.0005 | 99.34 | 87.80 | 6.19 |  0.321  | 1.41  | 94.17 | 83.13 | 6.31 | 0.3435 | 1.478 |
 | 11 | 1 | sixth   | Spherical softmax | 0.0005 | 98.97 | 87.77 | 4.75 | 0.262 | 1.109  | 94.72 | 83.78 | 4.86 | 0.2810 |1.164 |
 | 12 | 2 | sixth   | Spherical softmax | 0.0005 | 99.09 | 85.81 | 4.77 | 0.260 |1.110 |  93.34 | 81.60 | 4.95 | 0.2777 | 1.166 |



<!---| 13  | zeroth    | Softmax (no entropy) | 0.0005 | 98.79 | 83.69 | 3.72 | 95.03 | 80.26 | 3.94 |
 | 14  | zeroth    | Softmax (no entropy) | 0.001 | - | - | - | - | - | - |
 | 15  | zeroth    | Softmax (no entropy) | 0.003 | - | - | - | - | - | - |
 | 16  | sixth     | Softmax (no entropy) | 0.0005 | 98.97 | 86.43 | 6.31 | 93.76 | 82.33 | 6.38 |
 | 17  | sixth     | Softmax (no entropy) | 0.001 | 98.35 | 87.69 | 4.92 | 94.41 | 83.65 | 5.07 |
 | 18  | sixth     | Softmax (no entropy) | 0.003 |  45.43 | 13.48 | 1.006 | 44.42 | 13.47 | 1.004 | 
 | 6  | 0 |sixth     | SparseMax            | 0.003 | 33.79 | 4.55 | 1.003 | 33.53 | 4.54 | 1.003 |
 | 3  | 0 |zeroth    | SparseMax            | 0.003 | 46.38 | 14.69 | 1.003 | 44.92 | 15.37 | 1.00 |
| 9 | 0|zeroth    | Spherical softmax    | 0.003 | 99.44 | 87.53  | 3.71 | 95.62 | 84.84 | 3.89  |
 | 12 |  0|sixth     | Spherical softmax    | 0.003 | 99.39 | 87.51  | 4.66 | 95.41 | 83.80 | 4.78 |
 | 4  | 0 |zeroth   | SparseMax         | 0.001  | 98.75 | 80.03 | 3.25  | - | 95.22 | 76.87 | 3.39 | - |
| 8  | 0 | sixth   | SparseMax         | 0.001  | 99.29 | 87.48 | 2.17 |  -    | 95.56 | 84.39 | 2.25 | -      | 
 | 9  | 2 | sixth   | SparseMax         | 0.001  | 99.10 | 78.37 | 2.25 | 0.24 | 95.47 | 75.52 | 2.31 | 0.2618 |
 | 12 | 0 |zeroth  | Spherical softmax | 0.001  | 98.41 | 81.21 | 4.34 | -  | | 93.89   | 77.84    | 4.58 | | |
 | 13 | 1 | zeroth | Spherical softmax | 0.001  | 99.19 | 83.05 | 4.57 | 0.261 | | 95.40 | 79.83 | 4.84 | 0.284 | |
 | 14 | 2 | zeroth | Spherical softmax | 0.001  | 99.37 | 86.85 | 4.03 | 0.21 | |95.01 |83.41 | 4.25 | 0.232 | |
 | 18 | 0 | sixth   | Spherical softmax | 0.001  | 99.32 | 88.69 |  4.29 | | | 95.26  | 85.00 | 4.40  | | |
 | 19 | 1 | sixth   | Spherical softmax | 0.001  | 98.92 | 87.43 |  5.02 | 0.26 | | 95.63 | 84.38 | 5.15 | 0.280 | |
 | 20 | 2 | sixth   | Spherical softmax | 0.001  | 99.25 | 87.83 | 4.40  | 0.24 | | 95.08 | 84.38 | 4.53 | 0.263 | |
--->

 
  
<!--  |SNo | avg layer | k-value | Learning Rate | Train Acc  | Train FTPT | Train avg sparsity | Test Acc  | Test FTPT | Test avg sparsity |
 |----|-----------|--------|-------|-------|--------|-------|-------|-------|--------|
 |1.1 | zeroth    |  0     | 0.001 | 98.88 | 81.34 | 3.9187 | 94.34 | 78.38 | 4.1388 |
 |1.2 | zeroth    |  0     | 0.0005| 98.79 | 83.69 | 3.7232 | 95.03 | 80.26 | 3.9465 |
 |2.1 | zeroth    |  0.001 | 0.001 | 98.83 | 84.18 | 3.8682 | 95.15 | 81.02 | 4.0746 |
 |2.2 | zeroth    |  0.001 | 0.0005| 99.09 | 80.69 | 4.1593 | 95.29 | 77.63 | 4.4181 |
 |3.1 | zeroth    |  0.003 | 0.001 | 99.06 | 82.25 | 4.1836 | 95.41 | 79.21 | 4.4451 |
 |3.2 | zeroth    |  0.003 | 0.0005| 99.32 | 86.49 | 3.3545 | 95.49 | 83.13 | 3.5912 |
 |4.1 | zeroth    |  0.005 | 0.001 | 98.52 | 86.10 | 2.4659 | 94.99 | 82.57 | 2.5934 |
 |4.2 | zeroth    |  0.005 | 0.0005| 99.04 | 85.39 | 3.1548 | 95.40 | 82.30 | 3.3495 |
 |5.1 | sixth     |  0     | 0.001 | 98.77 | 85.92 | 4.6685 | 94.73 | 82.35 | 4.8302 |
 |5.2 | sixth     |  0     | 0.0005| 98.90 | 86.10 | 5.4152 | 93.85 | 82.01 | 5.4931 |
 |6.1 | sixth     |  0.001 | 0.001 | 99.46 | 78.03 | 3.9369 | 94.65 | 74.54 | 4.0924 |
 |6.2 | sixth     |  0.001 | 0.0005| 99.29 | 87.61 | 3.9897 | 94.99 | 83.82 | 4.1308 |
 |7.1 | sixth     |  0.003 | 0.001 | 99.33 | 75.30 | 2.9134 | 94.33 | 72.64 | 2.9869 |
 |7.2 | sixth     |  0.003 | 0.0005| 99.47 | 88.57 | 4.4092 | 94.64 | 84.55 | 4.5881 |
 | 8  | sixth     |  0.005 | 0.0005| 99.59 | 88.35 | 3.6379 | 94.85 | 84.21 | 3.7670 | -->
 
  
 
